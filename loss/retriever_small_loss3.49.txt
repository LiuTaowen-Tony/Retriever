@dataclass
class RerieverConfig_29M:
    batch_size = 32
    gradient_accumulation_steps = 4
    sequence_length = 1024
    learning_rate = 6e-4
    min_lr = 6e-5
    vocab_size = 32000
    num_layers = 6
    hidden_size = 512
    num_heads = 8
    beta1 = 0.9
    beta2 = 0.95
    weight_decay = 1e-1
    warmup_iters = 2000
    max_iters = 250000
    lr_decay_iters = 220000
    grad_clip = 1.0

num decayed parameter tensors: 38, with 29,491,200 parameters
num non-decayed parameter tensors: 13, with 6,656 parameters
number of total parameters: 28.97M
all train file nums: 1024
preparing first dataset file english_c4/c4-train.00000-of-01024.txt
finished, consume: 109s
processing 0: english_c4/c4-train.00000-of-01024.txt, origin: 355732, samples: 173721, accum_tokens: 177M, iter_num: 0
step 100, loss 9.48, lr 0.000030, consume 95.70s
step 200, loss 7.81, lr 0.000060, consume 85.48s
step 300, loss 6.80, lr 0.000090, consume 71.62s
step 400, loss 6.38, lr 0.000120, consume 72.17s
step 500, loss 6.17, lr 0.000150, consume 71.52s
step 600, loss 6.01, lr 0.000180, consume 70.88s
step 700, loss 5.85, lr 0.000210, consume 70.86s
step 800, loss 5.70, lr 0.000240, consume 70.83s
step 900, loss 5.57, lr 0.000270, consume 70.83s
step 1000, loss 5.44, lr 0.000300, consume 70.81s
step 1100, loss 5.32, lr 0.000330, consume 70.85s
step 1200, loss 5.20, lr 0.000360, consume 70.82s
step 1300, loss 5.09, lr 0.000390, consume 70.82s
processing 1: english_c4/c4-train.00001-of-01024.txt, origin: 355708, samples: 173229, accum_tokens: 355M, iter_num: 1357
step 1400, loss 4.99, lr 0.000420, consume 93.11s
step 1500, loss 4.88, lr 0.000450, consume 73.18s
step 1600, loss 4.77, lr 0.000480, consume 84.34s
step 1700, loss 4.66, lr 0.000510, consume 70.79s
step 1800, loss 4.59, lr 0.000540, consume 70.82s
step 1900, loss 4.54, lr 0.000570, consume 70.82s
step 2000, loss 4.49, lr 0.000600, consume 70.81s
step 2100, loss 4.44, lr 0.000600, consume 70.78s
step 2200, loss 4.40, lr 0.000600, consume 70.78s
step 2300, loss 4.35, lr 0.000600, consume 70.78s
step 2400, loss 4.32, lr 0.000600, consume 70.77s
step 2500, loss 4.29, lr 0.000600, consume 70.77s
step 2600, loss 4.27, lr 0.000600, consume 70.76s
step 2700, loss 4.24, lr 0.000600, consume 70.75s
processing 2: english_c4/c4-train.00002-of-01024.txt, origin: 355718, samples: 173903, accum_tokens: 533M, iter_num: 2710
step 2800, loss 4.23, lr 0.000600, consume 94.38s
step 2900, loss 4.20, lr 0.000600, consume 73.28s
step 3000, loss 4.20, lr 0.000600, consume 83.24s
step 3100, loss 4.18, lr 0.000600, consume 70.84s
step 3200, loss 4.15, lr 0.000600, consume 70.84s
step 3300, loss 4.14, lr 0.000600, consume 70.85s
step 3400, loss 4.13, lr 0.000600, consume 70.84s
step 3500, loss 4.12, lr 0.000600, consume 70.83s
step 3600, loss 4.11, lr 0.000600, consume 70.82s
step 3700, loss 4.10, lr 0.000600, consume 70.83s
step 3800, loss 4.09, lr 0.000600, consume 70.82s
step 3900, loss 4.08, lr 0.000600, consume 70.83s
step 4000, loss 4.06, lr 0.000600, consume 70.84s
processing 3: english_c4/c4-train.00003-of-01024.txt, origin: 355753, samples: 173350, accum_tokens: 710M, iter_num: 4068
step 4100, loss 4.05, lr 0.000600, consume 93.77s
step 4200, loss 4.04, lr 0.000600, consume 72.39s
step 4300, loss 4.04, lr 0.000600, consume 84.34s
step 4400, loss 4.03, lr 0.000600, consume 70.80s
step 4500, loss 4.02, lr 0.000600, consume 70.87s
step 4600, loss 4.02, lr 0.000600, consume 70.85s
step 4700, loss 4.01, lr 0.000600, consume 70.84s
step 4800, loss 4.00, lr 0.000600, consume 70.85s
step 4900, loss 4.00, lr 0.000600, consume 70.83s
step 5000, loss 3.99, lr 0.000600, consume 70.83s
step 5100, loss 3.98, lr 0.000600, consume 70.82s
step 5200, loss 3.97, lr 0.000600, consume 70.81s
step 5300, loss 3.97, lr 0.000600, consume 70.81s
step 5400, loss 3.96, lr 0.000600, consume 70.81s
processing 4: english_c4/c4-train.00004-of-01024.txt, origin: 355691, samples: 173171, accum_tokens: 888M, iter_num: 5423
step 5500, loss 3.97, lr 0.000600, consume 93.93s
step 5600, loss 3.97, lr 0.000600, consume 73.02s
step 5700, loss 3.96, lr 0.000600, consume 83.08s
step 5800, loss 3.95, lr 0.000600, consume 70.87s
step 5900, loss 3.95, lr 0.000600, consume 70.91s
step 6000, loss 3.94, lr 0.000600, consume 70.91s
step 6100, loss 3.94, lr 0.000600, consume 70.89s
step 6200, loss 3.94, lr 0.000600, consume 70.90s
step 6300, loss 3.93, lr 0.000599, consume 70.86s
step 6400, loss 3.92, lr 0.000599, consume 70.88s
step 6500, loss 3.93, lr 0.000599, consume 70.87s
step 6600, loss 3.91, lr 0.000599, consume 70.86s
step 6700, loss 3.92, lr 0.000599, consume 70.87s
processing 5: english_c4/c4-train.00005-of-01024.txt, origin: 355717, samples: 172927, accum_tokens: 1065M, iter_num: 6775
step 6800, loss 3.92, lr 0.000599, consume 93.44s
step 6900, loss 3.92, lr 0.000599, consume 72.14s
step 7000, loss 3.91, lr 0.000599, consume 85.70s
step 7100, loss 3.91, lr 0.000599, consume 70.81s
step 7200, loss 3.90, lr 0.000599, consume 70.89s
step 7300, loss 3.90, lr 0.000599, consume 70.92s
step 7400, loss 3.90, lr 0.000599, consume 70.89s
step 7500, loss 3.89, lr 0.000599, consume 70.88s
step 7600, loss 3.89, lr 0.000599, consume 70.87s
step 7700, loss 3.89, lr 0.000599, consume 70.86s
step 7800, loss 3.89, lr 0.000599, consume 70.85s
step 7900, loss 3.88, lr 0.000599, consume 70.87s
step 8000, loss 3.87, lr 0.000599, consume 70.86s
step 8100, loss 3.87, lr 0.000599, consume 70.86s
processing 6: english_c4/c4-train.00006-of-01024.txt, origin: 355747, samples: 173252, accum_tokens: 1242M, iter_num: 8126
step 8200, loss 3.87, lr 0.000599, consume 94.52s
step 8300, loss 3.88, lr 0.000599, consume 73.00s
step 8400, loss 3.87, lr 0.000599, consume 83.36s
step 8500, loss 3.86, lr 0.000599, consume 70.87s
step 8600, loss 3.87, lr 0.000599, consume 70.89s
step 8700, loss 3.86, lr 0.000599, consume 70.90s
step 8800, loss 3.85, lr 0.000599, consume 70.88s
step 8900, loss 3.85, lr 0.000599, consume 70.88s
step 9000, loss 3.85, lr 0.000599, consume 70.87s
step 9100, loss 3.85, lr 0.000599, consume 70.86s
step 9200, loss 3.85, lr 0.000599, consume 70.88s
step 9300, loss 3.85, lr 0.000599, consume 70.87s
step 9400, loss 3.84, lr 0.000598, consume 70.88s
processing 7: english_c4/c4-train.00007-of-01024.txt, origin: 355719, samples: 173288, accum_tokens: 1420M, iter_num: 9480
step 9500, loss 3.85, lr 0.000598, consume 92.50s
step 9600, loss 3.85, lr 0.000598, consume 72.98s
step 9700, loss 3.84, lr 0.000598, consume 84.46s
step 9800, loss 3.85, lr 0.000598, consume 70.84s
step 9900, loss 3.84, lr 0.000598, consume 70.93s
step 10000, loss 3.84, lr 0.000598, consume 70.93s
step 10100, loss 3.83, lr 0.000598, consume 70.94s
step 10200, loss 3.84, lr 0.000598, consume 70.92s
step 10300, loss 3.83, lr 0.000598, consume 70.92s
step 10400, loss 3.83, lr 0.000598, consume 70.90s
step 10500, loss 3.83, lr 0.000598, consume 70.88s
step 10600, loss 3.84, lr 0.000598, consume 70.89s
step 10700, loss 3.83, lr 0.000598, consume 70.90s
step 10800, loss 3.82, lr 0.000598, consume 70.91s
processing 8: english_c4/c4-train.00008-of-01024.txt, origin: 355746, samples: 173024, accum_tokens: 1597M, iter_num: 10833
step 10900, loss 3.83, lr 0.000598, consume 94.16s
step 11000, loss 3.83, lr 0.000598, consume 72.92s
step 11100, loss 3.82, lr 0.000598, consume 84.47s
step 11200, loss 3.82, lr 0.000598, consume 70.88s
step 11300, loss 3.82, lr 0.000598, consume 70.90s
step 11400, loss 3.82, lr 0.000598, consume 70.90s
step 11500, loss 3.82, lr 0.000597, consume 70.92s
step 11600, loss 3.81, lr 0.000597, consume 70.88s
step 11700, loss 3.81, lr 0.000597, consume 70.90s
step 11800, loss 3.81, lr 0.000597, consume 70.88s
step 11900, loss 3.80, lr 0.000597, consume 70.88s
step 12000, loss 3.81, lr 0.000597, consume 70.89s
step 12100, loss 3.81, lr 0.000597, consume 70.88s
processing 9: english_c4/c4-train.00009-of-01024.txt, origin: 355708, samples: 172984, accum_tokens: 1774M, iter_num: 12185
step 12200, loss 3.80, lr 0.000597, consume 92.46s
step 12300, loss 3.81, lr 0.000597, consume 72.20s
step 12400, loss 3.81, lr 0.000597, consume 85.04s
step 12500, loss 3.80, lr 0.000597, consume 70.78s
step 12600, loss 3.80, lr 0.000597, consume 70.89s
step 12700, loss 3.80, lr 0.000597, consume 70.88s
step 12800, loss 3.80, lr 0.000597, consume 70.89s
step 12900, loss 3.79, lr 0.000597, consume 70.87s
step 13000, loss 3.79, lr 0.000597, consume 70.87s
step 13100, loss 3.80, lr 0.000597, consume 70.87s
step 13200, loss 3.80, lr 0.000596, consume 70.86s
step 13300, loss 3.79, lr 0.000596, consume 70.87s
step 13400, loss 3.80, lr 0.000596, consume 70.86s
step 13500, loss 3.79, lr 0.000596, consume 70.86s
processing 10: english_c4/c4-train.00010-of-01024.txt, origin: 355702, samples: 173710, accum_tokens: 1952M, iter_num: 13536
step 13600, loss 3.79, lr 0.000596, consume 93.52s
step 13700, loss 3.80, lr 0.000596, consume 72.84s
step 13800, loss 3.80, lr 0.000596, consume 84.46s
step 13900, loss 3.79, lr 0.000596, consume 70.85s
step 14000, loss 3.78, lr 0.000596, consume 70.90s
step 14100, loss 3.79, lr 0.000596, consume 70.89s
step 14200, loss 3.79, lr 0.000596, consume 70.89s
step 14300, loss 3.78, lr 0.000596, consume 70.87s
step 14400, loss 3.78, lr 0.000596, consume 70.87s
step 14500, loss 3.78, lr 0.000596, consume 70.89s
step 14600, loss 3.76, lr 0.000596, consume 70.87s
step 14700, loss 3.78, lr 0.000595, consume 70.87s
step 14800, loss 3.79, lr 0.000595, consume 70.88s
processing 11: english_c4/c4-train.00011-of-01024.txt, origin: 355701, samples: 173885, accum_tokens: 2130M, iter_num: 14893
step 14900, loss 3.78, lr 0.000595, consume 93.25s
step 15000, loss 3.79, lr 0.000595, consume 72.27s
step 15100, loss 3.78, lr 0.000595, consume 85.56s
step 15200, loss 3.79, lr 0.000595, consume 70.78s
step 15300, loss 3.78, lr 0.000595, consume 70.90s
step 15400, loss 3.78, lr 0.000595, consume 70.92s
step 15500, loss 3.78, lr 0.000595, consume 70.90s
step 15600, loss 3.78, lr 0.000595, consume 70.89s
step 15700, loss 3.78, lr 0.000595, consume 70.89s
step 15800, loss 3.77, lr 0.000595, consume 70.87s
step 15900, loss 3.78, lr 0.000595, consume 70.88s
step 16000, loss 3.78, lr 0.000595, consume 70.87s
step 16100, loss 3.78, lr 0.000594, consume 70.86s
step 16200, loss 3.77, lr 0.000594, consume 70.87s
processing 12: english_c4/c4-train.00012-of-01024.txt, origin: 355710, samples: 174423, accum_tokens: 2308M, iter_num: 16252
step 16300, loss 3.77, lr 0.000594, consume 93.98s
step 16400, loss 3.78, lr 0.000594, consume 72.60s
step 16500, loss 3.77, lr 0.000594, consume 84.33s
step 16600, loss 3.77, lr 0.000594, consume 70.87s
step 16700, loss 3.77, lr 0.000594, consume 70.91s
step 16800, loss 3.76, lr 0.000594, consume 70.92s
step 16900, loss 3.77, lr 0.000594, consume 70.91s
step 17000, loss 3.76, lr 0.000594, consume 70.91s
step 17100, loss 3.77, lr 0.000594, consume 70.90s
step 17200, loss 3.76, lr 0.000594, consume 70.90s
step 17300, loss 3.76, lr 0.000593, consume 70.90s
step 17400, loss 3.75, lr 0.000593, consume 70.89s
step 17500, loss 3.76, lr 0.000593, consume 70.90s
step 17600, loss 3.75, lr 0.000593, consume 70.89s
processing 13: english_c4/c4-train.00013-of-01024.txt, origin: 355723, samples: 173966, accum_tokens: 2487M, iter_num: 17614
step 17700, loss 3.76, lr 0.000593, consume 93.77s
step 17800, loss 3.76, lr 0.000593, consume 74.17s
step 17900, loss 3.76, lr 0.000593, consume 83.01s
step 18000, loss 3.77, lr 0.000593, consume 70.89s
step 18100, loss 3.76, lr 0.000593, consume 70.92s
step 18200, loss 3.76, lr 0.000593, consume 70.92s
step 18300, loss 3.75, lr 0.000593, consume 70.91s
step 18400, loss 3.74, lr 0.000592, consume 70.92s
step 18500, loss 3.75, lr 0.000592, consume 70.90s
step 18600, loss 3.75, lr 0.000592, consume 70.89s
step 18700, loss 3.75, lr 0.000592, consume 70.88s
step 18800, loss 3.74, lr 0.000592, consume 70.87s
step 18900, loss 3.75, lr 0.000592, consume 70.89s
processing 14: english_c4/c4-train.00014-of-01024.txt, origin: 355708, samples: 174115, accum_tokens: 2665M, iter_num: 18973
step 19000, loss 3.75, lr 0.000592, consume 90.66s
step 19100, loss 3.75, lr 0.000592, consume 72.93s
step 19200, loss 3.76, lr 0.000592, consume 84.70s
step 19300, loss 3.75, lr 0.000592, consume 70.85s
step 19400, loss 3.75, lr 0.000592, consume 70.92s
step 19500, loss 3.75, lr 0.000591, consume 70.94s
step 19600, loss 3.75, lr 0.000591, consume 70.92s
step 19700, loss 3.74, lr 0.000591, consume 70.90s
step 19800, loss 3.74, lr 0.000591, consume 70.92s
step 19900, loss 3.75, lr 0.000591, consume 70.92s
step 20000, loss 3.74, lr 0.000591, consume 70.93s
step 20100, loss 3.74, lr 0.000591, consume 70.91s
step 20200, loss 3.74, lr 0.000591, consume 70.91s
step 20300, loss 3.74, lr 0.000591, consume 70.90s
processing 15: english_c4/c4-train.00015-of-01024.txt, origin: 355698, samples: 173319, accum_tokens: 2842M, iter_num: 20333
step 20400, loss 3.75, lr 0.000591, consume 91.60s
step 20500, loss 3.74, lr 0.000590, consume 72.88s
step 20600, loss 3.74, lr 0.000590, consume 84.65s
step 20700, loss 3.75, lr 0.000590, consume 70.90s
step 20800, loss 3.74, lr 0.000590, consume 70.92s
step 20900, loss 3.74, lr 0.000590, consume 70.93s
step 21000, loss 3.75, lr 0.000590, consume 70.93s
step 21100, loss 3.74, lr 0.000590, consume 70.93s
step 21200, loss 3.74, lr 0.000590, consume 70.93s
step 21300, loss 3.74, lr 0.000590, consume 70.91s
step 21400, loss 3.74, lr 0.000590, consume 70.91s
step 21500, loss 3.73, lr 0.000589, consume 70.91s
step 21600, loss 3.73, lr 0.000589, consume 70.90s
processing 16: english_c4/c4-train.00016-of-01024.txt, origin: 355697, samples: 173354, accum_tokens: 3020M, iter_num: 21687
step 21700, loss 3.74, lr 0.000589, consume 91.36s
step 21800, loss 3.75, lr 0.000589, consume 71.97s
step 21900, loss 3.74, lr 0.000589, consume 85.22s
step 22000, loss 3.74, lr 0.000589, consume 70.80s
step 22100, loss 3.74, lr 0.000589, consume 70.89s
step 22200, loss 3.74, lr 0.000589, consume 70.91s
step 22300, loss 3.73, lr 0.000589, consume 70.89s
step 22400, loss 3.74, lr 0.000588, consume 70.88s
step 22500, loss 3.74, lr 0.000588, consume 70.87s
step 22600, loss 3.73, lr 0.000588, consume 70.87s
step 22700, loss 3.73, lr 0.000588, consume 70.87s
step 22800, loss 3.73, lr 0.000588, consume 70.87s
step 22900, loss 3.73, lr 0.000588, consume 70.86s
step 23000, loss 3.73, lr 0.000588, consume 70.88s
processing 17: english_c4/c4-train.00017-of-01024.txt, origin: 355726, samples: 174259, accum_tokens: 3198M, iter_num: 23042
step 23100, loss 3.73, lr 0.000588, consume 91.21s
step 23200, loss 3.73, lr 0.000587, consume 72.59s
step 23300, loss 3.73, lr 0.000587, consume 84.09s
step 23400, loss 3.73, lr 0.000587, consume 70.89s
step 23500, loss 3.74, lr 0.000587, consume 70.92s
step 23600, loss 3.74, lr 0.000587, consume 70.94s
step 23700, loss 3.73, lr 0.000587, consume 70.93s
step 23800, loss 3.72, lr 0.000587, consume 70.91s
step 23900, loss 3.73, lr 0.000587, consume 70.92s
step 24000, loss 3.73, lr 0.000587, consume 70.90s
step 24100, loss 3.73, lr 0.000586, consume 70.88s
step 24200, loss 3.73, lr 0.000586, consume 70.90s
step 24300, loss 3.73, lr 0.000586, consume 70.89s
step 24400, loss 3.73, lr 0.000586, consume 70.89s
processing 18: english_c4/c4-train.00018-of-01024.txt, origin: 355709, samples: 173222, accum_tokens: 3376M, iter_num: 24403
step 24500, loss 3.74, lr 0.000586, consume 92.20s
step 24600, loss 3.72, lr 0.000586, consume 73.30s
step 24700, loss 3.73, lr 0.000586, consume 82.89s
step 24800, loss 3.73, lr 0.000586, consume 70.93s
step 24900, loss 3.73, lr 0.000585, consume 70.93s
step 25000, loss 3.73, lr 0.000585, consume 70.95s
step 25100, loss 3.72, lr 0.000585, consume 70.94s
step 25200, loss 3.73, lr 0.000585, consume 70.93s
step 25300, loss 3.73, lr 0.000585, consume 70.94s
step 25400, loss 3.72, lr 0.000585, consume 70.93s
step 25500, loss 3.73, lr 0.000585, consume 70.91s
step 25600, loss 3.73, lr 0.000585, consume 70.92s
step 25700, loss 3.73, lr 0.000584, consume 70.90s
processing 19: english_c4/c4-train.00019-of-01024.txt, origin: 355697, samples: 173993, accum_tokens: 3554M, iter_num: 25756
step 25800, loss 3.72, lr 0.000584, consume 91.08s
step 25900, loss 3.73, lr 0.000584, consume 72.46s
step 26000, loss 3.72, lr 0.000584, consume 84.10s
step 26100, loss 3.73, lr 0.000584, consume 70.85s
step 26200, loss 3.73, lr 0.000584, consume 70.93s
step 26300, loss 3.72, lr 0.000584, consume 70.93s
step 26400, loss 3.72, lr 0.000583, consume 70.93s
step 26500, loss 3.72, lr 0.000583, consume 70.90s
step 26600, loss 3.72, lr 0.000583, consume 70.91s
step 26700, loss 3.72, lr 0.000583, consume 70.90s
step 26800, loss 3.71, lr 0.000583, consume 70.90s
step 26900, loss 3.71, lr 0.000583, consume 70.89s
step 27000, loss 3.72, lr 0.000583, consume 70.89s
step 27100, loss 3.71, lr 0.000583, consume 70.88s
processing 20: english_c4/c4-train.00020-of-01024.txt, origin: 355687, samples: 173497, accum_tokens: 3732M, iter_num: 27115
step 27200, loss 3.73, lr 0.000582, consume 91.98s
step 27300, loss 3.72, lr 0.000582, consume 73.18s
step 27400, loss 3.72, lr 0.000582, consume 83.26s
step 27500, loss 3.72, lr 0.000582, consume 70.91s
step 27600, loss 3.72, lr 0.000582, consume 70.94s
step 27700, loss 3.72, lr 0.000582, consume 70.94s
step 27800, loss 3.72, lr 0.000582, consume 70.94s
step 27900, loss 3.72, lr 0.000581, consume 70.94s
step 28000, loss 3.72, lr 0.000581, consume 70.92s
step 28100, loss 3.72, lr 0.000581, consume 70.91s
step 28200, loss 3.71, lr 0.000581, consume 70.91s
step 28300, loss 3.71, lr 0.000581, consume 70.90s
step 28400, loss 3.72, lr 0.000581, consume 70.90s
processing 21: english_c4/c4-train.00021-of-01024.txt, origin: 355709, samples: 173358, accum_tokens: 3909M, iter_num: 28471
step 28500, loss 3.72, lr 0.000581, consume 90.62s
step 28600, loss 3.72, lr 0.000580, consume 72.13s
step 28700, loss 3.71, lr 0.000580, consume 85.39s
step 28800, loss 3.71, lr 0.000580, consume 70.85s
step 28900, loss 3.71, lr 0.000580, consume 70.93s
step 29000, loss 3.70, lr 0.000580, consume 70.94s
step 29100, loss 3.71, lr 0.000580, consume 70.93s
step 29200, loss 3.71, lr 0.000580, consume 70.93s
step 29300, loss 3.71, lr 0.000579, consume 70.92s
step 29400, loss 3.71, lr 0.000579, consume 70.91s
step 29500, loss 3.70, lr 0.000579, consume 70.92s
step 29600, loss 3.71, lr 0.000579, consume 70.91s
step 29700, loss 3.71, lr 0.000579, consume 70.92s
step 29800, loss 3.71, lr 0.000579, consume 70.90s
processing 22: english_c4/c4-train.00022-of-01024.txt, origin: 355742, samples: 173215, accum_tokens: 4086M, iter_num: 29825
step 29900, loss 3.71, lr 0.000578, consume 91.74s
step 30000, loss 3.72, lr 0.000578, consume 73.22s
step 30100, loss 3.72, lr 0.000578, consume 83.24s
step 30200, loss 3.72, lr 0.000578, consume 70.89s
step 30300, loss 3.72, lr 0.000578, consume 70.95s
step 30400, loss 3.71, lr 0.000578, consume 70.96s
step 30500, loss 3.71, lr 0.000578, consume 70.93s
step 30600, loss 3.71, lr 0.000577, consume 70.93s
step 30700, loss 3.71, lr 0.000577, consume 70.90s
step 30800, loss 3.70, lr 0.000577, consume 70.92s
step 30900, loss 3.71, lr 0.000577, consume 70.93s
step 31000, loss 3.71, lr 0.000577, consume 70.92s
step 31100, loss 3.70, lr 0.000577, consume 70.93s
processing 23: english_c4/c4-train.00023-of-01024.txt, origin: 355714, samples: 173979, accum_tokens: 4265M, iter_num: 31178
step 31200, loss 3.72, lr 0.000576, consume 91.46s
step 31300, loss 3.71, lr 0.000576, consume 73.02s
step 31400, loss 3.71, lr 0.000576, consume 84.35s
step 31500, loss 3.71, lr 0.000576, consume 70.81s
step 31600, loss 3.70, lr 0.000576, consume 70.95s
step 31700, loss 3.71, lr 0.000576, consume 70.95s
step 31800, loss 3.70, lr 0.000575, consume 70.95s
step 31900, loss 3.71, lr 0.000575, consume 70.92s
step 32000, loss 3.70, lr 0.000575, consume 70.96s
step 32100, loss 3.70, lr 0.000575, consume 70.95s
step 32200, loss 3.71, lr 0.000575, consume 70.93s
step 32300, loss 3.70, lr 0.000575, consume 70.92s
step 32400, loss 3.70, lr 0.000575, consume 70.91s
step 32500, loss 3.70, lr 0.000574, consume 70.92s
processing 24: english_c4/c4-train.00024-of-01024.txt, origin: 355728, samples: 172879, accum_tokens: 4442M, iter_num: 32537
step 32600, loss 3.70, lr 0.000574, consume 91.29s
step 32700, loss 3.71, lr 0.000574, consume 72.87s
step 32800, loss 3.71, lr 0.000574, consume 84.69s
step 32900, loss 3.71, lr 0.000574, consume 70.86s
step 33000, loss 3.70, lr 0.000574, consume 70.94s
step 33100, loss 3.71, lr 0.000573, consume 70.95s
step 33200, loss 3.70, lr 0.000573, consume 70.93s
step 33300, loss 3.70, lr 0.000573, consume 70.93s
step 33400, loss 3.71, lr 0.000573, consume 70.94s
step 33500, loss 3.70, lr 0.000573, consume 70.92s
step 33600, loss 3.71, lr 0.000572, consume 70.91s
step 33700, loss 3.70, lr 0.000572, consume 70.92s
step 33800, loss 3.71, lr 0.000572, consume 70.91s
processing 25: english_c4/c4-train.00025-of-01024.txt, origin: 355713, samples: 173638, accum_tokens: 4619M, iter_num: 33887
step 33900, loss 3.70, lr 0.000572, consume 90.43s
step 34000, loss 3.70, lr 0.000572, consume 72.14s
step 34100, loss 3.70, lr 0.000572, consume 85.55s
step 34200, loss 3.70, lr 0.000571, consume 70.79s
step 34300, loss 3.69, lr 0.000571, consume 70.90s
step 34400, loss 3.69, lr 0.000571, consume 70.91s
step 34500, loss 3.70, lr 0.000571, consume 70.91s
step 34600, loss 3.70, lr 0.000571, consume 70.88s
step 34700, loss 3.69, lr 0.000571, consume 70.87s
step 34800, loss 3.69, lr 0.000570, consume 70.88s
step 34900, loss 3.70, lr 0.000570, consume 70.85s
step 35000, loss 3.69, lr 0.000570, consume 70.86s
step 35100, loss 3.70, lr 0.000570, consume 70.85s
step 35200, loss 3.69, lr 0.000570, consume 70.87s
processing 26: english_c4/c4-train.00026-of-01024.txt, origin: 355688, samples: 173072, accum_tokens: 4797M, iter_num: 35244
step 35300, loss 3.70, lr 0.000570, consume 91.15s
step 35400, loss 3.69, lr 0.000569, consume 72.81s
step 35500, loss 3.70, lr 0.000569, consume 84.22s
step 35600, loss 3.70, lr 0.000569, consume 70.83s
step 35700, loss 3.69, lr 0.000569, consume 70.87s
step 35800, loss 3.70, lr 0.000569, consume 70.89s
step 35900, loss 3.69, lr 0.000568, consume 70.89s
step 36000, loss 3.70, lr 0.000568, consume 70.88s
step 36100, loss 3.69, lr 0.000568, consume 70.87s
step 36200, loss 3.69, lr 0.000568, consume 70.87s
step 36300, loss 3.69, lr 0.000568, consume 70.85s
step 36400, loss 3.69, lr 0.000567, consume 70.87s
step 36500, loss 3.69, lr 0.000567, consume 70.87s
processing 27: english_c4/c4-train.00027-of-01024.txt, origin: 355713, samples: 174471, accum_tokens: 4975M, iter_num: 36596
step 36600, loss 3.68, lr 0.000567, consume 88.09s
step 36700, loss 3.70, lr 0.000567, consume 74.48s
step 36800, loss 3.69, lr 0.000567, consume 73.06s
step 36900, loss 3.69, lr 0.000567, consume 84.21s
step 37000, loss 3.69, lr 0.000566, consume 70.87s
step 37100, loss 3.69, lr 0.000566, consume 70.91s
step 37200, loss 3.69, lr 0.000566, consume 70.89s
step 37300, loss 3.69, lr 0.000566, consume 70.89s
step 37400, loss 3.69, lr 0.000566, consume 70.87s
step 37500, loss 3.69, lr 0.000565, consume 70.87s
step 37600, loss 3.69, lr 0.000565, consume 70.88s
step 37700, loss 3.69, lr 0.000565, consume 70.87s
step 37800, loss 3.69, lr 0.000565, consume 70.88s
step 37900, loss 3.69, lr 0.000565, consume 70.87s
processing 28: english_c4/c4-train.00028-of-01024.txt, origin: 355701, samples: 173576, accum_tokens: 5153M, iter_num: 37959
step 38000, loss 3.69, lr 0.000564, consume 90.79s
step 38100, loss 3.69, lr 0.000564, consume 72.58s
step 38200, loss 3.69, lr 0.000564, consume 85.88s
step 38300, loss 3.69, lr 0.000564, consume 70.86s
step 38400, loss 3.69, lr 0.000564, consume 70.90s
step 38500, loss 3.68, lr 0.000564, consume 70.92s
step 38600, loss 3.69, lr 0.000563, consume 70.89s
step 38700, loss 3.69, lr 0.000563, consume 70.90s
step 38800, loss 3.69, lr 0.000563, consume 70.87s
step 38900, loss 3.69, lr 0.000563, consume 70.89s
step 39000, loss 3.69, lr 0.000563, consume 70.88s
step 39100, loss 3.68, lr 0.000562, consume 70.87s
step 39200, loss 3.69, lr 0.000562, consume 70.87s
step 39300, loss 3.69, lr 0.000562, consume 70.87s
processing 29: english_c4/c4-train.00029-of-01024.txt, origin: 355707, samples: 173593, accum_tokens: 5331M, iter_num: 39315
step 39400, loss 3.69, lr 0.000562, consume 91.19s
step 39500, loss 3.68, lr 0.000562, consume 72.84s
step 39600, loss 3.69, lr 0.000561, consume 84.15s
step 39700, loss 3.68, lr 0.000561, consume 70.88s
step 39800, loss 3.68, lr 0.000561, consume 70.90s
step 39900, loss 3.68, lr 0.000561, consume 70.90s
step 40000, loss 3.69, lr 0.000561, consume 71.25s
step 40100, loss 3.68, lr 0.000560, consume 71.14s
step 40200, loss 3.67, lr 0.000560, consume 71.45s
step 40300, loss 3.68, lr 0.000560, consume 71.20s
step 40400, loss 3.69, lr 0.000560, consume 71.21s
step 40500, loss 3.69, lr 0.000560, consume 71.20s
step 40600, loss 3.68, lr 0.000559, consume 71.19s
processing 30: english_c4/c4-train.00030-of-01024.txt, origin: 355751, samples: 173202, accum_tokens: 5508M, iter_num: 40671
step 40700, loss 3.67, lr 0.000559, consume 90.83s
step 40800, loss 3.69, lr 0.000559, consume 72.56s
step 40900, loss 3.69, lr 0.000559, consume 85.94s
step 41000, loss 3.69, lr 0.000558, consume 71.13s
step 41100, loss 3.69, lr 0.000558, consume 71.23s
step 41200, loss 3.68, lr 0.000558, consume 71.23s
step 41300, loss 3.68, lr 0.000558, consume 71.24s
step 41400, loss 3.68, lr 0.000558, consume 71.21s
step 41500, loss 3.68, lr 0.000557, consume 71.22s
step 41600, loss 3.68, lr 0.000557, consume 71.21s
step 41700, loss 3.68, lr 0.000557, consume 71.22s
step 41800, loss 3.67, lr 0.000557, consume 71.20s
step 41900, loss 3.68, lr 0.000557, consume 71.20s
step 42000, loss 3.67, lr 0.000556, consume 71.21s
processing 31: english_c4/c4-train.00031-of-01024.txt, origin: 355742, samples: 173547, accum_tokens: 5686M, iter_num: 42024
step 42100, loss 3.69, lr 0.000556, consume 91.71s
step 42200, loss 3.70, lr 0.000556, consume 73.41s
step 42300, loss 3.68, lr 0.000556, consume 83.34s
step 42400, loss 3.68, lr 0.000556, consume 71.34s
step 42500, loss 3.68, lr 0.000555, consume 70.93s
step 42600, loss 3.68, lr 0.000555, consume 70.91s
step 42700, loss 3.68, lr 0.000555, consume 70.89s
step 42800, loss 3.67, lr 0.000555, consume 70.89s
step 42900, loss 3.68, lr 0.000554, consume 70.90s
step 43000, loss 3.68, lr 0.000554, consume 70.90s
step 43100, loss 3.68, lr 0.000554, consume 70.93s
step 43200, loss 3.67, lr 0.000554, consume 70.92s
step 43300, loss 3.68, lr 0.000554, consume 70.91s
processing 32: english_c4/c4-train.00032-of-01024.txt, origin: 355738, samples: 174581, accum_tokens: 5865M, iter_num: 43380
step 43400, loss 3.68, lr 0.000553, consume 90.72s
step 43500, loss 3.67, lr 0.000553, consume 72.81s
step 43600, loss 3.68, lr 0.000553, consume 84.62s
step 43700, loss 3.68, lr 0.000553, consume 70.83s
step 43800, loss 3.67, lr 0.000552, consume 71.81s
step 43900, loss 3.68, lr 0.000552, consume 71.69s
step 44000, loss 3.68, lr 0.000552, consume 71.86s
step 44100, loss 3.68, lr 0.000552, consume 71.95s
step 44200, loss 3.67, lr 0.000552, consume 74.42s
step 44300, loss 3.68, lr 0.000551, consume 72.79s
step 44400, loss 3.67, lr 0.000551, consume 71.48s
step 44500, loss 3.68, lr 0.000551, consume 71.65s
step 44600, loss 3.67, lr 0.000551, consume 75.21s
step 44700, loss 3.68, lr 0.000550, consume 74.75s
processing 33: english_c4/c4-train.00033-of-01024.txt, origin: 355671, samples: 174239, accum_tokens: 6043M, iter_num: 44743
step 44800, loss 3.67, lr 0.000550, consume 94.01s
step 44900, loss 3.68, lr 0.000550, consume 73.27s
step 45000, loss 3.68, lr 0.000550, consume 84.93s
step 45100, loss 3.68, lr 0.000550, consume 71.83s
step 45200, loss 3.67, lr 0.000549, consume 72.24s
step 45300, loss 3.67, lr 0.000549, consume 70.92s
step 45400, loss 3.68, lr 0.000549, consume 70.91s
step 45500, loss 3.68, lr 0.000549, consume 70.91s
step 45600, loss 3.68, lr 0.000548, consume 70.91s
step 45700, loss 3.67, lr 0.000548, consume 70.91s
step 45800, loss 3.68, lr 0.000548, consume 70.90s
step 45900, loss 3.68, lr 0.000548, consume 71.30s
step 46000, loss 3.67, lr 0.000548, consume 71.24s
step 46100, loss 3.66, lr 0.000547, consume 70.95s
processing 34: english_c4/c4-train.00034-of-01024.txt, origin: 355742, samples: 173538, accum_tokens: 6221M, iter_num: 46104
step 46200, loss 3.68, lr 0.000547, consume 92.87s
step 46300, loss 3.67, lr 0.000547, consume 73.44s
step 46400, loss 3.66, lr 0.000547, consume 83.18s
step 46500, loss 3.67, lr 0.000546, consume 70.89s
step 46600, loss 3.67, lr 0.000546, consume 70.93s
step 46700, loss 3.67, lr 0.000546, consume 70.93s
step 46800, loss 3.68, lr 0.000546, consume 70.92s
step 46900, loss 3.67, lr 0.000545, consume 70.88s
step 47000, loss 3.67, lr 0.000545, consume 70.88s
step 47100, loss 3.67, lr 0.000545, consume 70.88s
step 47200, loss 3.67, lr 0.000545, consume 70.90s
step 47300, loss 3.67, lr 0.000544, consume 70.90s
step 47400, loss 3.66, lr 0.000544, consume 70.88s
processing 35: english_c4/c4-train.00035-of-01024.txt, origin: 355715, samples: 173348, accum_tokens: 6398M, iter_num: 47460
step 47500, loss 3.67, lr 0.000544, consume 90.82s
step 47600, loss 3.67, lr 0.000544, consume 72.75s
step 47700, loss 3.68, lr 0.000544, consume 84.47s
step 47800, loss 3.67, lr 0.000543, consume 70.84s
step 47900, loss 3.68, lr 0.000543, consume 70.90s
step 48000, loss 3.67, lr 0.000543, consume 70.90s
step 48100, loss 3.67, lr 0.000543, consume 70.89s
step 48200, loss 3.67, lr 0.000542, consume 70.90s
step 48300, loss 3.67, lr 0.000542, consume 70.88s
step 48400, loss 3.67, lr 0.000542, consume 71.48s
step 48500, loss 3.67, lr 0.000542, consume 70.87s
step 48600, loss 3.67, lr 0.000541, consume 70.94s
step 48700, loss 3.68, lr 0.000541, consume 70.87s
step 48800, loss 3.67, lr 0.000541, consume 70.88s
processing 36: english_c4/c4-train.00036-of-01024.txt, origin: 355725, samples: 173573, accum_tokens: 6576M, iter_num: 48814
step 48900, loss 3.68, lr 0.000541, consume 91.48s
step 49000, loss 3.67, lr 0.000540, consume 73.91s
step 49100, loss 3.67, lr 0.000540, consume 83.06s
step 49200, loss 3.67, lr 0.000540, consume 70.93s
step 49300, loss 3.66, lr 0.000540, consume 70.96s
step 49400, loss 3.66, lr 0.000539, consume 70.94s
step 49500, loss 3.66, lr 0.000539, consume 70.93s
step 49600, loss 3.67, lr 0.000539, consume 70.93s
step 49700, loss 3.66, lr 0.000539, consume 70.92s
step 49800, loss 3.67, lr 0.000538, consume 70.91s
step 49900, loss 3.66, lr 0.000538, consume 70.92s
step 50000, loss 3.66, lr 0.000538, consume 70.92s
step 50100, loss 3.66, lr 0.000538, consume 70.91s
processing 37: english_c4/c4-train.00037-of-01024.txt, origin: 355760, samples: 174025, accum_tokens: 6754M, iter_num: 50170
step 50200, loss 3.67, lr 0.000537, consume 90.52s
step 50300, loss 3.68, lr 0.000537, consume 72.81s
step 50400, loss 3.67, lr 0.000537, consume 85.91s
step 50500, loss 3.67, lr 0.000537, consume 70.87s
step 50600, loss 3.67, lr 0.000536, consume 70.95s
step 50700, loss 3.67, lr 0.000536, consume 70.94s
step 50800, loss 3.67, lr 0.000536, consume 70.94s
step 50900, loss 3.68, lr 0.000536, consume 70.92s
step 51000, loss 3.66, lr 0.000535, consume 70.92s
step 51100, loss 3.67, lr 0.000535, consume 70.92s
step 51200, loss 3.67, lr 0.000535, consume 70.90s
step 51300, loss 3.66, lr 0.000535, consume 70.91s
step 51400, loss 3.67, lr 0.000534, consume 70.90s
step 51500, loss 3.66, lr 0.000534, consume 70.91s
processing 38: english_c4/c4-train.00038-of-01024.txt, origin: 355686, samples: 173172, accum_tokens: 6932M, iter_num: 51530
step 51600, loss 3.66, lr 0.000534, consume 91.47s
step 51700, loss 3.66, lr 0.000534, consume 72.91s
step 51800, loss 3.67, lr 0.000533, consume 84.33s
step 51900, loss 3.66, lr 0.000533, consume 70.88s
step 52000, loss 3.66, lr 0.000533, consume 70.90s
step 52100, loss 3.66, lr 0.000533, consume 70.91s
step 52200, loss 3.66, lr 0.000532, consume 70.89s
step 52300, loss 3.66, lr 0.000532, consume 70.88s
step 52400, loss 3.66, lr 0.000532, consume 70.87s
step 52500, loss 3.66, lr 0.000532, consume 70.87s
step 52600, loss 3.66, lr 0.000531, consume 70.88s
step 52700, loss 3.66, lr 0.000531, consume 70.86s
step 52800, loss 3.66, lr 0.000531, consume 70.87s
processing 39: english_c4/c4-train.00039-of-01024.txt, origin: 355723, samples: 174130, accum_tokens: 7110M, iter_num: 52883
step 52900, loss 3.66, lr 0.000531, consume 90.54s
step 53000, loss 3.67, lr 0.000530, consume 72.28s
step 53100, loss 3.68, lr 0.000530, consume 85.44s
step 53200, loss 3.67, lr 0.000530, consume 70.80s
step 53300, loss 3.66, lr 0.000530, consume 70.89s
step 53400, loss 3.67, lr 0.000529, consume 70.91s
step 53500, loss 3.67, lr 0.000529, consume 70.91s
step 53600, loss 3.67, lr 0.000529, consume 70.89s
step 53700, loss 3.66, lr 0.000528, consume 70.87s
step 53800, loss 3.67, lr 0.000528, consume 70.88s
step 53900, loss 3.66, lr 0.000528, consume 70.88s
step 54000, loss 3.66, lr 0.000528, consume 70.89s
step 54100, loss 3.66, lr 0.000527, consume 70.87s
step 54200, loss 3.66, lr 0.000527, consume 70.87s
processing 40: english_c4/c4-train.00040-of-01024.txt, origin: 355743, samples: 174205, accum_tokens: 7288M, iter_num: 54243
step 54300, loss 3.66, lr 0.000527, consume 91.10s
step 54400, loss 3.67, lr 0.000527, consume 72.76s
step 54500, loss 3.67, lr 0.000526, consume 84.35s
step 54600, loss 3.66, lr 0.000526, consume 70.88s
step 54700, loss 3.65, lr 0.000526, consume 70.94s
step 54800, loss 3.67, lr 0.000526, consume 70.94s
step 54900, loss 3.66, lr 0.000525, consume 70.94s
step 55000, loss 3.66, lr 0.000525, consume 70.94s
step 55100, loss 3.66, lr 0.000525, consume 70.92s
step 55200, loss 3.66, lr 0.000524, consume 70.90s
step 55300, loss 3.66, lr 0.000524, consume 70.91s
step 55400, loss 3.66, lr 0.000524, consume 70.90s
step 55500, loss 3.66, lr 0.000524, consume 70.91s
step 55600, loss 3.65, lr 0.000523, consume 70.91s
processing 41: english_c4/c4-train.00041-of-01024.txt, origin: 355732, samples: 173841, accum_tokens: 7466M, iter_num: 55604
step 55700, loss 3.67, lr 0.000523, consume 91.35s
step 55800, loss 3.67, lr 0.000523, consume 73.14s
step 55900, loss 3.66, lr 0.000523, consume 83.12s
step 56000, loss 3.66, lr 0.000522, consume 70.94s
step 56100, loss 3.67, lr 0.000522, consume 70.97s
step 56200, loss 3.67, lr 0.000522, consume 70.98s
step 56300, loss 3.65, lr 0.000521, consume 70.98s
step 56400, loss 3.67, lr 0.000521, consume 70.96s
step 56500, loss 3.67, lr 0.000521, consume 70.95s
step 56600, loss 3.66, lr 0.000521, consume 70.93s
step 56700, loss 3.66, lr 0.000520, consume 70.94s
step 56800, loss 3.65, lr 0.000520, consume 70.93s
step 56900, loss 3.66, lr 0.000520, consume 70.93s
processing 42: english_c4/c4-train.00042-of-01024.txt, origin: 355693, samples: 172927, accum_tokens: 7643M, iter_num: 56962
step 57000, loss 3.66, lr 0.000520, consume 90.99s
step 57100, loss 3.67, lr 0.000519, consume 72.62s
step 57200, loss 3.67, lr 0.000519, consume 84.36s
step 57300, loss 3.66, lr 0.000519, consume 70.87s
step 57400, loss 3.66, lr 0.000518, consume 70.96s
step 57500, loss 3.65, lr 0.000518, consume 70.97s
step 57600, loss 3.66, lr 0.000518, consume 70.96s
step 57700, loss 3.67, lr 0.000518, consume 70.97s
step 57800, loss 3.66, lr 0.000517, consume 70.96s
step 57900, loss 3.66, lr 0.000517, consume 70.94s
step 58000, loss 3.65, lr 0.000517, consume 70.93s
step 58100, loss 3.66, lr 0.000516, consume 70.93s
step 58200, loss 3.65, lr 0.000516, consume 70.93s
step 58300, loss 3.66, lr 0.000516, consume 70.94s
processing 43: english_c4/c4-train.00043-of-01024.txt, origin: 355728, samples: 172642, accum_tokens: 7820M, iter_num: 58312
step 58400, loss 3.66, lr 0.000516, consume 91.51s
step 58500, loss 3.67, lr 0.000515, consume 73.24s
step 58600, loss 3.66, lr 0.000515, consume 83.28s
step 58700, loss 3.66, lr 0.000515, consume 70.95s
step 58800, loss 3.66, lr 0.000514, consume 70.95s
step 58900, loss 3.67, lr 0.000514, consume 70.95s
step 59000, loss 3.66, lr 0.000514, consume 70.95s
step 59100, loss 3.66, lr 0.000514, consume 70.94s
step 59200, loss 3.66, lr 0.000513, consume 70.92s
step 59300, loss 3.65, lr 0.000513, consume 70.93s
step 59400, loss 3.66, lr 0.000513, consume 70.92s
step 59500, loss 3.66, lr 0.000512, consume 70.93s
step 59600, loss 3.65, lr 0.000512, consume 70.94s
processing 44: english_c4/c4-train.00044-of-01024.txt, origin: 355718, samples: 173521, accum_tokens: 7998M, iter_num: 59661
step 59700, loss 3.65, lr 0.000512, consume 91.47s
step 59800, loss 3.66, lr 0.000512, consume 73.21s
step 59900, loss 3.66, lr 0.000511, consume 84.31s
step 60000, loss 3.65, lr 0.000511, consume 70.85s
step 60100, loss 3.65, lr 0.000511, consume 70.93s
step 60200, loss 3.65, lr 0.000510, consume 70.94s
step 60300, loss 3.65, lr 0.000510, consume 70.91s
step 60400, loss 3.65, lr 0.000510, consume 70.90s
step 60500, loss 3.65, lr 0.000510, consume 70.90s
step 60600, loss 3.65, lr 0.000509, consume 70.89s
step 60700, loss 3.66, lr 0.000509, consume 70.91s
step 60800, loss 3.65, lr 0.000509, consume 70.91s
step 60900, loss 3.65, lr 0.000508, consume 70.90s
step 61000, loss 3.65, lr 0.000508, consume 70.88s
processing 45: english_c4/c4-train.00045-of-01024.txt, origin: 355708, samples: 173877, accum_tokens: 8176M, iter_num: 61017
step 61100, loss 3.66, lr 0.000508, consume 91.48s
step 61200, loss 3.67, lr 0.000508, consume 73.11s
step 61300, loss 3.65, lr 0.000507, consume 83.22s
step 61400, loss 3.66, lr 0.000507, consume 71.27s
step 61500, loss 3.65, lr 0.000507, consume 70.95s
step 61600, loss 3.65, lr 0.000506, consume 70.95s
step 61700, loss 3.65, lr 0.000506, consume 70.96s
step 61800, loss 3.65, lr 0.000506, consume 70.93s
step 61900, loss 3.65, lr 0.000506, consume 70.93s
step 62000, loss 3.65, lr 0.000505, consume 70.93s
step 62100, loss 3.66, lr 0.000505, consume 70.93s
step 62200, loss 3.65, lr 0.000505, consume 70.93s
step 62300, loss 3.65, lr 0.000504, consume 70.95s
processing 46: english_c4/c4-train.00046-of-01024.txt, origin: 355711, samples: 173463, accum_tokens: 8354M, iter_num: 62375
step 62400, loss 3.65, lr 0.000504, consume 90.89s
step 62500, loss 3.65, lr 0.000504, consume 72.91s
step 62600, loss 3.65, lr 0.000503, consume 84.65s
step 62700, loss 3.65, lr 0.000503, consume 70.91s
step 62800, loss 3.66, lr 0.000503, consume 70.99s
step 62900, loss 3.66, lr 0.000503, consume 70.99s
step 63000, loss 3.66, lr 0.000502, consume 71.01s
step 63100, loss 3.66, lr 0.000502, consume 70.99s
step 63200, loss 3.65, lr 0.000502, consume 70.97s
step 63300, loss 3.65, lr 0.000501, consume 70.96s
step 63400, loss 3.64, lr 0.000501, consume 70.96s
step 63500, loss 3.65, lr 0.000501, consume 70.97s
step 63600, loss 3.65, lr 0.000500, consume 70.97s
step 63700, loss 3.64, lr 0.000500, consume 70.95s
processing 47: english_c4/c4-train.00047-of-01024.txt, origin: 355731, samples: 172936, accum_tokens: 8531M, iter_num: 63730
step 63800, loss 3.66, lr 0.000500, consume 91.31s
step 63900, loss 3.65, lr 0.000500, consume 72.79s
step 64000, loss 3.65, lr 0.000499, consume 84.40s
step 64100, loss 3.65, lr 0.000499, consume 70.94s
step 64200, loss 3.65, lr 0.000499, consume 70.98s
step 64300, loss 3.65, lr 0.000498, consume 70.99s
step 64400, loss 3.64, lr 0.000498, consume 70.97s
step 64500, loss 3.66, lr 0.000498, consume 70.96s
step 64600, loss 3.65, lr 0.000497, consume 70.96s
step 64700, loss 3.65, lr 0.000497, consume 70.95s
step 64800, loss 3.64, lr 0.000497, consume 70.97s
step 64900, loss 3.64, lr 0.000496, consume 70.97s
step 65000, loss 3.65, lr 0.000496, consume 70.98s
processing 48: english_c4/c4-train.00048-of-01024.txt, origin: 355721, samples: 172684, accum_tokens: 8707M, iter_num: 65081
step 65100, loss 3.64, lr 0.000496, consume 91.22s
step 65200, loss 3.65, lr 0.000496, consume 72.27s
step 65300, loss 3.65, lr 0.000495, consume 85.33s
step 65400, loss 3.65, lr 0.000495, consume 70.84s
step 65500, loss 3.65, lr 0.000495, consume 70.95s
step 65600, loss 3.65, lr 0.000494, consume 70.95s
step 65700, loss 3.65, lr 0.000494, consume 70.94s
step 65800, loss 3.65, lr 0.000494, consume 70.93s
step 65900, loss 3.64, lr 0.000493, consume 70.93s
step 66000, loss 3.66, lr 0.000493, consume 70.93s
step 66100, loss 3.65, lr 0.000493, consume 70.91s
step 66200, loss 3.65, lr 0.000492, consume 70.91s
step 66300, loss 3.65, lr 0.000492, consume 70.92s
step 66400, loss 3.65, lr 0.000492, consume 70.93s
processing 49: english_c4/c4-train.00049-of-01024.txt, origin: 355716, samples: 173827, accum_tokens: 8885M, iter_num: 66430
step 66500, loss 3.65, lr 0.000492, consume 91.20s
step 66600, loss 3.65, lr 0.000491, consume 72.93s
step 66700, loss 3.65, lr 0.000491, consume 84.49s
step 66800, loss 3.64, lr 0.000491, consume 70.91s
step 66900, loss 3.65, lr 0.000490, consume 70.96s
step 67000, loss 3.64, lr 0.000490, consume 70.94s
step 67100, loss 3.65, lr 0.000490, consume 70.93s
step 67200, loss 3.64, lr 0.000489, consume 70.93s
step 67300, loss 3.64, lr 0.000489, consume 70.92s
step 67400, loss 3.64, lr 0.000489, consume 70.93s
step 67500, loss 3.64, lr 0.000488, consume 70.91s
step 67600, loss 3.64, lr 0.000488, consume 70.93s
step 67700, loss 3.63, lr 0.000488, consume 70.91s
processing 50: english_c4/c4-train.00050-of-01024.txt, origin: 355718, samples: 172909, accum_tokens: 9062M, iter_num: 67788
step 67800, loss 3.64, lr 0.000487, consume 90.63s
step 67900, loss 3.65, lr 0.000487, consume 72.28s
step 68000, loss 3.65, lr 0.000487, consume 85.38s
step 68100, loss 3.65, lr 0.000486, consume 70.84s
step 68200, loss 3.65, lr 0.000486, consume 70.98s
step 68300, loss 3.65, lr 0.000486, consume 71.01s
step 68400, loss 3.64, lr 0.000486, consume 70.98s
step 68500, loss 3.65, lr 0.000485, consume 70.98s
step 68600, loss 3.64, lr 0.000485, consume 70.97s
step 68700, loss 3.64, lr 0.000485, consume 70.97s
step 68800, loss 3.64, lr 0.000484, consume 70.96s
step 68900, loss 3.65, lr 0.000484, consume 70.96s
step 69000, loss 3.65, lr 0.000484, consume 70.95s
step 69100, loss 3.65, lr 0.000483, consume 70.93s
processing 51: english_c4/c4-train.00051-of-01024.txt, origin: 355672, samples: 173579, accum_tokens: 9240M, iter_num: 69139
step 69200, loss 3.65, lr 0.000483, consume 91.14s
step 69300, loss 3.64, lr 0.000483, consume 73.50s
step 69400, loss 3.64, lr 0.000482, consume 84.33s
step 69500, loss 3.64, lr 0.000482, consume 70.90s
step 69600, loss 3.63, lr 0.000482, consume 70.99s
step 69700, loss 3.64, lr 0.000481, consume 70.97s
step 69800, loss 3.64, lr 0.000481, consume 70.98s
step 69900, loss 3.64, lr 0.000481, consume 70.96s
step 70000, loss 3.64, lr 0.000480, consume 70.93s
step 70100, loss 3.64, lr 0.000480, consume 70.96s
step 70200, loss 3.64, lr 0.000480, consume 71.01s
step 70300, loss 3.65, lr 0.000479, consume 70.95s
step 70400, loss 3.64, lr 0.000479, consume 70.94s
processing 52: english_c4/c4-train.00052-of-01024.txt, origin: 355741, samples: 174645, accum_tokens: 9419M, iter_num: 70495
step 70500, loss 3.63, lr 0.000479, consume 88.19s
step 70600, loss 3.65, lr 0.000478, consume 74.99s
step 70700, loss 3.64, lr 0.000478, consume 73.49s
step 70800, loss 3.65, lr 0.000478, consume 82.93s
step 70900, loss 3.65, lr 0.000477, consume 70.95s
step 71000, loss 3.64, lr 0.000477, consume 70.98s
step 71100, loss 3.64, lr 0.000477, consume 70.95s
step 71200, loss 3.64, lr 0.000477, consume 70.95s
step 71300, loss 3.64, lr 0.000476, consume 70.95s
step 71400, loss 3.64, lr 0.000476, consume 70.96s
step 71500, loss 3.63, lr 0.000476, consume 70.97s
step 71600, loss 3.64, lr 0.000475, consume 70.94s
step 71700, loss 3.64, lr 0.000475, consume 70.97s
step 71800, loss 3.64, lr 0.000475, consume 70.95s
processing 53: english_c4/c4-train.00053-of-01024.txt, origin: 355705, samples: 174657, accum_tokens: 9598M, iter_num: 71859
step 71900, loss 3.64, lr 0.000474, consume 90.51s
step 72000, loss 3.65, lr 0.000474, consume 72.30s
step 72100, loss 3.64, lr 0.000474, consume 85.38s
step 72200, loss 3.64, lr 0.000473, consume 70.90s
step 72300, loss 3.64, lr 0.000473, consume 70.98s
step 72400, loss 3.64, lr 0.000473, consume 70.99s
step 72500, loss 3.63, lr 0.000472, consume 70.98s
step 72600, loss 3.63, lr 0.000472, consume 70.96s
step 72700, loss 3.64, lr 0.000472, consume 70.95s
step 72800, loss 3.64, lr 0.000471, consume 70.97s
step 72900, loss 3.63, lr 0.000471, consume 70.97s
step 73000, loss 3.63, lr 0.000471, consume 70.96s
step 73100, loss 3.64, lr 0.000470, consume 70.97s
step 73200, loss 3.64, lr 0.000470, consume 70.97s
processing 54: english_c4/c4-train.00054-of-01024.txt, origin: 355738, samples: 174513, accum_tokens: 9777M, iter_num: 73223
step 73300, loss 3.64, lr 0.000470, consume 91.11s
step 73400, loss 3.64, lr 0.000469, consume 73.66s
step 73500, loss 3.64, lr 0.000469, consume 83.21s
step 73600, loss 3.64, lr 0.000469, consume 70.96s
step 73700, loss 3.64, lr 0.000468, consume 70.99s
step 73800, loss 3.64, lr 0.000468, consume 71.00s
step 73900, loss 3.64, lr 0.000468, consume 70.97s
step 74000, loss 3.63, lr 0.000467, consume 70.98s
step 74100, loss 3.64, lr 0.000467, consume 70.98s
step 74200, loss 3.63, lr 0.000467, consume 70.96s
step 74300, loss 3.63, lr 0.000466, consume 70.97s
step 74400, loss 3.64, lr 0.000466, consume 70.97s
step 74500, loss 3.63, lr 0.000466, consume 70.95s
processing 55: english_c4/c4-train.00055-of-01024.txt, origin: 355762, samples: 173354, accum_tokens: 9954M, iter_num: 74587
step 74600, loss 3.63, lr 0.000465, consume 90.59s
step 74700, loss 3.64, lr 0.000465, consume 72.38s
step 74800, loss 3.64, lr 0.000465, consume 85.51s
step 74900, loss 3.64, lr 0.000464, consume 70.84s
step 75000, loss 3.64, lr 0.000464, consume 70.92s
step 75100, loss 3.64, lr 0.000464, consume 70.94s
step 75200, loss 3.64, lr 0.000463, consume 70.94s
step 75300, loss 3.63, lr 0.000463, consume 70.92s
step 75400, loss 3.63, lr 0.000463, consume 70.94s
step 75500, loss 3.64, lr 0.000462, consume 70.92s
step 75600, loss 3.64, lr 0.000462, consume 70.93s
step 75700, loss 3.65, lr 0.000462, consume 70.92s
step 75800, loss 3.63, lr 0.000461, consume 70.93s
step 75900, loss 3.64, lr 0.000461, consume 70.93s
processing 56: english_c4/c4-train.00056-of-01024.txt, origin: 355728, samples: 173929, accum_tokens: 10132M, iter_num: 75941
step 76000, loss 3.64, lr 0.000460, consume 90.89s
step 76100, loss 3.63, lr 0.000460, consume 73.41s
step 76200, loss 3.64, lr 0.000460, consume 84.35s
step 76300, loss 3.64, lr 0.000459, consume 70.89s
step 76400, loss 3.64, lr 0.000459, consume 70.94s
step 76500, loss 3.64, lr 0.000459, consume 70.93s
step 76600, loss 3.63, lr 0.000458, consume 71.01s
step 76700, loss 3.63, lr 0.000458, consume 71.10s
step 76800, loss 3.63, lr 0.000458, consume 71.12s
step 76900, loss 3.63, lr 0.000457, consume 71.15s
step 77000, loss 3.63, lr 0.000457, consume 70.92s
step 77100, loss 3.63, lr 0.000457, consume 70.93s
step 77200, loss 3.64, lr 0.000456, consume 70.92s
step 77300, loss 3.63, lr 0.000456, consume 70.92s
processing 57: english_c4/c4-train.00057-of-01024.txt, origin: 355709, samples: 174072, accum_tokens: 10310M, iter_num: 77300
step 77400, loss 3.64, lr 0.000456, consume 92.24s
step 77500, loss 3.64, lr 0.000455, consume 73.24s
step 77600, loss 3.63, lr 0.000455, consume 83.44s
step 77700, loss 3.64, lr 0.000455, consume 70.97s
step 77800, loss 3.63, lr 0.000454, consume 70.98s
step 77900, loss 3.63, lr 0.000454, consume 70.98s
step 78000, loss 3.63, lr 0.000454, consume 70.99s
step 78100, loss 3.63, lr 0.000453, consume 70.98s
step 78200, loss 3.64, lr 0.000453, consume 71.00s
step 78300, loss 3.64, lr 0.000453, consume 70.97s
step 78400, loss 3.63, lr 0.000452, consume 70.95s
step 78500, loss 3.63, lr 0.000452, consume 70.96s
step 78600, loss 3.63, lr 0.000452, consume 70.96s
processing 58: english_c4/c4-train.00058-of-01024.txt, origin: 355737, samples: 173163, accum_tokens: 10488M, iter_num: 78659
step 78700, loss 3.64, lr 0.000451, consume 90.56s
step 78800, loss 3.64, lr 0.000451, consume 72.43s
step 78900, loss 3.63, lr 0.000450, consume 85.71s
step 79000, loss 3.64, lr 0.000450, consume 70.90s
step 79100, loss 3.64, lr 0.000450, consume 70.99s
step 79200, loss 3.64, lr 0.000449, consume 70.99s
step 79300, loss 3.63, lr 0.000449, consume 70.99s
step 79400, loss 3.63, lr 0.000449, consume 70.98s
step 79500, loss 3.63, lr 0.000448, consume 70.98s
step 79600, loss 3.64, lr 0.000448, consume 70.98s
step 79700, loss 3.62, lr 0.000448, consume 70.97s
step 79800, loss 3.63, lr 0.000447, consume 70.96s
step 79900, loss 3.63, lr 0.000447, consume 70.96s
step 80000, loss 3.64, lr 0.000447, consume 70.96s
processing 59: english_c4/c4-train.00059-of-01024.txt, origin: 355712, samples: 173027, accum_tokens: 10665M, iter_num: 80012
step 80100, loss 3.64, lr 0.000446, consume 91.82s
step 80200, loss 3.63, lr 0.000446, consume 73.34s
step 80300, loss 3.64, lr 0.000446, consume 84.61s
step 80400, loss 3.63, lr 0.000445, consume 71.00s
step 80500, loss 3.63, lr 0.000445, consume 71.04s
step 80600, loss 3.63, lr 0.000445, consume 71.01s
step 80700, loss 3.63, lr 0.000444, consume 71.01s
step 80800, loss 3.62, lr 0.000444, consume 71.00s
step 80900, loss 3.63, lr 0.000443, consume 71.00s
step 81000, loss 3.62, lr 0.000443, consume 71.29s
step 81100, loss 3.63, lr 0.000443, consume 72.35s
step 81200, loss 3.62, lr 0.000442, consume 71.80s
step 81300, loss 3.62, lr 0.000442, consume 70.98s
processing 60: english_c4/c4-train.00060-of-01024.txt, origin: 355761, samples: 172895, accum_tokens: 10842M, iter_num: 81364
step 81400, loss 3.63, lr 0.000442, consume 90.73s
step 81500, loss 3.63, lr 0.000441, consume 73.17s
step 81600, loss 3.64, lr 0.000441, consume 84.42s
step 81700, loss 3.63, lr 0.000441, consume 70.86s
step 81800, loss 3.63, lr 0.000440, consume 71.00s
step 81900, loss 3.62, lr 0.000440, consume 71.01s
step 82000, loss 3.63, lr 0.000440, consume 71.00s
step 82100, loss 3.63, lr 0.000439, consume 70.99s
step 82200, loss 3.63, lr 0.000439, consume 70.98s
step 82300, loss 3.63, lr 0.000439, consume 70.97s
step 82400, loss 3.63, lr 0.000438, consume 70.97s
step 82500, loss 3.62, lr 0.000438, consume 70.96s
step 82600, loss 3.63, lr 0.000437, consume 70.98s
step 82700, loss 3.62, lr 0.000437, consume 70.98s
processing 61: english_c4/c4-train.00061-of-01024.txt, origin: 355653, samples: 173587, accum_tokens: 11020M, iter_num: 82714
step 82800, loss 3.63, lr 0.000437, consume 91.57s
step 82900, loss 3.63, lr 0.000436, consume 73.00s
step 83000, loss 3.63, lr 0.000436, consume 84.14s
step 83100, loss 3.63, lr 0.000436, consume 70.97s
step 83200, loss 3.63, lr 0.000435, consume 71.02s
step 83300, loss 3.63, lr 0.000435, consume 71.04s
step 83400, loss 3.62, lr 0.000435, consume 71.00s
step 83500, loss 3.62, lr 0.000434, consume 70.99s
step 83600, loss 3.62, lr 0.000434, consume 70.99s
step 83700, loss 3.62, lr 0.000434, consume 70.98s
step 83800, loss 3.62, lr 0.000433, consume 70.99s
step 83900, loss 3.63, lr 0.000433, consume 70.99s
step 84000, loss 3.62, lr 0.000432, consume 70.97s
processing 62: english_c4/c4-train.00062-of-01024.txt, origin: 355695, samples: 173559, accum_tokens: 11197M, iter_num: 84070
step 84100, loss 3.62, lr 0.000432, consume 90.42s
step 84200, loss 3.63, lr 0.000432, consume 72.26s
step 84300, loss 3.63, lr 0.000431, consume 85.23s
step 84400, loss 3.62, lr 0.000431, consume 70.91s
step 84500, loss 3.62, lr 0.000431, consume 70.97s
step 84600, loss 3.63, lr 0.000430, consume 70.99s
step 84700, loss 3.63, lr 0.000430, consume 70.98s
step 84800, loss 3.63, lr 0.000430, consume 70.98s
step 84900, loss 3.63, lr 0.000429, consume 71.00s
step 85000, loss 3.63, lr 0.000429, consume 70.98s
step 85100, loss 3.63, lr 0.000428, consume 70.98s
step 85200, loss 3.62, lr 0.000428, consume 70.96s
step 85300, loss 3.62, lr 0.000428, consume 70.93s
step 85400, loss 3.62, lr 0.000427, consume 70.94s
processing 63: english_c4/c4-train.00063-of-01024.txt, origin: 355702, samples: 173212, accum_tokens: 11375M, iter_num: 85426
step 85500, loss 3.63, lr 0.000427, consume 91.13s
step 85600, loss 3.63, lr 0.000427, consume 72.74s
step 85700, loss 3.63, lr 0.000426, consume 84.43s
step 85800, loss 3.63, lr 0.000426, consume 70.94s
step 85900, loss 3.63, lr 0.000426, consume 70.99s
step 86000, loss 3.63, lr 0.000425, consume 71.00s
step 86100, loss 3.62, lr 0.000425, consume 70.97s
step 86200, loss 3.63, lr 0.000424, consume 70.96s
step 86300, loss 3.63, lr 0.000424, consume 70.95s
step 86400, loss 3.61, lr 0.000424, consume 70.94s
step 86500, loss 3.62, lr 0.000423, consume 70.95s
step 86600, loss 3.62, lr 0.000423, consume 70.94s
step 86700, loss 3.62, lr 0.000423, consume 70.94s
processing 64: english_c4/c4-train.00064-of-01024.txt, origin: 355669, samples: 173600, accum_tokens: 11553M, iter_num: 86779
step 86800, loss 3.62, lr 0.000422, consume 90.75s
step 86900, loss 3.63, lr 0.000422, consume 72.58s
step 87000, loss 3.63, lr 0.000422, consume 85.57s
step 87100, loss 3.62, lr 0.000421, consume 70.88s
step 87200, loss 3.62, lr 0.000421, consume 70.97s
step 87300, loss 3.62, lr 0.000420, consume 70.99s
step 87400, loss 3.63, lr 0.000420, consume 70.99s
step 87500, loss 3.62, lr 0.000420, consume 70.96s
step 87600, loss 3.63, lr 0.000419, consume 70.96s
step 87700, loss 3.62, lr 0.000419, consume 70.97s
step 87800, loss 3.62, lr 0.000419, consume 70.94s
step 87900, loss 3.61, lr 0.000418, consume 70.95s
step 88000, loss 3.62, lr 0.000418, consume 70.94s
step 88100, loss 3.62, lr 0.000417, consume 71.00s
processing 65: english_c4/c4-train.00065-of-01024.txt, origin: 355739, samples: 174137, accum_tokens: 11731M, iter_num: 88135
step 88200, loss 3.63, lr 0.000417, consume 91.50s
step 88300, loss 3.62, lr 0.000417, consume 72.86s
step 88400, loss 3.62, lr 0.000416, consume 84.69s
step 88500, loss 3.62, lr 0.000416, consume 70.92s
step 88600, loss 3.63, lr 0.000416, consume 70.99s
step 88700, loss 3.63, lr 0.000415, consume 70.98s
step 88800, loss 3.61, lr 0.000415, consume 70.98s
step 88900, loss 3.62, lr 0.000415, consume 70.96s
step 89000, loss 3.62, lr 0.000414, consume 70.96s
step 89100, loss 3.62, lr 0.000414, consume 70.96s
step 89200, loss 3.61, lr 0.000413, consume 70.95s
step 89300, loss 3.62, lr 0.000413, consume 71.03s
step 89400, loss 3.61, lr 0.000413, consume 70.95s
processing 66: english_c4/c4-train.00066-of-01024.txt, origin: 355688, samples: 174665, accum_tokens: 11910M, iter_num: 89496
step 89500, loss 3.62, lr 0.000412, consume 87.83s
step 89600, loss 3.63, lr 0.000412, consume 74.86s
step 89700, loss 3.62, lr 0.000412, consume 73.34s
step 89800, loss 3.62, lr 0.000411, consume 82.79s
step 89900, loss 3.61, lr 0.000411, consume 70.95s
step 90000, loss 3.61, lr 0.000410, consume 70.98s
step 90100, loss 3.61, lr 0.000410, consume 70.97s
step 90200, loss 3.61, lr 0.000410, consume 70.95s
step 90300, loss 3.61, lr 0.000409, consume 70.94s
step 90400, loss 3.61, lr 0.000409, consume 70.95s
step 90500, loss 3.60, lr 0.000409, consume 70.94s
step 90600, loss 3.61, lr 0.000408, consume 70.92s
step 90700, loss 3.61, lr 0.000408, consume 70.94s
step 90800, loss 3.61, lr 0.000407, consume 70.92s
processing 67: english_c4/c4-train.00067-of-01024.txt, origin: 355732, samples: 173614, accum_tokens: 12088M, iter_num: 90860
step 90900, loss 3.62, lr 0.000407, consume 91.02s
step 91000, loss 3.63, lr 0.000407, consume 73.23s
step 91100, loss 3.62, lr 0.000406, consume 84.39s
step 91200, loss 3.62, lr 0.000406, consume 70.85s
step 91300, loss 3.62, lr 0.000406, consume 70.93s
step 91400, loss 3.62, lr 0.000405, consume 70.91s
step 91500, loss 3.62, lr 0.000405, consume 70.90s
step 91600, loss 3.62, lr 0.000405, consume 70.91s
step 91700, loss 3.62, lr 0.000404, consume 70.89s
step 91800, loss 3.62, lr 0.000404, consume 70.91s
step 91900, loss 3.62, lr 0.000403, consume 70.89s
step 92000, loss 3.62, lr 0.000403, consume 70.90s
step 92100, loss 3.62, lr 0.000403, consume 70.89s
step 92200, loss 3.62, lr 0.000402, consume 70.89s
processing 68: english_c4/c4-train.00068-of-01024.txt, origin: 355711, samples: 173483, accum_tokens: 12265M, iter_num: 92216
step 92300, loss 3.62, lr 0.000402, consume 91.58s
step 92400, loss 3.62, lr 0.000402, consume 73.16s
step 92500, loss 3.62, lr 0.000401, consume 82.99s
step 92600, loss 3.62, lr 0.000401, consume 70.94s
step 92700, loss 3.62, lr 0.000400, consume 70.98s
step 92800, loss 3.62, lr 0.000400, consume 70.97s
step 92900, loss 3.61, lr 0.000400, consume 70.97s
step 93000, loss 3.61, lr 0.000399, consume 70.99s
step 93100, loss 3.61, lr 0.000399, consume 70.98s
step 93200, loss 3.61, lr 0.000399, consume 70.98s
step 93300, loss 3.61, lr 0.000398, consume 70.99s
step 93400, loss 3.61, lr 0.000398, consume 70.99s
step 93500, loss 3.62, lr 0.000397, consume 71.00s
processing 69: english_c4/c4-train.00069-of-01024.txt, origin: 355698, samples: 173842, accum_tokens: 12443M, iter_num: 93572
step 93600, loss 3.62, lr 0.000397, consume 90.99s
step 93700, loss 3.62, lr 0.000397, consume 72.34s
step 93800, loss 3.62, lr 0.000396, consume 85.30s
step 93900, loss 3.62, lr 0.000396, consume 70.86s
step 94000, loss 3.62, lr 0.000395, consume 71.01s
step 94100, loss 3.60, lr 0.000395, consume 71.03s
step 94200, loss 3.62, lr 0.000395, consume 71.02s
step 94300, loss 3.62, lr 0.000394, consume 71.01s
step 94400, loss 3.62, lr 0.000394, consume 71.01s
step 94500, loss 3.61, lr 0.000394, consume 70.98s
step 94600, loss 3.61, lr 0.000393, consume 70.98s
step 94700, loss 3.61, lr 0.000393, consume 70.97s
step 94800, loss 3.61, lr 0.000392, consume 70.97s
step 94900, loss 3.61, lr 0.000392, consume 70.99s
processing 70: english_c4/c4-train.00070-of-01024.txt, origin: 355769, samples: 173545, accum_tokens: 12621M, iter_num: 94930
step 95000, loss 3.62, lr 0.000392, consume 90.98s
step 95100, loss 3.62, lr 0.000391, consume 73.67s
step 95200, loss 3.62, lr 0.000391, consume 83.40s
step 95300, loss 3.61, lr 0.000391, consume 70.98s
step 95400, loss 3.61, lr 0.000390, consume 71.03s
step 95500, loss 3.61, lr 0.000390, consume 71.04s
step 95600, loss 3.61, lr 0.000389, consume 71.02s
step 95700, loss 3.61, lr 0.000389, consume 71.01s
step 95800, loss 3.61, lr 0.000389, consume 71.01s
step 95900, loss 3.61, lr 0.000388, consume 71.01s
step 96000, loss 3.61, lr 0.000388, consume 71.03s
step 96100, loss 3.61, lr 0.000388, consume 71.01s
step 96200, loss 3.60, lr 0.000387, consume 70.99s
processing 71: english_c4/c4-train.00071-of-01024.txt, origin: 355701, samples: 173316, accum_tokens: 12798M, iter_num: 96285
step 96300, loss 3.61, lr 0.000387, consume 91.16s
step 96400, loss 3.62, lr 0.000386, consume 72.01s
step 96500, loss 3.61, lr 0.000386, consume 85.63s
step 96600, loss 3.61, lr 0.000386, consume 70.81s
step 96700, loss 3.61, lr 0.000385, consume 71.03s
step 96800, loss 3.61, lr 0.000385, consume 71.03s
step 96900, loss 3.60, lr 0.000384, consume 71.03s
step 97000, loss 3.60, lr 0.000384, consume 71.03s
step 97100, loss 3.60, lr 0.000384, consume 70.99s
step 97200, loss 3.60, lr 0.000383, consume 70.99s
step 97300, loss 3.60, lr 0.000383, consume 70.98s
step 97400, loss 3.60, lr 0.000383, consume 70.99s
step 97500, loss 3.60, lr 0.000382, consume 70.98s
step 97600, loss 3.61, lr 0.000382, consume 70.99s
processing 72: english_c4/c4-train.00072-of-01024.txt, origin: 355730, samples: 173441, accum_tokens: 12976M, iter_num: 97639
step 97700, loss 3.61, lr 0.000381, consume 91.03s
step 97800, loss 3.61, lr 0.000381, consume 72.70s
step 97900, loss 3.61, lr 0.000381, consume 84.51s
step 98000, loss 3.61, lr 0.000380, consume 70.93s
step 98100, loss 3.61, lr 0.000380, consume 70.98s
step 98200, loss 3.62, lr 0.000380, consume 70.98s
step 98300, loss 3.61, lr 0.000379, consume 70.99s
step 98400, loss 3.61, lr 0.000379, consume 70.98s
step 98500, loss 3.62, lr 0.000378, consume 70.96s
step 98600, loss 3.61, lr 0.000378, consume 70.95s
step 98700, loss 3.61, lr 0.000378, consume 70.97s
step 98800, loss 3.61, lr 0.000377, consume 70.95s
step 98900, loss 3.60, lr 0.000377, consume 70.95s
processing 73: english_c4/c4-train.00073-of-01024.txt, origin: 355659, samples: 173063, accum_tokens: 13153M, iter_num: 98994
step 99000, loss 3.62, lr 0.000376, consume 87.94s
step 99100, loss 3.62, lr 0.000376, consume 74.65s
step 99200, loss 3.61, lr 0.000376, consume 73.05s
step 99300, loss 3.61, lr 0.000375, consume 83.17s
step 99400, loss 3.61, lr 0.000375, consume 70.99s
step 99500, loss 3.61, lr 0.000375, consume 71.02s
step 99600, loss 3.60, lr 0.000374, consume 71.02s
step 99700, loss 3.61, lr 0.000374, consume 71.03s
step 99800, loss 3.60, lr 0.000373, consume 70.98s
step 99900, loss 3.60, lr 0.000373, consume 70.99s
step 100000, loss 3.61, lr 0.000373, consume 71.01s
step 100100, loss 3.61, lr 0.000372, consume 71.00s
step 100200, loss 3.60, lr 0.000372, consume 70.99s
step 100300, loss 3.59, lr 0.000371, consume 70.98s
processing 74: english_c4/c4-train.00074-of-01024.txt, origin: 355720, samples: 173769, accum_tokens: 13331M, iter_num: 100346
step 100400, loss 3.61, lr 0.000371, consume 91.60s
step 100500, loss 3.61, lr 0.000371, consume 72.73s
step 100600, loss 3.61, lr 0.000370, consume 84.15s
step 100700, loss 3.61, lr 0.000370, consume 70.96s
step 100800, loss 3.61, lr 0.000370, consume 71.00s
step 100900, loss 3.60, lr 0.000369, consume 71.03s
step 101000, loss 3.61, lr 0.000369, consume 71.03s
step 101100, loss 3.61, lr 0.000368, consume 71.00s
step 101200, loss 3.60, lr 0.000368, consume 70.99s
step 101300, loss 3.60, lr 0.000368, consume 70.99s
step 101400, loss 3.60, lr 0.000367, consume 70.98s
step 101500, loss 3.61, lr 0.000367, consume 70.98s
step 101600, loss 3.60, lr 0.000366, consume 70.98s
step 101700, loss 3.60, lr 0.000366, consume 70.98s
processing 75: english_c4/c4-train.00075-of-01024.txt, origin: 355726, samples: 174522, accum_tokens: 13510M, iter_num: 101704
step 101800, loss 3.61, lr 0.000366, consume 91.83s
step 101900, loss 3.61, lr 0.000365, consume 73.53s
step 102000, loss 3.61, lr 0.000365, consume 82.98s
step 102100, loss 3.60, lr 0.000365, consume 70.96s
step 102200, loss 3.61, lr 0.000364, consume 71.00s
step 102300, loss 3.61, lr 0.000364, consume 70.98s
step 102400, loss 3.60, lr 0.000363, consume 70.98s
step 102500, loss 3.61, lr 0.000363, consume 70.96s
step 102600, loss 3.61, lr 0.000363, consume 70.97s
step 102700, loss 3.61, lr 0.000362, consume 70.99s
step 102800, loss 3.61, lr 0.000362, consume 70.96s
step 102900, loss 3.60, lr 0.000361, consume 70.97s
step 103000, loss 3.60, lr 0.000361, consume 70.97s
processing 76: english_c4/c4-train.00076-of-01024.txt, origin: 355712, samples: 174378, accum_tokens: 13688M, iter_num: 103067
step 103100, loss 3.61, lr 0.000361, consume 90.82s
step 103200, loss 3.61, lr 0.000360, consume 72.74s
step 103300, loss 3.60, lr 0.000360, consume 84.73s
step 103400, loss 3.61, lr 0.000360, consume 70.92s
step 103500, loss 3.60, lr 0.000359, consume 70.99s
step 103600, loss 3.60, lr 0.000359, consume 71.02s
step 103700, loss 3.60, lr 0.000358, consume 71.00s
step 103800, loss 3.60, lr 0.000358, consume 71.00s
step 103900, loss 3.60, lr 0.000358, consume 70.99s
step 104000, loss 3.61, lr 0.000357, consume 70.97s
step 104100, loss 3.60, lr 0.000357, consume 70.99s
step 104200, loss 3.60, lr 0.000356, consume 70.99s
step 104300, loss 3.60, lr 0.000356, consume 70.98s
step 104400, loss 3.60, lr 0.000356, consume 70.97s
processing 77: english_c4/c4-train.00077-of-01024.txt, origin: 355692, samples: 173612, accum_tokens: 13866M, iter_num: 104429
step 104500, loss 3.61, lr 0.000355, consume 91.19s
step 104600, loss 3.61, lr 0.000355, consume 72.65s
step 104700, loss 3.61, lr 0.000354, consume 84.17s
step 104800, loss 3.60, lr 0.000354, consume 70.95s
step 104900, loss 3.61, lr 0.000354, consume 70.99s
step 105000, loss 3.61, lr 0.000353, consume 71.01s
step 105100, loss 3.60, lr 0.000353, consume 70.99s
step 105200, loss 3.61, lr 0.000353, consume 70.99s
step 105300, loss 3.60, lr 0.000352, consume 70.97s
step 105400, loss 3.60, lr 0.000352, consume 70.97s
step 105500, loss 3.60, lr 0.000351, consume 70.97s
step 105600, loss 3.60, lr 0.000351, consume 70.97s
step 105700, loss 3.61, lr 0.000351, consume 70.97s
processing 78: english_c4/c4-train.00078-of-01024.txt, origin: 355623, samples: 174399, accum_tokens: 14045M, iter_num: 105786
step 105800, loss 3.61, lr 0.000350, consume 90.96s
step 105900, loss 3.61, lr 0.000350, consume 72.42s
step 106000, loss 3.60, lr 0.000349, consume 85.56s
step 106100, loss 3.60, lr 0.000349, consume 70.83s
step 106200, loss 3.59, lr 0.000349, consume 70.99s
step 106300, loss 3.60, lr 0.000348, consume 70.98s
step 106400, loss 3.59, lr 0.000348, consume 70.98s
step 106500, loss 3.60, lr 0.000348, consume 70.98s
step 106600, loss 3.59, lr 0.000347, consume 70.97s
step 106700, loss 3.60, lr 0.000347, consume 70.94s
step 106800, loss 3.60, lr 0.000346, consume 70.96s
step 106900, loss 3.60, lr 0.000346, consume 70.96s
step 107000, loss 3.60, lr 0.000346, consume 70.95s
step 107100, loss 3.60, lr 0.000345, consume 70.97s
processing 79: english_c4/c4-train.00079-of-01024.txt, origin: 355719, samples: 174829, accum_tokens: 14224M, iter_num: 107148
step 107200, loss 3.60, lr 0.000345, consume 91.48s
step 107300, loss 3.60, lr 0.000344, consume 72.65s
step 107400, loss 3.60, lr 0.000344, consume 84.20s
step 107500, loss 3.60, lr 0.000344, consume 70.90s
step 107600, loss 3.60, lr 0.000343, consume 70.97s
step 107700, loss 3.59, lr 0.000343, consume 70.97s
step 107800, loss 3.60, lr 0.000342, consume 70.95s
step 107900, loss 3.59, lr 0.000342, consume 70.94s
step 108000, loss 3.60, lr 0.000342, consume 70.94s
step 108100, loss 3.59, lr 0.000341, consume 70.93s
step 108200, loss 3.60, lr 0.000341, consume 70.94s
step 108300, loss 3.59, lr 0.000341, consume 70.92s
step 108400, loss 3.59, lr 0.000340, consume 70.93s
step 108500, loss 3.60, lr 0.000340, consume 70.93s
processing 80: english_c4/c4-train.00080-of-01024.txt, origin: 355717, samples: 174189, accum_tokens: 14402M, iter_num: 108514
step 108600, loss 3.61, lr 0.000339, consume 91.58s
step 108700, loss 3.59, lr 0.000339, consume 74.03s
step 108800, loss 3.61, lr 0.000339, consume 83.33s
step 108900, loss 3.60, lr 0.000338, consume 70.93s
step 109000, loss 3.60, lr 0.000338, consume 70.95s
step 109100, loss 3.59, lr 0.000337, consume 70.93s
step 109200, loss 3.61, lr 0.000337, consume 70.94s
step 109300, loss 3.59, lr 0.000337, consume 70.91s
step 109400, loss 3.60, lr 0.000336, consume 70.92s
step 109500, loss 3.60, lr 0.000336, consume 70.92s
step 109600, loss 3.60, lr 0.000335, consume 70.94s
step 109700, loss 3.60, lr 0.000335, consume 70.90s
step 109800, loss 3.59, lr 0.000335, consume 70.92s
processing 81: english_c4/c4-train.00081-of-01024.txt, origin: 355718, samples: 172889, accum_tokens: 14579M, iter_num: 109874
step 109900, loss 3.61, lr 0.000334, consume 90.76s
step 110000, loss 3.60, lr 0.000334, consume 72.58s
step 110100, loss 3.60, lr 0.000334, consume 84.63s
step 110200, loss 3.60, lr 0.000333, consume 70.90s
step 110300, loss 3.60, lr 0.000333, consume 71.00s
step 110400, loss 3.60, lr 0.000332, consume 71.02s
step 110500, loss 3.60, lr 0.000332, consume 71.02s
step 110600, loss 3.60, lr 0.000332, consume 70.99s
step 110700, loss 3.61, lr 0.000331, consume 70.98s
step 110800, loss 3.59, lr 0.000331, consume 70.99s
step 110900, loss 3.60, lr 0.000330, consume 70.97s
step 111000, loss 3.60, lr 0.000330, consume 70.97s
step 111100, loss 3.59, lr 0.000330, consume 70.95s
step 111200, loss 3.60, lr 0.000329, consume 70.95s
processing 82: english_c4/c4-train.00082-of-01024.txt, origin: 355740, samples: 172818, accum_tokens: 14756M, iter_num: 111225
step 111300, loss 3.61, lr 0.000329, consume 92.03s
step 111400, loss 3.59, lr 0.000328, consume 73.19s
step 111500, loss 3.60, lr 0.000328, consume 83.39s
step 111600, loss 3.59, lr 0.000328, consume 70.95s
step 111700, loss 3.60, lr 0.000327, consume 70.99s
step 111800, loss 3.60, lr 0.000327, consume 71.00s
step 111900, loss 3.60, lr 0.000327, consume 70.99s
step 112000, loss 3.60, lr 0.000326, consume 70.99s
step 112100, loss 3.60, lr 0.000326, consume 70.99s
step 112200, loss 3.59, lr 0.000325, consume 70.96s
step 112300, loss 3.58, lr 0.000325, consume 70.96s
step 112400, loss 3.59, lr 0.000325, consume 70.95s
step 112500, loss 3.59, lr 0.000324, consume 70.94s
processing 83: english_c4/c4-train.00083-of-01024.txt, origin: 355720, samples: 173793, accum_tokens: 14934M, iter_num: 112575
step 112600, loss 3.59, lr 0.000324, consume 91.09s
step 112700, loss 3.59, lr 0.000323, consume 72.85s
step 112800, loss 3.59, lr 0.000323, consume 84.71s
step 112900, loss 3.60, lr 0.000323, consume 70.87s
step 113000, loss 3.60, lr 0.000322, consume 70.96s
step 113100, loss 3.59, lr 0.000322, consume 70.98s
step 113200, loss 3.59, lr 0.000321, consume 70.96s
step 113300, loss 3.59, lr 0.000321, consume 70.95s
step 113400, loss 3.59, lr 0.000321, consume 70.96s
step 113500, loss 3.59, lr 0.000320, consume 70.95s
step 113600, loss 3.59, lr 0.000320, consume 70.95s
step 113700, loss 3.58, lr 0.000320, consume 70.97s
step 113800, loss 3.59, lr 0.000319, consume 70.97s
step 113900, loss 3.60, lr 0.000319, consume 70.96s
processing 84: english_c4/c4-train.00084-of-01024.txt, origin: 355711, samples: 173849, accum_tokens: 15112M, iter_num: 113933
step 114000, loss 3.59, lr 0.000318, consume 91.75s
step 114100, loss 3.60, lr 0.000318, consume 72.83s
step 114200, loss 3.59, lr 0.000318, consume 84.33s
step 114300, loss 3.59, lr 0.000317, consume 70.93s
step 114400, loss 3.60, lr 0.000317, consume 70.98s
step 114500, loss 3.59, lr 0.000316, consume 70.97s
step 114600, loss 3.59, lr 0.000316, consume 70.98s
step 114700, loss 3.59, lr 0.000316, consume 70.97s
step 114800, loss 3.59, lr 0.000315, consume 70.96s
step 114900, loss 3.59, lr 0.000315, consume 70.97s
step 115000, loss 3.59, lr 0.000314, consume 70.95s
step 115100, loss 3.58, lr 0.000314, consume 70.96s
step 115200, loss 3.59, lr 0.000314, consume 70.95s
processing 85: english_c4/c4-train.00085-of-01024.txt, origin: 355761, samples: 174551, accum_tokens: 15291M, iter_num: 115291
step 115300, loss 3.59, lr 0.000313, consume 90.77s
step 115400, loss 3.59, lr 0.000313, consume 72.18s
step 115500, loss 3.60, lr 0.000313, consume 73.12s
step 115600, loss 3.59, lr 0.000312, consume 82.88s
step 115700, loss 3.59, lr 0.000312, consume 70.96s
step 115800, loss 3.58, lr 0.000311, consume 70.95s
step 115900, loss 3.59, lr 0.000311, consume 70.96s
step 116000, loss 3.59, lr 0.000311, consume 70.93s
step 116100, loss 3.59, lr 0.000310, consume 70.94s
step 116200, loss 3.59, lr 0.000310, consume 70.92s
step 116300, loss 3.58, lr 0.000309, consume 70.93s
step 116400, loss 3.58, lr 0.000309, consume 70.91s
step 116500, loss 3.58, lr 0.000309, consume 70.91s
step 116600, loss 3.58, lr 0.000308, consume 70.92s
processing 86: english_c4/c4-train.00086-of-01024.txt, origin: 355755, samples: 173919, accum_tokens: 15469M, iter_num: 116654
step 116700, loss 3.59, lr 0.000308, consume 91.35s
step 116800, loss 3.60, lr 0.000307, consume 72.53s
step 116900, loss 3.59, lr 0.000307, consume 84.12s
step 117000, loss 3.59, lr 0.000307, consume 70.87s
step 117100, loss 3.59, lr 0.000306, consume 70.95s
step 117200, loss 3.58, lr 0.000306, consume 70.95s
step 117300, loss 3.59, lr 0.000306, consume 70.94s
step 117400, loss 3.59, lr 0.000305, consume 70.94s
step 117500, loss 3.59, lr 0.000305, consume 70.93s
step 117600, loss 3.58, lr 0.000304, consume 70.94s
step 117700, loss 3.58, lr 0.000304, consume 70.93s
step 117800, loss 3.59, lr 0.000304, consume 70.93s
step 117900, loss 3.58, lr 0.000303, consume 70.95s
step 118000, loss 3.59, lr 0.000303, consume 70.94s
processing 87: english_c4/c4-train.00087-of-01024.txt, origin: 355681, samples: 173693, accum_tokens: 15647M, iter_num: 118013
step 118100, loss 3.59, lr 0.000302, consume 91.63s
step 118200, loss 3.59, lr 0.000302, consume 74.01s
step 118300, loss 3.59, lr 0.000302, consume 83.43s
step 118400, loss 3.58, lr 0.000301, consume 70.98s
step 118500, loss 3.59, lr 0.000301, consume 70.98s
step 118600, loss 3.58, lr 0.000300, consume 70.99s
step 118700, loss 3.59, lr 0.000300, consume 70.98s
step 118800, loss 3.58, lr 0.000300, consume 70.97s
step 118900, loss 3.59, lr 0.000299, consume 70.96s
step 119000, loss 3.58, lr 0.000299, consume 70.98s
step 119100, loss 3.58, lr 0.000299, consume 70.98s
step 119200, loss 3.58, lr 0.000298, consume 70.97s
step 119300, loss 3.58, lr 0.000298, consume 70.98s
processing 88: english_c4/c4-train.00088-of-01024.txt, origin: 355669, samples: 173422, accum_tokens: 15824M, iter_num: 119369
step 119400, loss 3.58, lr 0.000297, consume 91.12s
step 119500, loss 3.59, lr 0.000297, consume 72.79s
step 119600, loss 3.59, lr 0.000297, consume 84.73s
step 119700, loss 3.58, lr 0.000296, consume 70.86s
step 119800, loss 3.59, lr 0.000296, consume 70.95s
step 119900, loss 3.59, lr 0.000295, consume 70.93s
step 120000, loss 3.59, lr 0.000295, consume 70.94s
step 120100, loss 3.59, lr 0.000295, consume 70.93s
step 120200, loss 3.59, lr 0.000294, consume 70.93s
step 120300, loss 3.58, lr 0.000294, consume 70.92s
step 120400, loss 3.58, lr 0.000294, consume 70.95s
step 120500, loss 3.59, lr 0.000293, consume 71.08s
step 120600, loss 3.60, lr 0.000293, consume 71.06s
step 120700, loss 3.59, lr 0.000292, consume 70.96s
processing 89: english_c4/c4-train.00089-of-01024.txt, origin: 355704, samples: 173644, accum_tokens: 16002M, iter_num: 120724
step 120800, loss 3.59, lr 0.000292, consume 91.46s
step 120900, loss 3.59, lr 0.000292, consume 73.72s
step 121000, loss 3.58, lr 0.000291, consume 83.41s
step 121100, loss 3.59, lr 0.000291, consume 70.94s
step 121200, loss 3.59, lr 0.000290, consume 70.99s
step 121300, loss 3.58, lr 0.000290, consume 70.98s
step 121400, loss 3.58, lr 0.000290, consume 70.98s
step 121500, loss 3.57, lr 0.000289, consume 70.95s
step 121600, loss 3.58, lr 0.000289, consume 70.97s
step 121700, loss 3.58, lr 0.000289, consume 70.97s
step 121800, loss 3.58, lr 0.000288, consume 70.97s
step 121900, loss 3.58, lr 0.000288, consume 70.96s
step 122000, loss 3.58, lr 0.000287, consume 70.96s
processing 90: english_c4/c4-train.00090-of-01024.txt, origin: 355702, samples: 173297, accum_tokens: 16180M, iter_num: 122081
step 122100, loss 3.59, lr 0.000287, consume 90.72s
step 122200, loss 3.58, lr 0.000287, consume 72.55s
step 122300, loss 3.59, lr 0.000286, consume 85.56s
step 122400, loss 3.58, lr 0.000286, consume 70.90s
step 122500, loss 3.58, lr 0.000285, consume 71.00s
step 122600, loss 3.58, lr 0.000285, consume 71.02s
step 122700, loss 3.58, lr 0.000285, consume 71.00s
step 122800, loss 3.58, lr 0.000284, consume 71.00s
step 122900, loss 3.59, lr 0.000284, consume 70.98s
step 123000, loss 3.59, lr 0.000284, consume 70.99s
step 123100, loss 3.58, lr 0.000283, consume 70.99s
step 123200, loss 3.58, lr 0.000283, consume 70.98s
step 123300, loss 3.58, lr 0.000282, consume 70.97s
step 123400, loss 3.57, lr 0.000282, consume 70.96s
processing 91: english_c4/c4-train.00091-of-01024.txt, origin: 355734, samples: 173833, accum_tokens: 16358M, iter_num: 123434
step 123500, loss 3.59, lr 0.000282, consume 91.93s
step 123600, loss 3.59, lr 0.000281, consume 72.71s
step 123700, loss 3.59, lr 0.000281, consume 84.52s
step 123800, loss 3.59, lr 0.000280, consume 70.95s
step 123900, loss 3.58, lr 0.000280, consume 71.02s
step 124000, loss 3.58, lr 0.000280, consume 70.99s
step 124100, loss 3.58, lr 0.000279, consume 71.00s
step 124200, loss 3.59, lr 0.000279, consume 70.99s
step 124300, loss 3.58, lr 0.000279, consume 70.97s
step 124400, loss 3.58, lr 0.000278, consume 70.98s
step 124500, loss 3.59, lr 0.000278, consume 71.00s
step 124600, loss 3.58, lr 0.000277, consume 70.99s
step 124700, loss 3.59, lr 0.000277, consume 70.97s
processing 92: english_c4/c4-train.00092-of-01024.txt, origin: 355739, samples: 173558, accum_tokens: 16535M, iter_num: 124792
step 124800, loss 3.57, lr 0.000277, consume 91.06s
step 124900, loss 3.58, lr 0.000276, consume 72.54s
step 125000, loss 3.58, lr 0.000276, consume 85.60s
step 125100, loss 3.58, lr 0.000276, consume 70.87s
step 125200, loss 3.58, lr 0.000275, consume 70.98s
step 125300, loss 3.58, lr 0.000275, consume 70.98s
step 125400, loss 3.58, lr 0.000274, consume 70.97s
step 125500, loss 3.58, lr 0.000274, consume 70.94s
step 125600, loss 3.57, lr 0.000274, consume 70.95s
step 125700, loss 3.57, lr 0.000273, consume 70.94s
step 125800, loss 3.57, lr 0.000273, consume 70.95s
step 125900, loss 3.57, lr 0.000272, consume 70.92s
step 126000, loss 3.58, lr 0.000272, consume 70.94s
step 126100, loss 3.57, lr 0.000272, consume 70.93s
processing 93: english_c4/c4-train.00093-of-01024.txt, origin: 355680, samples: 173573, accum_tokens: 16713M, iter_num: 126148
step 126200, loss 3.59, lr 0.000271, consume 91.45s
step 126300, loss 3.59, lr 0.000271, consume 72.61s
step 126400, loss 3.58, lr 0.000271, consume 85.52s
step 126500, loss 3.58, lr 0.000270, consume 70.93s
step 126600, loss 3.58, lr 0.000270, consume 70.99s
step 126700, loss 3.58, lr 0.000269, consume 71.00s
step 126800, loss 3.58, lr 0.000269, consume 70.99s
step 126900, loss 3.58, lr 0.000269, consume 70.98s
step 127000, loss 3.58, lr 0.000268, consume 70.98s
step 127100, loss 3.58, lr 0.000268, consume 70.96s
step 127200, loss 3.58, lr 0.000268, consume 70.96s
step 127300, loss 3.57, lr 0.000267, consume 70.97s
step 127400, loss 3.58, lr 0.000267, consume 70.97s
step 127500, loss 3.58, lr 0.000266, consume 70.97s
processing 94: english_c4/c4-train.00094-of-01024.txt, origin: 355750, samples: 174481, accum_tokens: 16892M, iter_num: 127504
step 127600, loss 3.58, lr 0.000266, consume 91.83s
step 127700, loss 3.58, lr 0.000266, consume 73.08s
step 127800, loss 3.58, lr 0.000265, consume 84.37s
step 127900, loss 3.58, lr 0.000265, consume 70.97s
step 128000, loss 3.58, lr 0.000265, consume 71.01s
step 128100, loss 3.58, lr 0.000264, consume 71.02s
step 128200, loss 3.57, lr 0.000264, consume 70.99s
step 128300, loss 3.58, lr 0.000263, consume 70.98s
step 128400, loss 3.57, lr 0.000263, consume 70.98s
step 128500, loss 3.58, lr 0.000263, consume 70.98s
step 128600, loss 3.58, lr 0.000262, consume 70.98s
step 128700, loss 3.57, lr 0.000262, consume 70.98s
step 128800, loss 3.57, lr 0.000262, consume 70.98s
processing 95: english_c4/c4-train.00095-of-01024.txt, origin: 355731, samples: 174016, accum_tokens: 17070M, iter_num: 128867
step 128900, loss 3.57, lr 0.000261, consume 91.27s
step 129000, loss 3.58, lr 0.000261, consume 72.53s
step 129100, loss 3.58, lr 0.000260, consume 85.49s
step 129200, loss 3.58, lr 0.000260, consume 70.92s
step 129300, loss 3.59, lr 0.000260, consume 70.99s
step 129400, loss 3.58, lr 0.000259, consume 71.00s
step 129500, loss 3.58, lr 0.000259, consume 71.01s
step 129600, loss 3.57, lr 0.000258, consume 70.99s
step 129700, loss 3.58, lr 0.000258, consume 71.00s
step 129800, loss 3.58, lr 0.000258, consume 70.99s
step 129900, loss 3.58, lr 0.000257, consume 70.97s
step 130000, loss 3.57, lr 0.000257, consume 70.99s
step 130100, loss 3.58, lr 0.000257, consume 70.97s
step 130200, loss 3.57, lr 0.000256, consume 70.98s
processing 96: english_c4/c4-train.00096-of-01024.txt, origin: 355724, samples: 174296, accum_tokens: 17249M, iter_num: 130227
step 130300, loss 3.57, lr 0.000256, consume 91.44s
step 130400, loss 3.58, lr 0.000255, consume 72.91s
step 130500, loss 3.57, lr 0.000255, consume 84.34s
step 130600, loss 3.58, lr 0.000255, consume 70.95s
step 130700, loss 3.57, lr 0.000254, consume 70.95s
step 130800, loss 3.57, lr 0.000254, consume 70.98s
step 130900, loss 3.57, lr 0.000254, consume 70.97s
step 131000, loss 3.57, lr 0.000253, consume 70.94s
step 131100, loss 3.57, lr 0.000253, consume 70.94s
step 131200, loss 3.57, lr 0.000253, consume 70.92s
step 131300, loss 3.57, lr 0.000252, consume 70.94s
step 131400, loss 3.57, lr 0.000252, consume 70.97s
step 131500, loss 3.57, lr 0.000251, consume 70.96s
processing 97: english_c4/c4-train.00097-of-01024.txt, origin: 355707, samples: 174019, accum_tokens: 17427M, iter_num: 131588
step 131600, loss 3.57, lr 0.000251, consume 91.04s
step 131700, loss 3.58, lr 0.000251, consume 72.78s
step 131800, loss 3.58, lr 0.000250, consume 84.90s
step 131900, loss 3.57, lr 0.000250, consume 70.84s
step 132000, loss 3.57, lr 0.000250, consume 70.97s
step 132100, loss 3.58, lr 0.000249, consume 70.98s
step 132200, loss 3.58, lr 0.000249, consume 70.97s
step 132300, loss 3.57, lr 0.000248, consume 70.96s
step 132400, loss 3.57, lr 0.000248, consume 70.96s
step 132500, loss 3.57, lr 0.000248, consume 70.97s
step 132600, loss 3.57, lr 0.000247, consume 70.96s
step 132700, loss 3.57, lr 0.000247, consume 70.96s
step 132800, loss 3.57, lr 0.000247, consume 70.97s
step 132900, loss 3.57, lr 0.000246, consume 70.95s
processing 98: english_c4/c4-train.00098-of-01024.txt, origin: 355709, samples: 174792, accum_tokens: 17606M, iter_num: 132948
step 133000, loss 3.58, lr 0.000246, consume 91.50s
step 133100, loss 3.57, lr 0.000245, consume 72.62s
step 133200, loss 3.56, lr 0.000245, consume 84.32s
step 133300, loss 3.57, lr 0.000245, consume 70.92s
step 133400, loss 3.57, lr 0.000244, consume 71.00s
step 133500, loss 3.57, lr 0.000244, consume 70.99s
step 133600, loss 3.56, lr 0.000244, consume 71.01s
step 133700, loss 3.57, lr 0.000243, consume 70.98s
step 133800, loss 3.57, lr 0.000243, consume 70.98s
step 133900, loss 3.57, lr 0.000243, consume 70.99s
step 134000, loss 3.57, lr 0.000242, consume 70.97s
step 134100, loss 3.56, lr 0.000242, consume 70.97s
step 134200, loss 3.57, lr 0.000241, consume 70.97s
step 134300, loss 3.56, lr 0.000241, consume 70.98s
processing 99: english_c4/c4-train.00099-of-01024.txt, origin: 355710, samples: 174093, accum_tokens: 17784M, iter_num: 134313
step 134400, loss 3.57, lr 0.000241, consume 92.51s
step 134500, loss 3.57, lr 0.000240, consume 73.20s
step 134600, loss 3.57, lr 0.000240, consume 83.06s
step 134700, loss 3.57, lr 0.000240, consume 70.96s
step 134800, loss 3.57, lr 0.000239, consume 71.00s
step 134900, loss 3.56, lr 0.000239, consume 70.99s
step 135000, loss 3.56, lr 0.000238, consume 70.98s
step 135100, loss 3.57, lr 0.000238, consume 70.97s
step 135200, loss 3.57, lr 0.000238, consume 70.97s
step 135300, loss 3.57, lr 0.000237, consume 70.96s
step 135400, loss 3.57, lr 0.000237, consume 70.95s
step 135500, loss 3.56, lr 0.000237, consume 70.98s
step 135600, loss 3.57, lr 0.000236, consume 70.95s
processing 100: english_c4/c4-train.00100-of-01024.txt, origin: 355728, samples: 174038, accum_tokens: 17962M, iter_num: 135673
step 135700, loss 3.57, lr 0.000236, consume 91.22s
step 135800, loss 3.57, lr 0.000236, consume 72.29s
step 135900, loss 3.57, lr 0.000235, consume 85.75s
step 136000, loss 3.57, lr 0.000235, consume 70.90s
step 136100, loss 3.57, lr 0.000234, consume 70.99s
step 136200, loss 3.57, lr 0.000234, consume 71.00s
step 136300, loss 3.57, lr 0.000234, consume 71.00s
step 136400, loss 3.56, lr 0.000233, consume 70.99s
step 136500, loss 3.57, lr 0.000233, consume 70.99s
step 136600, loss 3.56, lr 0.000233, consume 70.98s
step 136700, loss 3.57, lr 0.000232, consume 70.99s
step 136800, loss 3.57, lr 0.000232, consume 70.98s
step 136900, loss 3.56, lr 0.000232, consume 70.99s
step 137000, loss 3.57, lr 0.000231, consume 70.97s
processing 101: english_c4/c4-train.00101-of-01024.txt, origin: 355722, samples: 173621, accum_tokens: 18140M, iter_num: 137033
step 137100, loss 3.56, lr 0.000231, consume 91.54s
step 137200, loss 3.56, lr 0.000230, consume 72.77s
step 137300, loss 3.57, lr 0.000230, consume 84.64s
step 137400, loss 3.56, lr 0.000230, consume 70.94s
step 137500, loss 3.56, lr 0.000229, consume 70.99s
step 137600, loss 3.56, lr 0.000229, consume 71.02s
step 137700, loss 3.56, lr 0.000229, consume 71.00s
step 137800, loss 3.57, lr 0.000228, consume 71.00s
step 137900, loss 3.55, lr 0.000228, consume 70.98s
step 138000, loss 3.57, lr 0.000228, consume 70.97s
step 138100, loss 3.56, lr 0.000227, consume 70.97s
step 138200, loss 3.56, lr 0.000227, consume 70.98s
step 138300, loss 3.57, lr 0.000226, consume 71.14s
processing 102: english_c4/c4-train.00102-of-01024.txt, origin: 355723, samples: 174771, accum_tokens: 18319M, iter_num: 138389
step 138400, loss 3.56, lr 0.000226, consume 91.09s
step 138500, loss 3.57, lr 0.000226, consume 72.36s
step 138600, loss 3.57, lr 0.000225, consume 85.50s
step 138700, loss 3.56, lr 0.000225, consume 70.87s
step 138800, loss 3.56, lr 0.000225, consume 71.00s
step 138900, loss 3.56, lr 0.000224, consume 71.01s
step 139000, loss 3.56, lr 0.000224, consume 70.99s
step 139100, loss 3.57, lr 0.000224, consume 71.00s
step 139200, loss 3.56, lr 0.000223, consume 70.99s
step 139300, loss 3.57, lr 0.000223, consume 70.98s
step 139400, loss 3.56, lr 0.000223, consume 71.00s
step 139500, loss 3.56, lr 0.000222, consume 70.98s
step 139600, loss 3.56, lr 0.000222, consume 70.98s
step 139700, loss 3.57, lr 0.000221, consume 70.99s
processing 103: english_c4/c4-train.00103-of-01024.txt, origin: 355699, samples: 174028, accum_tokens: 18497M, iter_num: 139754
step 139800, loss 3.57, lr 0.000221, consume 91.61s
step 139900, loss 3.58, lr 0.000221, consume 72.39s
step 140000, loss 3.57, lr 0.000220, consume 85.48s
step 140100, loss 3.57, lr 0.000220, consume 70.93s
step 140200, loss 3.57, lr 0.000220, consume 71.00s
step 140300, loss 3.56, lr 0.000219, consume 71.02s
step 140400, loss 3.56, lr 0.000219, consume 71.01s
step 140500, loss 3.57, lr 0.000219, consume 71.01s
step 140600, loss 3.57, lr 0.000218, consume 71.01s
step 140700, loss 3.56, lr 0.000218, consume 71.00s
step 140800, loss 3.57, lr 0.000218, consume 71.00s
step 140900, loss 3.57, lr 0.000217, consume 70.97s
step 141000, loss 3.56, lr 0.000217, consume 70.98s
step 141100, loss 3.56, lr 0.000217, consume 71.00s
processing 104: english_c4/c4-train.00104-of-01024.txt, origin: 355728, samples: 174018, accum_tokens: 18675M, iter_num: 141114
step 141200, loss 3.57, lr 0.000216, consume 91.64s
step 141300, loss 3.56, lr 0.000216, consume 73.16s
step 141400, loss 3.56, lr 0.000215, consume 84.44s
step 141500, loss 3.56, lr 0.000215, consume 70.99s
step 141600, loss 3.56, lr 0.000215, consume 71.01s
step 141700, loss 3.57, lr 0.000214, consume 71.02s
step 141800, loss 3.56, lr 0.000214, consume 71.00s
step 141900, loss 3.56, lr 0.000214, consume 70.98s
step 142000, loss 3.56, lr 0.000213, consume 70.99s
step 142100, loss 3.56, lr 0.000213, consume 70.98s
step 142200, loss 3.56, lr 0.000213, consume 70.99s
step 142300, loss 3.55, lr 0.000212, consume 70.98s
step 142400, loss 3.56, lr 0.000212, consume 70.98s
processing 105: english_c4/c4-train.00105-of-01024.txt, origin: 355715, samples: 174626, accum_tokens: 18854M, iter_num: 142473
step 142500, loss 3.56, lr 0.000212, consume 91.36s
step 142600, loss 3.55, lr 0.000211, consume 72.33s
step 142700, loss 3.55, lr 0.000211, consume 85.87s
step 142800, loss 3.55, lr 0.000211, consume 70.91s
step 142900, loss 3.55, lr 0.000210, consume 71.00s
step 143000, loss 3.55, lr 0.000210, consume 71.00s
step 143100, loss 3.56, lr 0.000210, consume 70.99s
step 143200, loss 3.55, lr 0.000209, consume 70.98s
step 143300, loss 3.55, lr 0.000209, consume 70.98s
step 143400, loss 3.54, lr 0.000208, consume 70.98s
step 143500, loss 3.55, lr 0.000208, consume 70.97s
step 143600, loss 3.54, lr 0.000208, consume 70.99s
step 143700, loss 3.54, lr 0.000207, consume 70.98s
step 143800, loss 3.55, lr 0.000207, consume 70.97s
processing 106: english_c4/c4-train.00106-of-01024.txt, origin: 355742, samples: 173457, accum_tokens: 19032M, iter_num: 143837
step 143900, loss 3.56, lr 0.000207, consume 91.40s
step 144000, loss 3.55, lr 0.000206, consume 72.75s
step 144100, loss 3.56, lr 0.000206, consume 84.36s
step 144200, loss 3.56, lr 0.000206, consume 70.90s
step 144300, loss 3.56, lr 0.000205, consume 71.01s
step 144400, loss 3.56, lr 0.000205, consume 71.02s
step 144500, loss 3.56, lr 0.000205, consume 71.01s
step 144600, loss 3.56, lr 0.000204, consume 70.99s
step 144700, loss 3.56, lr 0.000204, consume 71.01s
step 144800, loss 3.55, lr 0.000204, consume 70.99s
step 144900, loss 3.55, lr 0.000203, consume 71.00s
step 145000, loss 3.56, lr 0.000203, consume 71.00s
step 145100, loss 3.56, lr 0.000203, consume 70.98s
processing 107: english_c4/c4-train.00107-of-01024.txt, origin: 355699, samples: 174383, accum_tokens: 19210M, iter_num: 145192
step 145200, loss 3.56, lr 0.000202, consume 90.91s
step 145300, loss 3.56, lr 0.000202, consume 72.01s
step 145400, loss 3.56, lr 0.000202, consume 73.03s
step 145500, loss 3.56, lr 0.000201, consume 82.94s
step 145600, loss 3.56, lr 0.000201, consume 70.96s
step 145700, loss 3.55, lr 0.000201, consume 71.01s
step 145800, loss 3.55, lr 0.000200, consume 71.00s
step 145900, loss 3.55, lr 0.000200, consume 71.00s
step 146000, loss 3.56, lr 0.000200, consume 70.99s
step 146100, loss 3.55, lr 0.000199, consume 70.99s
step 146200, loss 3.56, lr 0.000199, consume 70.98s
step 146300, loss 3.56, lr 0.000199, consume 70.97s
step 146400, loss 3.56, lr 0.000198, consume 71.00s
step 146500, loss 3.55, lr 0.000198, consume 70.98s
processing 108: english_c4/c4-train.00108-of-01024.txt, origin: 355708, samples: 174092, accum_tokens: 19389M, iter_num: 146555
step 146600, loss 3.56, lr 0.000197, consume 91.60s
step 146700, loss 3.57, lr 0.000197, consume 72.67s
step 146800, loss 3.56, lr 0.000197, consume 84.23s
step 146900, loss 3.56, lr 0.000196, consume 70.82s
step 147000, loss 3.56, lr 0.000196, consume 71.01s
step 147100, loss 3.55, lr 0.000196, consume 71.00s
step 147200, loss 3.56, lr 0.000195, consume 70.99s
step 147300, loss 3.56, lr 0.000195, consume 70.99s
step 147400, loss 3.55, lr 0.000195, consume 70.99s
step 147500, loss 3.55, lr 0.000194, consume 70.99s
step 147600, loss 3.56, lr 0.000194, consume 70.97s
step 147700, loss 3.56, lr 0.000194, consume 70.98s
step 147800, loss 3.55, lr 0.000193, consume 70.98s
step 147900, loss 3.56, lr 0.000193, consume 70.97s
processing 109: english_c4/c4-train.00109-of-01024.txt, origin: 355716, samples: 172966, accum_tokens: 19566M, iter_num: 147915
step 148000, loss 3.56, lr 0.000193, consume 92.24s
step 148100, loss 3.56, lr 0.000192, consume 73.44s
step 148200, loss 3.56, lr 0.000192, consume 83.10s
step 148300, loss 3.56, lr 0.000192, consume 70.98s
step 148400, loss 3.56, lr 0.000191, consume 71.01s
step 148500, loss 3.56, lr 0.000191, consume 71.00s
step 148600, loss 3.55, lr 0.000191, consume 71.00s
step 148700, loss 3.56, lr 0.000190, consume 71.00s
step 148800, loss 3.56, lr 0.000190, consume 70.99s
step 148900, loss 3.55, lr 0.000190, consume 71.00s
step 149000, loss 3.55, lr 0.000189, consume 70.98s
step 149100, loss 3.55, lr 0.000189, consume 70.97s
step 149200, loss 3.55, lr 0.000189, consume 70.98s
processing 110: english_c4/c4-train.00110-of-01024.txt, origin: 355760, samples: 173788, accum_tokens: 19744M, iter_num: 149266
step 149300, loss 3.55, lr 0.000188, consume 91.41s
step 149400, loss 3.56, lr 0.000188, consume 72.21s
step 149500, loss 3.56, lr 0.000188, consume 85.34s
step 149600, loss 3.55, lr 0.000187, consume 70.83s
step 149700, loss 3.55, lr 0.000187, consume 71.02s
step 149800, loss 3.56, lr 0.000187, consume 71.03s
step 149900, loss 3.55, lr 0.000186, consume 71.01s
step 150000, loss 3.55, lr 0.000186, consume 71.01s
step 150100, loss 3.55, lr 0.000186, consume 70.99s
step 150200, loss 3.55, lr 0.000185, consume 70.99s
step 150300, loss 3.55, lr 0.000185, consume 70.99s
step 150400, loss 3.55, lr 0.000185, consume 71.00s
step 150500, loss 3.56, lr 0.000184, consume 70.99s
step 150600, loss 3.55, lr 0.000184, consume 70.98s
processing 111: english_c4/c4-train.00111-of-01024.txt, origin: 355714, samples: 173440, accum_tokens: 19921M, iter_num: 150623
step 150700, loss 3.55, lr 0.000184, consume 91.56s
step 150800, loss 3.56, lr 0.000183, consume 74.03s
step 150900, loss 3.56, lr 0.000183, consume 83.63s
step 151000, loss 3.56, lr 0.000183, consume 70.97s
step 151100, loss 3.55, lr 0.000183, consume 71.02s
step 151200, loss 3.55, lr 0.000182, consume 71.02s
step 151300, loss 3.55, lr 0.000182, consume 71.01s
step 151400, loss 3.55, lr 0.000182, consume 71.00s
step 151500, loss 3.55, lr 0.000181, consume 71.00s
step 151600, loss 3.56, lr 0.000181, consume 71.00s
step 151700, loss 3.55, lr 0.000181, consume 71.02s
step 151800, loss 3.55, lr 0.000180, consume 70.99s
step 151900, loss 3.55, lr 0.000180, consume 70.99s
processing 112: english_c4/c4-train.00112-of-01024.txt, origin: 355703, samples: 173500, accum_tokens: 20099M, iter_num: 151978
step 152000, loss 3.56, lr 0.000180, consume 90.97s
step 152100, loss 3.56, lr 0.000179, consume 72.44s
step 152200, loss 3.55, lr 0.000179, consume 85.55s
step 152300, loss 3.56, lr 0.000179, consume 70.91s
step 152400, loss 3.55, lr 0.000178, consume 71.00s
step 152500, loss 3.56, lr 0.000178, consume 71.02s
step 152600, loss 3.55, lr 0.000178, consume 71.01s
step 152700, loss 3.55, lr 0.000177, consume 70.99s
step 152800, loss 3.54, lr 0.000177, consume 71.00s
step 152900, loss 3.55, lr 0.000177, consume 70.99s
step 153000, loss 3.55, lr 0.000176, consume 70.96s
step 153100, loss 3.55, lr 0.000176, consume 70.97s
step 153200, loss 3.55, lr 0.000176, consume 70.97s
step 153300, loss 3.55, lr 0.000175, consume 70.98s
processing 113: english_c4/c4-train.00113-of-01024.txt, origin: 355764, samples: 173051, accum_tokens: 20276M, iter_num: 153334
step 153400, loss 3.55, lr 0.000175, consume 91.39s
step 153500, loss 3.54, lr 0.000175, consume 72.96s
step 153600, loss 3.54, lr 0.000174, consume 84.70s
step 153700, loss 3.54, lr 0.000174, consume 70.96s
step 153800, loss 3.55, lr 0.000174, consume 71.00s
step 153900, loss 3.54, lr 0.000174, consume 71.00s
step 154000, loss 3.54, lr 0.000173, consume 71.00s
step 154100, loss 3.54, lr 0.000173, consume 70.99s
step 154200, loss 3.54, lr 0.000173, consume 70.98s
step 154300, loss 3.55, lr 0.000172, consume 70.97s
step 154400, loss 3.55, lr 0.000172, consume 70.97s
step 154500, loss 3.54, lr 0.000172, consume 70.97s
step 154600, loss 3.54, lr 0.000171, consume 70.96s
processing 114: english_c4/c4-train.00114-of-01024.txt, origin: 355719, samples: 173595, accum_tokens: 20454M, iter_num: 154685
step 154700, loss 3.55, lr 0.000171, consume 91.38s
step 154800, loss 3.55, lr 0.000171, consume 71.94s
step 154900, loss 3.55, lr 0.000170, consume 85.25s
step 155000, loss 3.55, lr 0.000170, consume 70.89s
step 155100, loss 3.55, lr 0.000170, consume 71.01s
step 155200, loss 3.55, lr 0.000169, consume 71.01s
step 155300, loss 3.55, lr 0.000169, consume 71.00s
step 155400, loss 3.55, lr 0.000169, consume 71.00s
step 155500, loss 3.55, lr 0.000168, consume 71.00s
step 155600, loss 3.55, lr 0.000168, consume 70.99s
step 155700, loss 3.54, lr 0.000168, consume 70.99s
step 155800, loss 3.54, lr 0.000168, consume 70.98s
step 155900, loss 3.55, lr 0.000167, consume 70.98s
step 156000, loss 3.54, lr 0.000167, consume 70.99s
processing 115: english_c4/c4-train.00115-of-01024.txt, origin: 355742, samples: 173375, accum_tokens: 20632M, iter_num: 156041
step 156100, loss 3.54, lr 0.000167, consume 91.34s
step 156200, loss 3.55, lr 0.000166, consume 72.87s
step 156300, loss 3.55, lr 0.000166, consume 84.70s
step 156400, loss 3.56, lr 0.000166, consume 70.96s
step 156500, loss 3.54, lr 0.000165, consume 71.01s
step 156600, loss 3.54, lr 0.000165, consume 71.01s
step 156700, loss 3.55, lr 0.000165, consume 71.00s
step 156800, loss 3.55, lr 0.000164, consume 70.99s
step 156900, loss 3.55, lr 0.000164, consume 70.99s
step 157000, loss 3.55, lr 0.000164, consume 70.99s
step 157100, loss 3.54, lr 0.000164, consume 70.97s
step 157200, loss 3.55, lr 0.000163, consume 70.98s
step 157300, loss 3.55, lr 0.000163, consume 71.05s
processing 116: english_c4/c4-train.00116-of-01024.txt, origin: 355705, samples: 173722, accum_tokens: 20809M, iter_num: 157396
step 157400, loss 3.54, lr 0.000163, consume 88.51s
step 157500, loss 3.55, lr 0.000162, consume 74.68s
step 157600, loss 3.54, lr 0.000162, consume 73.19s
step 157700, loss 3.55, lr 0.000162, consume 83.23s
step 157800, loss 3.55, lr 0.000161, consume 70.95s
step 157900, loss 3.54, lr 0.000161, consume 70.95s
step 158000, loss 3.54, lr 0.000161, consume 70.94s
step 158100, loss 3.54, lr 0.000160, consume 70.95s
step 158200, loss 3.54, lr 0.000160, consume 70.95s
step 158300, loss 3.54, lr 0.000160, consume 70.95s
step 158400, loss 3.53, lr 0.000160, consume 70.93s
step 158500, loss 3.53, lr 0.000159, consume 70.93s
step 158600, loss 3.54, lr 0.000159, consume 70.93s
step 158700, loss 3.55, lr 0.000159, consume 70.92s
processing 117: english_c4/c4-train.00117-of-01024.txt, origin: 355666, samples: 173021, accum_tokens: 20987M, iter_num: 158753
step 158800, loss 3.55, lr 0.000158, consume 91.46s
step 158900, loss 3.55, lr 0.000158, consume 72.55s
step 159000, loss 3.54, lr 0.000158, consume 84.75s
step 159100, loss 3.54, lr 0.000157, consume 70.93s
step 159200, loss 3.54, lr 0.000157, consume 70.98s
step 159300, loss 3.54, lr 0.000157, consume 70.98s
step 159400, loss 3.54, lr 0.000157, consume 70.97s
step 159500, loss 3.54, lr 0.000156, consume 70.99s
step 159600, loss 3.54, lr 0.000156, consume 70.97s
step 159700, loss 3.54, lr 0.000156, consume 71.08s
step 159800, loss 3.54, lr 0.000155, consume 70.95s
step 159900, loss 3.54, lr 0.000155, consume 70.97s
step 160000, loss 3.54, lr 0.000155, consume 70.96s
step 160100, loss 3.54, lr 0.000155, consume 70.95s
processing 118: english_c4/c4-train.00118-of-01024.txt, origin: 355700, samples: 173453, accum_tokens: 21164M, iter_num: 160104
step 160200, loss 3.55, lr 0.000154, consume 92.34s
step 160300, loss 3.54, lr 0.000154, consume 73.21s
step 160400, loss 3.54, lr 0.000154, consume 83.26s
step 160500, loss 3.54, lr 0.000153, consume 70.97s
step 160600, loss 3.54, lr 0.000153, consume 71.00s
step 160700, loss 3.54, lr 0.000153, consume 70.99s
step 160800, loss 3.53, lr 0.000152, consume 70.99s
step 160900, loss 3.54, lr 0.000152, consume 70.98s
step 161000, loss 3.54, lr 0.000152, consume 71.81s
step 161100, loss 3.54, lr 0.000152, consume 71.14s
step 161200, loss 3.53, lr 0.000151, consume 70.98s
step 161300, loss 3.54, lr 0.000151, consume 70.98s
step 161400, loss 3.55, lr 0.000151, consume 70.98s
processing 119: english_c4/c4-train.00119-of-01024.txt, origin: 355729, samples: 173266, accum_tokens: 21342M, iter_num: 161459
step 161500, loss 3.55, lr 0.000150, consume 90.99s
step 161600, loss 3.54, lr 0.000150, consume 73.08s
step 161700, loss 3.54, lr 0.000150, consume 84.52s
step 161800, loss 3.54, lr 0.000150, consume 70.94s
step 161900, loss 3.54, lr 0.000149, consume 70.98s
step 162000, loss 3.54, lr 0.000149, consume 70.99s
step 162100, loss 3.54, lr 0.000149, consume 70.99s
step 162200, loss 3.53, lr 0.000148, consume 70.98s
step 162300, loss 3.54, lr 0.000148, consume 70.98s
step 162400, loss 3.54, lr 0.000148, consume 70.98s
step 162500, loss 3.54, lr 0.000148, consume 70.97s
step 162600, loss 3.54, lr 0.000147, consume 70.98s
step 162700, loss 3.53, lr 0.000147, consume 70.97s
step 162800, loss 3.55, lr 0.000147, consume 70.98s
processing 120: english_c4/c4-train.00120-of-01024.txt, origin: 355752, samples: 174186, accum_tokens: 21520M, iter_num: 162813
step 162900, loss 3.53, lr 0.000146, consume 92.07s
step 163000, loss 3.54, lr 0.000146, consume 73.39s
step 163100, loss 3.53, lr 0.000146, consume 82.94s
step 163200, loss 3.53, lr 0.000146, consume 71.00s
step 163300, loss 3.54, lr 0.000145, consume 71.02s
step 163400, loss 3.53, lr 0.000145, consume 71.02s
step 163500, loss 3.53, lr 0.000145, consume 71.02s
step 163600, loss 3.54, lr 0.000144, consume 71.01s
step 163700, loss 3.54, lr 0.000144, consume 71.00s
step 163800, loss 3.53, lr 0.000144, consume 71.00s
step 163900, loss 3.53, lr 0.000144, consume 71.01s
step 164000, loss 3.53, lr 0.000143, consume 70.99s
step 164100, loss 3.53, lr 0.000143, consume 71.00s
processing 121: english_c4/c4-train.00121-of-01024.txt, origin: 355734, samples: 173265, accum_tokens: 21697M, iter_num: 164173
step 164200, loss 3.53, lr 0.000143, consume 91.13s
step 164300, loss 3.54, lr 0.000142, consume 72.19s
step 164400, loss 3.54, lr 0.000142, consume 85.45s
step 164500, loss 3.54, lr 0.000142, consume 70.93s
step 164600, loss 3.54, lr 0.000142, consume 71.00s
step 164700, loss 3.54, lr 0.000141, consume 71.01s
step 164800, loss 3.54, lr 0.000141, consume 71.01s
step 164900, loss 3.53, lr 0.000141, consume 71.00s
step 165000, loss 3.54, lr 0.000140, consume 70.99s
step 165100, loss 3.53, lr 0.000140, consume 70.99s
step 165200, loss 3.53, lr 0.000140, consume 70.98s
step 165300, loss 3.54, lr 0.000140, consume 70.97s
step 165400, loss 3.53, lr 0.000139, consume 70.97s
step 165500, loss 3.54, lr 0.000139, consume 71.00s
processing 122: english_c4/c4-train.00122-of-01024.txt, origin: 355751, samples: 174704, accum_tokens: 21876M, iter_num: 165527
step 165600, loss 3.54, lr 0.000139, consume 91.99s
step 165700, loss 3.54, lr 0.000139, consume 73.15s
step 165800, loss 3.54, lr 0.000138, consume 84.80s
step 165900, loss 3.54, lr 0.000138, consume 70.97s
step 166000, loss 3.54, lr 0.000138, consume 71.01s
step 166100, loss 3.54, lr 0.000137, consume 71.00s
step 166200, loss 3.53, lr 0.000137, consume 71.02s
step 166300, loss 3.53, lr 0.000137, consume 71.00s
step 166400, loss 3.54, lr 0.000137, consume 71.00s
step 166500, loss 3.54, lr 0.000136, consume 70.97s
step 166600, loss 3.53, lr 0.000136, consume 70.99s
step 166700, loss 3.54, lr 0.000136, consume 71.00s
step 166800, loss 3.53, lr 0.000136, consume 70.98s
processing 123: english_c4/c4-train.00123-of-01024.txt, origin: 355701, samples: 173087, accum_tokens: 22054M, iter_num: 166892
step 166900, loss 3.53, lr 0.000135, consume 91.63s
step 167000, loss 3.54, lr 0.000135, consume 72.41s
step 167100, loss 3.54, lr 0.000135, consume 85.81s
step 167200, loss 3.53, lr 0.000134, consume 70.75s
step 167300, loss 3.53, lr 0.000134, consume 70.98s
step 167400, loss 3.54, lr 0.000134, consume 71.02s
step 167500, loss 3.52, lr 0.000134, consume 71.00s
step 167600, loss 3.53, lr 0.000133, consume 70.98s
step 167700, loss 3.54, lr 0.000133, consume 70.99s
step 167800, loss 3.53, lr 0.000133, consume 70.98s
step 167900, loss 3.53, lr 0.000133, consume 70.98s
step 168000, loss 3.53, lr 0.000132, consume 71.00s
step 168100, loss 3.53, lr 0.000132, consume 71.00s
step 168200, loss 3.53, lr 0.000132, consume 71.00s
processing 124: english_c4/c4-train.00124-of-01024.txt, origin: 355738, samples: 172762, accum_tokens: 22230M, iter_num: 168244
step 168300, loss 3.53, lr 0.000132, consume 90.73s
step 168400, loss 3.53, lr 0.000131, consume 73.19s
step 168500, loss 3.53, lr 0.000131, consume 84.17s
step 168600, loss 3.54, lr 0.000131, consume 70.97s
step 168700, loss 3.52, lr 0.000130, consume 71.03s
step 168800, loss 3.53, lr 0.000130, consume 71.04s
step 168900, loss 3.53, lr 0.000130, consume 71.01s
step 169000, loss 3.52, lr 0.000130, consume 70.99s
step 169100, loss 3.54, lr 0.000129, consume 70.99s
step 169200, loss 3.53, lr 0.000129, consume 71.00s
step 169300, loss 3.54, lr 0.000129, consume 71.00s
step 169400, loss 3.53, lr 0.000129, consume 70.99s
step 169500, loss 3.53, lr 0.000128, consume 70.98s
processing 125: english_c4/c4-train.00125-of-01024.txt, origin: 355739, samples: 172475, accum_tokens: 22407M, iter_num: 169593
step 169600, loss 3.53, lr 0.000128, consume 88.31s
step 169700, loss 3.54, lr 0.000128, consume 74.92s
step 169800, loss 3.53, lr 0.000128, consume 73.37s
step 169900, loss 3.53, lr 0.000127, consume 83.21s
step 170000, loss 3.52, lr 0.000127, consume 71.02s
step 170100, loss 3.53, lr 0.000127, consume 71.03s
step 170200, loss 3.53, lr 0.000127, consume 71.03s
step 170300, loss 3.53, lr 0.000126, consume 71.01s
step 170400, loss 3.53, lr 0.000126, consume 70.99s
step 170500, loss 3.53, lr 0.000126, consume 71.00s
step 170600, loss 3.53, lr 0.000126, consume 71.01s
step 170700, loss 3.53, lr 0.000125, consume 70.99s
step 170800, loss 3.54, lr 0.000125, consume 71.00s
step 170900, loss 3.53, lr 0.000125, consume 70.98s
processing 126: english_c4/c4-train.00126-of-01024.txt, origin: 355727, samples: 173142, accum_tokens: 22584M, iter_num: 170940
step 171000, loss 3.53, lr 0.000125, consume 91.14s
step 171100, loss 3.52, lr 0.000124, consume 73.43s
step 171200, loss 3.53, lr 0.000124, consume 84.42s
step 171300, loss 3.52, lr 0.000124, consume 70.97s
step 171400, loss 3.52, lr 0.000124, consume 71.01s
step 171500, loss 3.54, lr 0.000123, consume 71.02s
step 171600, loss 3.52, lr 0.000123, consume 71.01s
step 171700, loss 3.52, lr 0.000123, consume 71.01s
step 171800, loss 3.52, lr 0.000123, consume 70.99s
step 171900, loss 3.53, lr 0.000122, consume 70.99s
step 172000, loss 3.52, lr 0.000122, consume 70.99s
step 172100, loss 3.53, lr 0.000122, consume 70.98s
step 172200, loss 3.52, lr 0.000122, consume 70.98s
processing 127: english_c4/c4-train.00127-of-01024.txt, origin: 355694, samples: 173707, accum_tokens: 22762M, iter_num: 172293
step 172300, loss 3.52, lr 0.000121, consume 90.95s
step 172400, loss 3.53, lr 0.000121, consume 72.44s
step 172500, loss 3.53, lr 0.000121, consume 73.50s
step 172600, loss 3.53, lr 0.000121, consume 83.21s
step 172700, loss 3.53, lr 0.000120, consume 70.99s
step 172800, loss 3.52, lr 0.000120, consume 71.01s
step 172900, loss 3.53, lr 0.000120, consume 71.01s
step 173000, loss 3.52, lr 0.000120, consume 70.98s
step 173100, loss 3.53, lr 0.000119, consume 70.98s
step 173200, loss 3.52, lr 0.000119, consume 70.96s
step 173300, loss 3.53, lr 0.000119, consume 70.98s
step 173400, loss 3.52, lr 0.000119, consume 70.94s
step 173500, loss 3.53, lr 0.000118, consume 70.97s
step 173600, loss 3.52, lr 0.000118, consume 70.97s
processing 128: english_c4/c4-train.00128-of-01024.txt, origin: 355674, samples: 173011, accum_tokens: 22939M, iter_num: 173650
step 173700, loss 3.53, lr 0.000118, consume 91.25s
step 173800, loss 3.53, lr 0.000118, consume 73.07s
step 173900, loss 3.53, lr 0.000117, consume 84.65s
step 174000, loss 3.52, lr 0.000117, consume 70.90s
step 174100, loss 3.52, lr 0.000117, consume 70.96s
step 174200, loss 3.52, lr 0.000117, consume 70.96s
step 174300, loss 3.53, lr 0.000116, consume 70.95s
step 174400, loss 3.53, lr 0.000116, consume 70.95s
step 174500, loss 3.53, lr 0.000116, consume 70.94s
step 174600, loss 3.52, lr 0.000116, consume 70.94s
step 174700, loss 3.53, lr 0.000116, consume 70.95s
step 174800, loss 3.53, lr 0.000115, consume 70.93s
step 174900, loss 3.52, lr 0.000115, consume 70.92s
step 175000, loss 3.53, lr 0.000115, consume 70.94s
processing 129: english_c4/c4-train.00129-of-01024.txt, origin: 355708, samples: 173251, accum_tokens: 23117M, iter_num: 175001
step 175100, loss 3.52, lr 0.000115, consume 91.63s
step 175200, loss 3.52, lr 0.000114, consume 73.27s
step 175300, loss 3.52, lr 0.000114, consume 83.27s
step 175400, loss 3.53, lr 0.000114, consume 70.97s
step 175500, loss 3.53, lr 0.000114, consume 70.99s
step 175600, loss 3.53, lr 0.000113, consume 70.98s
step 175700, loss 3.52, lr 0.000113, consume 70.99s
step 175800, loss 3.53, lr 0.000113, consume 70.98s
step 175900, loss 3.53, lr 0.000113, consume 70.97s
step 176000, loss 3.53, lr 0.000112, consume 70.97s
step 176100, loss 3.51, lr 0.000112, consume 70.95s
step 176200, loss 3.53, lr 0.000112, consume 70.95s
step 176300, loss 3.52, lr 0.000112, consume 70.95s
processing 130: english_c4/c4-train.00130-of-01024.txt, origin: 355736, samples: 173644, accum_tokens: 23295M, iter_num: 176355
step 176400, loss 3.52, lr 0.000112, consume 91.51s
step 176500, loss 3.54, lr 0.000111, consume 72.66s
step 176600, loss 3.53, lr 0.000111, consume 84.73s
step 176700, loss 3.53, lr 0.000111, consume 70.82s
step 176800, loss 3.53, lr 0.000111, consume 71.00s
step 176900, loss 3.52, lr 0.000110, consume 71.00s
step 177000, loss 3.53, lr 0.000110, consume 70.98s
step 177100, loss 3.52, lr 0.000110, consume 71.00s
step 177200, loss 3.52, lr 0.000110, consume 70.99s
step 177300, loss 3.53, lr 0.000110, consume 70.98s
step 177400, loss 3.51, lr 0.000109, consume 70.97s
step 177500, loss 3.52, lr 0.000109, consume 70.99s
step 177600, loss 3.51, lr 0.000109, consume 70.98s
step 177700, loss 3.52, lr 0.000109, consume 70.98s
processing 131: english_c4/c4-train.00131-of-01024.txt, origin: 355750, samples: 173772, accum_tokens: 23473M, iter_num: 177711
step 177800, loss 3.53, lr 0.000108, consume 92.38s
step 177900, loss 3.53, lr 0.000108, consume 74.16s
step 178000, loss 3.52, lr 0.000108, consume 83.32s
step 178100, loss 3.53, lr 0.000108, consume 71.00s
step 178200, loss 3.53, lr 0.000108, consume 71.02s
step 178300, loss 3.52, lr 0.000107, consume 71.01s
step 178400, loss 3.53, lr 0.000107, consume 71.00s
step 178500, loss 3.52, lr 0.000107, consume 71.00s
step 178600, loss 3.53, lr 0.000107, consume 71.00s
step 178700, loss 3.52, lr 0.000106, consume 70.98s
step 178800, loss 3.53, lr 0.000106, consume 71.08s
step 178900, loss 3.53, lr 0.000106, consume 71.10s
step 179000, loss 3.52, lr 0.000106, consume 70.99s
processing 132: english_c4/c4-train.00132-of-01024.txt, origin: 355702, samples: 172972, accum_tokens: 23650M, iter_num: 179069
step 179100, loss 3.54, lr 0.000106, consume 45.58s
step 179200, loss 3.53, lr 0.000105, consume 72.04s
step 179300, loss 3.52, lr 0.000105, consume 85.73s
step 179400, loss 3.52, lr 0.000105, consume 70.75s
step 179500, loss 3.53, lr 0.000105, consume 70.85s
step 179600, loss 3.52, lr 0.000104, consume 71.00s
step 179700, loss 3.52, lr 0.000104, consume 71.03s
step 179800, loss 3.52, lr 0.000104, consume 71.01s
step 179900, loss 3.52, lr 0.000104, consume 71.01s
step 180000, loss 3.52, lr 0.000104, consume 71.02s
step 180100, loss 3.52, lr 0.000103, consume 71.01s
step 180200, loss 3.52, lr 0.000103, consume 71.01s
step 180300, loss 3.52, lr 0.000103, consume 71.02s
step 180400, loss 3.52, lr 0.000103, consume 70.99s
processing 133: english_c4/c4-train.00133-of-01024.txt, origin: 355720, samples: 173614, accum_tokens: 23827M, iter_num: 180420
step 180500, loss 3.53, lr 0.000103, consume 91.44s
step 180600, loss 3.52, lr 0.000102, consume 73.02s
step 180700, loss 3.52, lr 0.000102, consume 84.22s
step 180800, loss 3.53, lr 0.000102, consume 70.84s
step 180900, loss 3.53, lr 0.000102, consume 70.87s
step 181000, loss 3.53, lr 0.000102, consume 70.87s
step 181100, loss 3.52, lr 0.000101, consume 70.87s
step 181200, loss 3.52, lr 0.000101, consume 70.88s
step 181300, loss 3.52, lr 0.000101, consume 70.85s
step 181400, loss 3.52, lr 0.000101, consume 70.86s
step 181500, loss 3.52, lr 0.000101, consume 70.86s
step 181600, loss 3.52, lr 0.000100, consume 70.86s
step 181700, loss 3.52, lr 0.000100, consume 70.85s
processing 134: english_c4/c4-train.00134-of-01024.txt, origin: 355686, samples: 174027, accum_tokens: 24006M, iter_num: 181776
step 181800, loss 3.52, lr 0.000100, consume 90.62s
step 181900, loss 3.52, lr 0.000100, consume 72.10s
step 182000, loss 3.52, lr 0.000099, consume 85.44s
step 182100, loss 3.52, lr 0.000099, consume 70.80s
step 182200, loss 3.52, lr 0.000099, consume 70.85s
step 182300, loss 3.51, lr 0.000099, consume 70.87s
step 182400, loss 3.52, lr 0.000099, consume 70.87s
step 182500, loss 3.52, lr 0.000098, consume 70.85s
step 182600, loss 3.51, lr 0.000098, consume 70.86s
step 182700, loss 3.51, lr 0.000098, consume 70.85s
step 182800, loss 3.51, lr 0.000098, consume 70.85s
step 182900, loss 3.51, lr 0.000098, consume 70.84s
step 183000, loss 3.52, lr 0.000097, consume 70.85s
step 183100, loss 3.51, lr 0.000097, consume 70.84s
processing 135: english_c4/c4-train.00135-of-01024.txt, origin: 355704, samples: 173528, accum_tokens: 24183M, iter_num: 183136
step 183200, loss 3.52, lr 0.000097, consume 91.69s
step 183300, loss 3.52, lr 0.000097, consume 72.86s
step 183400, loss 3.52, lr 0.000097, consume 84.22s
step 183500, loss 3.53, lr 0.000097, consume 70.82s
step 183600, loss 3.52, lr 0.000096, consume 70.86s
step 183700, loss 3.51, lr 0.000096, consume 70.86s
step 183800, loss 3.53, lr 0.000096, consume 70.85s
step 183900, loss 3.51, lr 0.000096, consume 70.86s
step 184000, loss 3.52, lr 0.000096, consume 70.85s
step 184100, loss 3.51, lr 0.000095, consume 70.84s
step 184200, loss 3.51, lr 0.000095, consume 70.84s
step 184300, loss 3.51, lr 0.000095, consume 70.84s
step 184400, loss 3.52, lr 0.000095, consume 70.85s
processing 136: english_c4/c4-train.00136-of-01024.txt, origin: 355697, samples: 173062, accum_tokens: 24361M, iter_num: 184491
step 184500, loss 3.52, lr 0.000095, consume 90.85s
step 184600, loss 3.50, lr 0.000094, consume 72.13s
step 184700, loss 3.51, lr 0.000094, consume 85.83s
step 184800, loss 3.51, lr 0.000094, consume 70.75s
step 184900, loss 3.51, lr 0.000094, consume 70.87s
step 185000, loss 3.51, lr 0.000094, consume 70.85s
step 185100, loss 3.51, lr 0.000093, consume 70.87s
step 185200, loss 3.51, lr 0.000093, consume 70.84s
step 185300, loss 3.50, lr 0.000093, consume 70.84s
step 185400, loss 3.51, lr 0.000093, consume 70.84s
step 185500, loss 3.50, lr 0.000093, consume 70.84s
step 185600, loss 3.51, lr 0.000093, consume 70.85s
step 185700, loss 3.50, lr 0.000092, consume 70.82s
step 185800, loss 3.50, lr 0.000092, consume 70.84s
processing 137: english_c4/c4-train.00137-of-01024.txt, origin: 355730, samples: 173455, accum_tokens: 24538M, iter_num: 185843
step 185900, loss 3.51, lr 0.000092, consume 91.19s
step 186000, loss 3.52, lr 0.000092, consume 72.81s
step 186100, loss 3.52, lr 0.000092, consume 84.27s
step 186200, loss 3.52, lr 0.000091, consume 70.84s
step 186300, loss 3.52, lr 0.000091, consume 70.88s
step 186400, loss 3.51, lr 0.000091, consume 70.89s
step 186500, loss 3.51, lr 0.000091, consume 70.88s
step 186600, loss 3.51, lr 0.000091, consume 71.37s
step 186700, loss 3.52, lr 0.000090, consume 71.62s
step 186800, loss 3.52, lr 0.000090, consume 70.87s
step 186900, loss 3.51, lr 0.000090, consume 70.86s
step 187000, loss 3.52, lr 0.000090, consume 70.87s
step 187100, loss 3.51, lr 0.000090, consume 70.86s
processing 138: english_c4/c4-train.00138-of-01024.txt, origin: 355760, samples: 173301, accum_tokens: 24716M, iter_num: 187198
step 187200, loss 3.52, lr 0.000090, consume 88.19s
step 187300, loss 3.52, lr 0.000089, consume 74.58s
step 187400, loss 3.52, lr 0.000089, consume 73.15s
step 187500, loss 3.51, lr 0.000089, consume 83.01s
step 187600, loss 3.51, lr 0.000089, consume 70.89s
step 187700, loss 3.52, lr 0.000089, consume 70.91s
step 187800, loss 3.51, lr 0.000089, consume 70.91s
step 187900, loss 3.51, lr 0.000088, consume 70.91s
step 188000, loss 3.52, lr 0.000088, consume 70.88s
step 188100, loss 3.51, lr 0.000088, consume 70.88s
step 188200, loss 3.52, lr 0.000088, consume 70.88s
step 188300, loss 3.52, lr 0.000088, consume 70.88s
step 188400, loss 3.51, lr 0.000088, consume 70.85s
step 188500, loss 3.51, lr 0.000087, consume 70.85s
processing 139: english_c4/c4-train.00139-of-01024.txt, origin: 355716, samples: 174519, accum_tokens: 24894M, iter_num: 188552
step 188600, loss 3.51, lr 0.000087, consume 91.25s
step 188700, loss 3.50, lr 0.000087, consume 72.72s
step 188800, loss 3.50, lr 0.000087, consume 84.41s
step 188900, loss 3.50, lr 0.000087, consume 70.90s
step 189000, loss 3.50, lr 0.000086, consume 70.95s
step 189100, loss 3.50, lr 0.000086, consume 70.96s
step 189200, loss 3.50, lr 0.000086, consume 70.96s
step 189300, loss 3.50, lr 0.000086, consume 70.96s
step 189400, loss 3.51, lr 0.000086, consume 70.94s
step 189500, loss 3.51, lr 0.000086, consume 70.94s
step 189600, loss 3.50, lr 0.000085, consume 70.94s
step 189700, loss 3.50, lr 0.000085, consume 70.93s
step 189800, loss 3.50, lr 0.000085, consume 70.93s
step 189900, loss 3.51, lr 0.000085, consume 70.94s
processing 140: english_c4/c4-train.00140-of-01024.txt, origin: 355749, samples: 174370, accum_tokens: 25073M, iter_num: 189915
step 190000, loss 3.50, lr 0.000085, consume 91.64s
step 190100, loss 3.50, lr 0.000085, consume 73.86s
step 190200, loss 3.50, lr 0.000085, consume 83.00s
step 190300, loss 3.50, lr 0.000084, consume 70.97s
step 190400, loss 3.51, lr 0.000084, consume 71.03s
step 190500, loss 3.50, lr 0.000084, consume 71.00s
step 190600, loss 3.50, lr 0.000084, consume 70.99s
step 190700, loss 3.49, lr 0.000084, consume 71.01s
step 190800, loss 3.50, lr 0.000084, consume 70.98s
step 190900, loss 3.50, lr 0.000083, consume 71.00s
step 191000, loss 3.50, lr 0.000083, consume 70.98s
step 191100, loss 3.50, lr 0.000083, consume 70.99s
step 191200, loss 3.51, lr 0.000083, consume 70.97s
processing 141: english_c4/c4-train.00141-of-01024.txt, origin: 355737, samples: 172895, accum_tokens: 25250M, iter_num: 191277
step 191300, loss 3.51, lr 0.000083, consume 90.95s
step 191400, loss 3.51, lr 0.000083, consume 72.76s
step 191500, loss 3.52, lr 0.000082, consume 84.64s
step 191600, loss 3.51, lr 0.000082, consume 70.92s
step 191700, loss 3.51, lr 0.000082, consume 71.01s
step 191800, loss 3.51, lr 0.000082, consume 71.02s
step 191900, loss 3.52, lr 0.000082, consume 71.03s
step 192000, loss 3.51, lr 0.000082, consume 71.01s
step 192100, loss 3.51, lr 0.000082, consume 71.00s
step 192200, loss 3.51, lr 0.000081, consume 70.98s
step 192300, loss 3.51, lr 0.000081, consume 71.01s
step 192400, loss 3.51, lr 0.000081, consume 70.99s
step 192500, loss 3.50, lr 0.000081, consume 71.01s
step 192600, loss 3.51, lr 0.000081, consume 70.97s
processing 142: english_c4/c4-train.00142-of-01024.txt, origin: 355716, samples: 173350, accum_tokens: 25427M, iter_num: 192628
step 192700, loss 3.50, lr 0.000081, consume 91.65s
step 192800, loss 3.50, lr 0.000080, consume 73.80s
step 192900, loss 3.51, lr 0.000080, consume 83.20s
step 193000, loss 3.51, lr 0.000080, consume 70.93s
step 193100, loss 3.51, lr 0.000080, consume 71.01s
step 193200, loss 3.50, lr 0.000080, consume 71.02s
step 193300, loss 3.50, lr 0.000080, consume 71.02s
step 193400, loss 3.51, lr 0.000080, consume 71.01s
step 193500, loss 3.50, lr 0.000079, consume 71.01s
step 193600, loss 3.51, lr 0.000079, consume 70.99s
step 193700, loss 3.51, lr 0.000079, consume 71.00s
step 193800, loss 3.51, lr 0.000079, consume 70.99s
step 193900, loss 3.49, lr 0.000079, consume 71.00s
processing 143: english_c4/c4-train.00143-of-01024.txt, origin: 355735, samples: 174165, accum_tokens: 25606M, iter_num: 193982
step 194000, loss 3.51, lr 0.000079, consume 90.87s
step 194100, loss 3.51, lr 0.000079, consume 72.56s
step 194200, loss 3.50, lr 0.000078, consume 85.46s
step 194300, loss 3.50, lr 0.000078, consume 70.80s
step 194400, loss 3.51, lr 0.000078, consume 71.02s
step 194500, loss 3.50, lr 0.000078, consume 71.04s
step 194600, loss 3.50, lr 0.000078, consume 71.04s
step 194700, loss 3.50, lr 0.000078, consume 71.02s
step 194800, loss 3.50, lr 0.000078, consume 71.04s
step 194900, loss 3.50, lr 0.000077, consume 71.01s
step 195000, loss 3.50, lr 0.000077, consume 71.00s
step 195100, loss 3.51, lr 0.000077, consume 71.02s
step 195200, loss 3.50, lr 0.000077, consume 71.01s
step 195300, loss 3.50, lr 0.000077, consume 71.00s
processing 144: english_c4/c4-train.00144-of-01024.txt, origin: 355741, samples: 174067, accum_tokens: 25784M, iter_num: 195343
step 195400, loss 3.51, lr 0.000077, consume 91.30s
step 195500, loss 3.50, lr 0.000077, consume 72.58s
step 195600, loss 3.51, lr 0.000077, consume 84.32s
step 195700, loss 3.50, lr 0.000076, consume 70.90s
step 195800, loss 3.50, lr 0.000076, consume 71.02s
step 195900, loss 3.51, lr 0.000076, consume 71.01s
step 196000, loss 3.51, lr 0.000076, consume 71.02s
step 196100, loss 3.50, lr 0.000076, consume 71.00s
step 196200, loss 3.51, lr 0.000076, consume 71.02s
step 196300, loss 3.51, lr 0.000076, consume 71.01s
step 196400, loss 3.50, lr 0.000075, consume 71.00s
step 196500, loss 3.51, lr 0.000075, consume 71.00s
step 196600, loss 3.51, lr 0.000075, consume 71.00s
step 196700, loss 3.51, lr 0.000075, consume 70.98s
processing 145: english_c4/c4-train.00145-of-01024.txt, origin: 355687, samples: 173329, accum_tokens: 25962M, iter_num: 196702
step 196800, loss 3.51, lr 0.000075, consume 92.38s
step 196900, loss 3.50, lr 0.000075, consume 73.42s
step 197000, loss 3.50, lr 0.000075, consume 83.03s
step 197100, loss 3.50, lr 0.000075, consume 70.96s
step 197200, loss 3.51, lr 0.000074, consume 71.01s
step 197300, loss 3.51, lr 0.000074, consume 71.02s
step 197400, loss 3.50, lr 0.000074, consume 71.02s
step 197500, loss 3.50, lr 0.000074, consume 71.00s
step 197600, loss 3.50, lr 0.000074, consume 71.02s
step 197700, loss 3.50, lr 0.000074, consume 70.99s
step 197800, loss 3.50, lr 0.000074, consume 70.99s
step 197900, loss 3.49, lr 0.000074, consume 71.00s
step 198000, loss 3.50, lr 0.000073, consume 71.00s
processing 146: english_c4/c4-train.00146-of-01024.txt, origin: 355690, samples: 173906, accum_tokens: 26140M, iter_num: 198056
step 198100, loss 3.51, lr 0.000073, consume 91.25s
step 198200, loss 3.51, lr 0.000073, consume 72.47s
step 198300, loss 3.50, lr 0.000073, consume 85.71s
step 198400, loss 3.50, lr 0.000073, consume 70.94s
step 198500, loss 3.50, lr 0.000073, consume 71.01s
step 198600, loss 3.50, lr 0.000073, consume 71.02s
step 198700, loss 3.50, lr 0.000073, consume 71.02s
step 198800, loss 3.50, lr 0.000073, consume 71.02s
step 198900, loss 3.51, lr 0.000072, consume 71.00s
step 199000, loss 3.50, lr 0.000072, consume 71.01s
step 199100, loss 3.50, lr 0.000072, consume 71.00s
step 199200, loss 3.50, lr 0.000072, consume 71.00s
step 199300, loss 3.50, lr 0.000072, consume 71.03s
step 199400, loss 3.50, lr 0.000072, consume 71.02s
processing 147: english_c4/c4-train.00147-of-01024.txt, origin: 355697, samples: 174642, accum_tokens: 26318M, iter_num: 199415
step 199500, loss 3.50, lr 0.000072, consume 91.26s
step 199600, loss 3.50, lr 0.000072, consume 73.07s
step 199700, loss 3.50, lr 0.000071, consume 84.32s
step 199800, loss 3.50, lr 0.000071, consume 70.98s
step 199900, loss 3.52, lr 0.000071, consume 71.04s
step 200000, loss 3.50, lr 0.000071, consume 71.03s
step 200100, loss 3.50, lr 0.000071, consume 71.04s
step 200200, loss 3.51, lr 0.000071, consume 71.01s
step 200300, loss 3.50, lr 0.000071, consume 71.00s
step 200400, loss 3.50, lr 0.000071, consume 71.02s
step 200500, loss 3.50, lr 0.000071, consume 71.01s
step 200600, loss 3.49, lr 0.000070, consume 71.01s
step 200700, loss 3.51, lr 0.000070, consume 71.01s
processing 148: english_c4/c4-train.00148-of-01024.txt, origin: 355705, samples: 173179, accum_tokens: 26496M, iter_num: 200779
step 200800, loss 3.49, lr 0.000070, consume 91.03s
step 200900, loss 3.50, lr 0.000070, consume 72.47s
step 201000, loss 3.51, lr 0.000070, consume 85.63s
step 201100, loss 3.49, lr 0.000070, consume 70.82s
step 201200, loss 3.50, lr 0.000070, consume 71.01s
step 201300, loss 3.50, lr 0.000070, consume 71.04s
step 201400, loss 3.50, lr 0.000070, consume 71.03s
step 201500, loss 3.51, lr 0.000070, consume 71.02s
step 201600, loss 3.50, lr 0.000069, consume 71.01s
step 201700, loss 3.50, lr 0.000069, consume 71.01s
step 201800, loss 3.50, lr 0.000069, consume 71.03s
step 201900, loss 3.50, lr 0.000069, consume 71.01s
step 202000, loss 3.51, lr 0.000069, consume 71.02s
step 202100, loss 3.50, lr 0.000069, consume 71.00s
processing 149: english_c4/c4-train.00149-of-01024.txt, origin: 355691, samples: 173083, accum_tokens: 26673M, iter_num: 202132
step 202200, loss 3.50, lr 0.000069, consume 91.22s
step 202300, loss 3.51, lr 0.000069, consume 72.89s
step 202400, loss 3.50, lr 0.000069, consume 84.36s
step 202500, loss 3.51, lr 0.000069, consume 70.95s
step 202600, loss 3.50, lr 0.000068, consume 71.01s
step 202700, loss 3.50, lr 0.000068, consume 71.00s
step 202800, loss 3.50, lr 0.000068, consume 70.98s
step 202900, loss 3.50, lr 0.000068, consume 70.99s
step 203000, loss 3.50, lr 0.000068, consume 70.98s
step 203100, loss 3.50, lr 0.000068, consume 70.97s
step 203200, loss 3.51, lr 0.000068, consume 70.99s
step 203300, loss 3.50, lr 0.000068, consume 70.97s
step 203400, loss 3.50, lr 0.000068, consume 70.97s
processing 150: english_c4/c4-train.00150-of-01024.txt, origin: 355699, samples: 173333, accum_tokens: 26851M, iter_num: 203484
step 203500, loss 3.50, lr 0.000068, consume 90.61s
step 203600, loss 3.50, lr 0.000068, consume 72.76s
step 203700, loss 3.50, lr 0.000067, consume 84.29s
step 203800, loss 3.49, lr 0.000067, consume 70.90s
step 203900, loss 3.49, lr 0.000067, consume 70.98s
step 204000, loss 3.50, lr 0.000067, consume 71.01s
step 204100, loss 3.50, lr 0.000067, consume 70.99s
step 204200, loss 3.49, lr 0.000067, consume 70.98s
step 204300, loss 3.50, lr 0.000067, consume 70.97s
step 204400, loss 3.50, lr 0.000067, consume 70.97s
step 204500, loss 3.49, lr 0.000067, consume 70.95s
step 204600, loss 3.50, lr 0.000067, consume 70.95s
step 204700, loss 3.50, lr 0.000067, consume 70.96s
step 204800, loss 3.50, lr 0.000066, consume 70.96s
processing 151: english_c4/c4-train.00151-of-01024.txt, origin: 355716, samples: 171343, accum_tokens: 27026M, iter_num: 204838
step 204900, loss 3.50, lr 0.000066, consume 91.31s
step 205000, loss 3.51, lr 0.000066, consume 72.63s
step 205100, loss 3.50, lr 0.000066, consume 84.13s
step 205200, loss 3.50, lr 0.000066, consume 70.86s
step 205300, loss 3.50, lr 0.000066, consume 71.00s
step 205400, loss 3.50, lr 0.000066, consume 71.01s
step 205500, loss 3.50, lr 0.000066, consume 71.00s
step 205600, loss 3.50, lr 0.000066, consume 70.98s
step 205700, loss 3.50, lr 0.000066, consume 70.99s
step 205800, loss 3.50, lr 0.000066, consume 70.99s
step 205900, loss 3.50, lr 0.000066, consume 70.98s
step 206000, loss 3.50, lr 0.000065, consume 70.98s
step 206100, loss 3.50, lr 0.000065, consume 70.98s
processing 152: english_c4/c4-train.00152-of-01024.txt, origin: 355655, samples: 174156, accum_tokens: 27204M, iter_num: 206176
step 206200, loss 3.50, lr 0.000065, consume 90.83s
step 206300, loss 3.50, lr 0.000065, consume 73.05s
step 206400, loss 3.50, lr 0.000065, consume 84.48s
step 206500, loss 3.50, lr 0.000065, consume 70.89s
step 206600, loss 3.50, lr 0.000065, consume 71.01s
step 206700, loss 3.50, lr 0.000065, consume 71.29s
step 206800, loss 3.50, lr 0.000065, consume 71.14s
step 206900, loss 3.49, lr 0.000065, consume 71.00s
step 207000, loss 3.49, lr 0.000065, consume 71.02s
step 207100, loss 3.49, lr 0.000065, consume 71.01s
step 207200, loss 3.49, lr 0.000065, consume 71.02s
step 207300, loss 3.49, lr 0.000065, consume 71.04s
step 207400, loss 3.49, lr 0.000064, consume 70.99s
step 207500, loss 3.50, lr 0.000064, consume 71.02s
processing 153: english_c4/c4-train.00153-of-01024.txt, origin: 355697, samples: 172925, accum_tokens: 27381M, iter_num: 207537
step 207600, loss 3.50, lr 0.000064, consume 91.52s
step 207700, loss 3.51, lr 0.000064, consume 72.93s
step 207800, loss 3.50, lr 0.000064, consume 84.42s
step 207900, loss 3.51, lr 0.000064, consume 70.98s
step 208000, loss 3.50, lr 0.000064, consume 71.03s
step 208100, loss 3.50, lr 0.000064, consume 71.02s
step 208200, loss 3.50, lr 0.000064, consume 71.04s
step 208300, loss 3.50, lr 0.000064, consume 71.01s
step 208400, loss 3.49, lr 0.000064, consume 71.03s
step 208500, loss 3.50, lr 0.000064, consume 71.02s
step 208600, loss 3.50, lr 0.000064, consume 71.01s
step 208700, loss 3.49, lr 0.000064, consume 71.02s
step 208800, loss 3.50, lr 0.000064, consume 71.02s
processing 154: english_c4/c4-train.00154-of-01024.txt, origin: 355766, samples: 174305, accum_tokens: 27560M, iter_num: 208888
step 208900, loss 3.50, lr 0.000063, consume 90.88s
step 209000, loss 3.50, lr 0.000063, consume 72.12s
step 209100, loss 3.50, lr 0.000063, consume 85.59s
step 209200, loss 3.50, lr 0.000063, consume 70.77s
step 209300, loss 3.50, lr 0.000063, consume 71.05s
step 209400, loss 3.49, lr 0.000063, consume 71.05s
step 209500, loss 3.50, lr 0.000063, consume 71.04s
step 209600, loss 3.50, lr 0.000063, consume 71.03s
step 209700, loss 3.49, lr 0.000063, consume 71.02s
step 209800, loss 3.50, lr 0.000063, consume 71.00s
step 209900, loss 3.49, lr 0.000063, consume 71.01s
step 210000, loss 3.50, lr 0.000063, consume 71.06s
step 210100, loss 3.50, lr 0.000063, consume 71.16s
step 210200, loss 3.49, lr 0.000063, consume 71.18s
processing 155: english_c4/c4-train.00155-of-01024.txt, origin: 355708, samples: 172915, accum_tokens: 27737M, iter_num: 210249
step 210300, loss 3.50, lr 0.000063, consume 91.62s
step 210400, loss 3.51, lr 0.000063, consume 72.72s
step 210500, loss 3.50, lr 0.000063, consume 84.67s
step 210600, loss 3.50, lr 0.000062, consume 70.99s
step 210700, loss 3.51, lr 0.000062, consume 71.20s
step 210800, loss 3.50, lr 0.000062, consume 71.19s
step 210900, loss 3.50, lr 0.000062, consume 71.17s
step 211000, loss 3.50, lr 0.000062, consume 71.18s
step 211100, loss 3.50, lr 0.000062, consume 71.18s
step 211200, loss 3.50, lr 0.000062, consume 71.17s
step 211300, loss 3.50, lr 0.000062, consume 71.17s
step 211400, loss 3.49, lr 0.000062, consume 71.18s
step 211500, loss 3.50, lr 0.000062, consume 71.17s
step 211600, loss 3.50, lr 0.000062, consume 71.16s
processing 156: english_c4/c4-train.00156-of-01024.txt, origin: 355664, samples: 173891, accum_tokens: 27915M, iter_num: 211600
step 211700, loss 3.50, lr 0.000062, consume 91.71s
step 211800, loss 3.51, lr 0.000062, consume 73.09s
step 211900, loss 3.50, lr 0.000062, consume 84.61s
step 212000, loss 3.50, lr 0.000062, consume 71.17s
step 212100, loss 3.50, lr 0.000062, consume 71.20s
step 212200, loss 3.50, lr 0.000062, consume 71.22s
step 212300, loss 3.50, lr 0.000062, consume 71.17s
step 212400, loss 3.50, lr 0.000062, consume 71.18s
step 212500, loss 3.50, lr 0.000062, consume 71.17s
step 212600, loss 3.50, lr 0.000062, consume 71.17s
step 212700, loss 3.50, lr 0.000061, consume 71.15s
step 212800, loss 3.49, lr 0.000061, consume 71.13s
step 212900, loss 3.50, lr 0.000061, consume 71.14s
processing 157: english_c4/c4-train.00157-of-01024.txt, origin: 355698, samples: 174157, accum_tokens: 28093M, iter_num: 212959
step 213000, loss 3.50, lr 0.000061, consume 91.12s
step 213100, loss 3.50, lr 0.000061, consume 72.60s
step 213200, loss 3.50, lr 0.000061, consume 85.60s
step 213300, loss 3.50, lr 0.000061, consume 71.10s
step 213400, loss 3.49, lr 0.000061, consume 71.16s
step 213500, loss 3.49, lr 0.000061, consume 71.18s
step 213600, loss 3.50, lr 0.000061, consume 71.14s
step 213700, loss 3.50, lr 0.000061, consume 71.17s
step 213800, loss 3.49, lr 0.000061, consume 71.15s
step 213900, loss 3.50, lr 0.000061, consume 71.19s
step 214000, loss 3.49, lr 0.000061, consume 71.17s
step 214100, loss 3.49, lr 0.000061, consume 71.10s
step 214200, loss 3.50, lr 0.000061, consume 71.11s
step 214300, loss 3.50, lr 0.000061, consume 71.07s
processing 158: english_c4/c4-train.00158-of-01024.txt, origin: 355665, samples: 174283, accum_tokens: 28272M, iter_num: 214319
step 214400, loss 3.50, lr 0.000061, consume 91.62s
step 214500, loss 3.49, lr 0.000061, consume 74.16s
^[	step 214600, loss 3.49, lr 0.000061, consume 83.39s
step 214700, loss 3.49, lr 0.000061, consume 71.15s
step 214800, loss 3.49, lr 0.000061, consume 71.17s
step 214900, loss 3.51, lr 0.000061, consume 71.18s
step 215000, loss 3.49, lr 0.000061, consume 71.16s
step 215100, loss 3.50, lr 0.000061, consume 71.15s
step 215200, loss 3.50, lr 0.000061, consume 71.16s
step 215300, loss 3.50, lr 0.000061, consume 71.15s
step 215400, loss 3.49, lr 0.000061, consume 71.13s
step 215500, loss 3.49, lr 0.000061, consume 71.14s
step 215600, loss 3.49, lr 0.000061, consume 71.16s
processing 159: english_c4/c4-train.00159-of-01024.txt, origin: 355719, samples: 173581, accum_tokens: 28450M, iter_num: 215681
step 215700, loss 3.49, lr 0.000061, consume 90.82s
step 215800, loss 3.51, lr 0.000060, consume 72.88s
step 215900, loss 3.49, lr 0.000060, consume 86.01s
step 216000, loss 3.50, lr 0.000060, consume 71.06s
step 216100, loss 3.49, lr 0.000060, consume 71.16s
step 216200, loss 3.50, lr 0.000060, consume 71.18s
step 216300, loss 3.50, lr 0.000060, consume 71.18s
step 216400, loss 3.49, lr 0.000060, consume 71.16s
step 216500, loss 3.49, lr 0.000060, consume 71.16s
step 216600, loss 3.50, lr 0.000060, consume 71.13s
step 216700, loss 3.50, lr 0.000060, consume 71.14s
step 216800, loss 3.49, lr 0.000060, consume 71.14s
step 216900, loss 3.49, lr 0.000060, consume 71.13s
step 217000, loss 3.49, lr 0.000060, consume 71.15s
processing 160: english_c4/c4-train.00160-of-01024.txt, origin: 355744, samples: 173680, accum_tokens: 28627M, iter_num: 217037
step 217100, loss 3.49, lr 0.000060, consume 91.49s
step 217200, loss 3.49, lr 0.000060, consume 73.00s
step 217300, loss 3.49, lr 0.000060, consume 85.06s
step 217400, loss 3.49, lr 0.000060, consume 71.13s
step 217500, loss 3.49, lr 0.000060, consume 71.17s
step 217600, loss 3.50, lr 0.000060, consume 71.17s
step 217700, loss 3.49, lr 0.000060, consume 71.14s
step 217800, loss 3.50, lr 0.000060, consume 71.12s
step 217900, loss 3.50, lr 0.000060, consume 71.13s
step 218000, loss 3.50, lr 0.000060, consume 71.11s
step 218100, loss 3.50, lr 0.000060, consume 71.12s
step 218200, loss 3.50, lr 0.000060, consume 71.12s
step 218300, loss 3.50, lr 0.000060, consume 71.12s
processing 161: english_c4/c4-train.00161-of-01024.txt, origin: 355728, samples: 173473, accum_tokens: 28805M, iter_num: 218393
step 218400, loss 3.49, lr 0.000060, consume 91.06s
step 218500, loss 3.50, lr 0.000060, consume 72.35s
step 218600, loss 3.50, lr 0.000060, consume 73.55s
step 218700, loss 3.50, lr 0.000060, consume 83.22s
step 218800, loss 3.50, lr 0.000060, consume 71.15s
step 218900, loss 3.50, lr 0.000060, consume 71.17s
step 219000, loss 3.50, lr 0.000060, consume 71.19s
step 219100, loss 3.49, lr 0.000060, consume 71.15s
step 219200, loss 3.50, lr 0.000060, consume 71.12s
step 219300, loss 3.49, lr 0.000060, consume 71.12s
step 219400, loss 3.50, lr 0.000060, consume 71.13s
step 219500, loss 3.49, lr 0.000060, consume 71.13s
step 219600, loss 3.49, lr 0.000060, consume 71.11s
step 219700, loss 3.49, lr 0.000060, consume 71.12s
processing 162: english_c4/c4-train.00162-of-01024.txt, origin: 355747, samples: 174426, accum_tokens: 28984M, iter_num: 219749
step 219800, loss 3.49, lr 0.000060, consume 91.24s
step 219900, loss 3.50, lr 0.000060, consume 72.81s
step 220000, loss 3.50, lr 0.000060, consume 84.45s
step 220100, loss 3.49, lr 0.000060, consume 71.09s
step 220200, loss 3.49, lr 0.000060, consume 71.16s
step 220300, loss 3.48, lr 0.000060, consume 71.17s
step 220400, loss 3.49, lr 0.000060, consume 71.17s
step 220500, loss 3.49, lr 0.000060, consume 71.14s
step 220600, loss 3.50, lr 0.000060, consume 71.14s
step 220700, loss 3.49, lr 0.000060, consume 71.15s
step 220800, loss 3.49, lr 0.000060, consume 71.15s
step 220900, loss 3.49, lr 0.000060, consume 71.14s
step 221000, loss 3.49, lr 0.000060, consume 71.13s
step 221100, loss 3.49, lr 0.000060, consume 71.03s
