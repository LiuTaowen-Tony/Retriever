@dataclass
class RerieverConfig_29M:
    batch_size = 32
    gradient_accumulation_steps = 4
    sequence_length = 1024
    learning_rate = 6e-4
    min_lr = 6e-5
    vocab_size = 32000
    num_layers = 6
    hidden_size = 512
    num_heads = 8
    beta1 = 0.9
    beta2 = 0.95
    weight_decay = 1e-1
    warmup_iters = 2000
    max_iters = 80000
    lr_decay_iters = 80000
    grad_clip = 1.0

num decayed parameter tensors: 38, with 29,491,200 parameters
num non-decayed parameter tensors: 13, with 6,656 parameters
number of total parameters: 28.97M
all train file nums: 1024
preparing first dataset file english_c4/c4-train.00000-of-01024.txt
finished, consume: 112s
processing 0: english_c4/c4-train.00000-of-01024.txt, origin: 355732, samples: 173721, accum_tokens: 177M, iter_num: 0
step 100, loss 9.52, lr 0.000030, consume 102.28s
step 200, loss 7.82, lr 0.000060, consume 86.63s
step 300, loss 6.80, lr 0.000090, consume 71.16s
step 400, loss 6.38, lr 0.000120, consume 70.92s
step 500, loss 6.17, lr 0.000150, consume 70.98s
step 600, loss 6.01, lr 0.000180, consume 71.00s
step 700, loss 5.85, lr 0.000210, consume 71.00s
step 800, loss 5.70, lr 0.000240, consume 70.98s
step 900, loss 5.57, lr 0.000270, consume 70.97s
step 1000, loss 5.44, lr 0.000300, consume 70.96s
step 1100, loss 5.32, lr 0.000330, consume 71.31s
step 1200, loss 5.21, lr 0.000360, consume 71.13s
step 1300, loss 5.11, lr 0.000390, consume 71.13s
processing 1: english_c4/c4-train.00001-of-01024.txt, origin: 355708, samples: 173229, accum_tokens: 355M, iter_num: 1357
step 1400, loss 5.02, lr 0.000420, consume 82.37s
step 1500, loss 4.91, lr 0.000450, consume 72.67s
step 1600, loss 4.79, lr 0.000480, consume 85.49s
step 1700, loss 4.68, lr 0.000510, consume 71.09s
step 1800, loss 4.60, lr 0.000540, consume 71.13s
step 1900, loss 4.53, lr 0.000570, consume 71.12s
step 2000, loss 4.49, lr 0.000600, consume 71.13s
step 2100, loss 4.43, lr 0.000600, consume 71.13s
step 2200, loss 4.39, lr 0.000600, consume 71.13s
step 2300, loss 4.34, lr 0.000600, consume 71.13s
step 2400, loss 4.30, lr 0.000600, consume 71.12s
step 2500, loss 4.27, lr 0.000600, consume 71.12s
step 2600, loss 4.24, lr 0.000600, consume 71.11s
step 2700, loss 4.23, lr 0.000600, consume 71.10s
processing 2: english_c4/c4-train.00002-of-01024.txt, origin: 355718, samples: 173903, accum_tokens: 533M, iter_num: 2710
step 2800, loss 4.20, lr 0.000600, consume 91.84s
step 2900, loss 4.19, lr 0.000600, consume 73.61s
step 3000, loss 4.16, lr 0.000600, consume 83.12s
step 3100, loss 4.14, lr 0.000600, consume 71.13s
step 3200, loss 4.14, lr 0.000600, consume 71.16s
step 3300, loss 4.12, lr 0.000600, consume 71.16s
step 3400, loss 4.10, lr 0.000600, consume 71.17s
step 3500, loss 4.08, lr 0.000600, consume 71.18s
step 3600, loss 4.07, lr 0.000599, consume 71.16s
step 3700, loss 4.06, lr 0.000599, consume 71.16s
step 3800, loss 4.05, lr 0.000599, consume 71.16s
step 3900, loss 4.04, lr 0.000599, consume 71.16s
step 4000, loss 4.03, lr 0.000599, consume 71.17s
processing 3: english_c4/c4-train.00003-of-01024.txt, origin: 355753, samples: 173350, accum_tokens: 710M, iter_num: 4068
step 4100, loss 4.02, lr 0.000599, consume 90.89s
step 4200, loss 4.01, lr 0.000599, consume 73.16s
step 4300, loss 4.01, lr 0.000599, consume 85.67s
step 4400, loss 4.00, lr 0.000599, consume 71.06s
step 4500, loss 3.98, lr 0.000599, consume 71.16s
step 4600, loss 3.98, lr 0.000599, consume 71.17s
step 4700, loss 3.97, lr 0.000598, consume 71.15s
step 4800, loss 3.97, lr 0.000598, consume 71.17s
step 4900, loss 3.96, lr 0.000598, consume 71.16s
step 5000, loss 3.95, lr 0.000598, consume 71.16s
step 5100, loss 3.94, lr 0.000598, consume 71.17s
step 5200, loss 3.94, lr 0.000598, consume 71.16s
step 5300, loss 3.93, lr 0.000598, consume 71.16s
step 5400, loss 3.92, lr 0.000597, consume 71.15s
processing 4: english_c4/c4-train.00004-of-01024.txt, origin: 355691, samples: 173171, accum_tokens: 888M, iter_num: 5423
step 5500, loss 3.93, lr 0.000597, consume 92.12s
step 5600, loss 3.92, lr 0.000597, consume 73.32s
step 5700, loss 3.92, lr 0.000597, consume 84.38s
step 5800, loss 3.92, lr 0.000597, consume 71.12s
step 5900, loss 3.91, lr 0.000597, consume 71.16s
step 6000, loss 3.91, lr 0.000597, consume 71.17s
step 6100, loss 3.91, lr 0.000596, consume 71.17s
step 6200, loss 3.89, lr 0.000596, consume 71.16s
step 6300, loss 3.90, lr 0.000596, consume 71.28s
step 6400, loss 3.89, lr 0.000596, consume 71.00s
step 6500, loss 3.89, lr 0.000596, consume 70.98s
step 6600, loss 3.88, lr 0.000595, consume 70.96s
step 6700, loss 3.87, lr 0.000595, consume 70.96s
processing 5: english_c4/c4-train.00005-of-01024.txt, origin: 355717, samples: 172927, accum_tokens: 1065M, iter_num: 6775
step 6800, loss 3.88, lr 0.000595, consume 90.69s
step 6900, loss 3.87, lr 0.000595, consume 72.39s
step 7000, loss 3.86, lr 0.000595, consume 85.55s
step 7100, loss 3.87, lr 0.000594, consume 70.76s
step 7200, loss 3.87, lr 0.000594, consume 70.99s
step 7300, loss 3.86, lr 0.000594, consume 71.03s
step 7400, loss 3.86, lr 0.000594, consume 71.00s
step 7500, loss 3.85, lr 0.000593, consume 71.00s
step 7600, loss 3.85, lr 0.000593, consume 71.00s
step 7700, loss 3.85, lr 0.000593, consume 70.98s
step 7800, loss 3.84, lr 0.000593, consume 70.98s
step 7900, loss 3.84, lr 0.000592, consume 70.98s
step 8000, loss 3.84, lr 0.000592, consume 70.99s
step 8100, loss 3.83, lr 0.000592, consume 71.00s
processing 6: english_c4/c4-train.00006-of-01024.txt, origin: 355747, samples: 173252, accum_tokens: 1242M, iter_num: 8126
step 8200, loss 3.83, lr 0.000592, consume 91.38s
step 8300, loss 3.84, lr 0.000591, consume 72.68s
step 8400, loss 3.83, lr 0.000591, consume 84.11s
step 8500, loss 3.82, lr 0.000591, consume 70.95s
step 8600, loss 3.83, lr 0.000591, consume 71.01s
step 8700, loss 3.82, lr 0.000590, consume 71.00s
step 8800, loss 3.82, lr 0.000590, consume 71.02s
step 8900, loss 3.81, lr 0.000590, consume 71.00s
step 9000, loss 3.81, lr 0.000589, consume 71.00s
step 9100, loss 3.82, lr 0.000589, consume 70.99s
step 9200, loss 3.80, lr 0.000589, consume 71.01s
step 9300, loss 3.80, lr 0.000588, consume 71.00s
step 9400, loss 3.81, lr 0.000588, consume 70.99s
processing 7: english_c4/c4-train.00007-of-01024.txt, origin: 355719, samples: 173288, accum_tokens: 1420M, iter_num: 9480
step 9500, loss 3.80, lr 0.000588, consume 90.71s
step 9600, loss 3.81, lr 0.000587, consume 72.55s
step 9700, loss 3.81, lr 0.000587, consume 84.59s
step 9800, loss 3.80, lr 0.000587, consume 70.74s
step 9900, loss 3.80, lr 0.000586, consume 70.98s
step 10000, loss 3.80, lr 0.000586, consume 70.99s
step 10100, loss 3.80, lr 0.000586, consume 71.00s
step 10200, loss 3.80, lr 0.000585, consume 71.00s
step 10300, loss 3.80, lr 0.000585, consume 71.00s
step 10400, loss 3.79, lr 0.000585, consume 71.00s
step 10500, loss 3.79, lr 0.000584, consume 71.00s
step 10600, loss 3.79, lr 0.000584, consume 70.99s
step 10700, loss 3.78, lr 0.000584, consume 70.98s
step 10800, loss 3.78, lr 0.000583, consume 70.99s
processing 8: english_c4/c4-train.00008-of-01024.txt, origin: 355746, samples: 173024, accum_tokens: 1597M, iter_num: 10833
step 10900, loss 3.78, lr 0.000583, consume 91.25s
step 11000, loss 3.79, lr 0.000582, consume 73.72s
step 11100, loss 3.79, lr 0.000582, consume 83.38s
step 11200, loss 3.78, lr 0.000582, consume 70.93s
step 11300, loss 3.78, lr 0.000581, consume 71.00s
step 11400, loss 3.78, lr 0.000581, consume 71.03s
step 11500, loss 3.78, lr 0.000580, consume 71.01s
step 11600, loss 3.78, lr 0.000580, consume 71.00s
step 11700, loss 3.76, lr 0.000580, consume 70.99s
step 11800, loss 3.77, lr 0.000579, consume 70.98s
step 11900, loss 3.76, lr 0.000579, consume 70.98s
step 12000, loss 3.77, lr 0.000578, consume 70.97s
step 12100, loss 3.77, lr 0.000578, consume 70.97s
processing 9: english_c4/c4-train.00009-of-01024.txt, origin: 355708, samples: 172984, accum_tokens: 1774M, iter_num: 12185
step 12200, loss 3.76, lr 0.000578, consume 90.82s
step 12300, loss 3.77, lr 0.000577, consume 71.97s
step 12400, loss 3.76, lr 0.000577, consume 86.10s
step 12500, loss 3.77, lr 0.000576, consume 71.25s
step 12600, loss 3.76, lr 0.000576, consume 71.27s
step 12700, loss 3.76, lr 0.000575, consume 71.25s
step 12800, loss 3.76, lr 0.000575, consume 71.23s
step 12900, loss 3.75, lr 0.000574, consume 71.23s
step 13000, loss 3.76, lr 0.000574, consume 71.23s
step 13100, loss 3.75, lr 0.000573, consume 71.21s
step 13200, loss 3.76, lr 0.000573, consume 71.20s
step 13300, loss 3.75, lr 0.000573, consume 71.20s
step 13400, loss 3.75, lr 0.000572, consume 71.22s
step 13500, loss 3.75, lr 0.000572, consume 71.23s
processing 10: english_c4/c4-train.00010-of-01024.txt, origin: 355702, samples: 173710, accum_tokens: 1952M, iter_num: 13536
step 13600, loss 3.75, lr 0.000571, consume 91.60s
step 13700, loss 3.76, lr 0.000571, consume 72.93s
step 13800, loss 3.74, lr 0.000570, consume 84.58s
step 13900, loss 3.75, lr 0.000570, consume 71.16s
step 14000, loss 3.74, lr 0.000569, consume 71.22s
step 14100, loss 3.75, lr 0.000569, consume 71.23s
step 14200, loss 3.74, lr 0.000568, consume 71.24s
step 14300, loss 3.74, lr 0.000568, consume 71.24s
step 14400, loss 3.75, lr 0.000567, consume 71.23s
step 14500, loss 3.74, lr 0.000567, consume 71.20s
step 14600, loss 3.74, lr 0.000566, consume 71.24s
step 14700, loss 3.74, lr 0.000565, consume 71.23s
step 14800, loss 3.74, lr 0.000565, consume 71.22s
processing 11: english_c4/c4-train.00011-of-01024.txt, origin: 355701, samples: 173885, accum_tokens: 2130M, iter_num: 14893
step 14900, loss 3.74, lr 0.000564, consume 88.49s
step 15000, loss 3.75, lr 0.000564, consume 74.81s
step 15100, loss 3.74, lr 0.000563, consume 73.39s
step 15200, loss 3.74, lr 0.000563, consume 82.98s
step 15300, loss 3.74, lr 0.000562, consume 71.19s
step 15400, loss 3.74, lr 0.000562, consume 71.23s
step 15500, loss 3.74, lr 0.000561, consume 71.23s
step 15600, loss 3.73, lr 0.000561, consume 71.22s
step 15700, loss 3.73, lr 0.000560, consume 71.25s
step 15800, loss 3.74, lr 0.000559, consume 71.22s
step 15900, loss 3.73, lr 0.000559, consume 71.23s
step 16000, loss 3.73, lr 0.000558, consume 71.23s
step 16100, loss 3.74, lr 0.000558, consume 71.23s
step 16200, loss 3.73, lr 0.000557, consume 71.23s
processing 12: english_c4/c4-train.00012-of-01024.txt, origin: 355710, samples: 174423, accum_tokens: 2308M, iter_num: 16252
step 16300, loss 3.73, lr 0.000556, consume 91.41s
step 16400, loss 3.72, lr 0.000556, consume 72.74s
step 16500, loss 3.72, lr 0.000555, consume 84.42s
step 16600, loss 3.72, lr 0.000555, consume 71.08s
step 16700, loss 3.73, lr 0.000554, consume 71.21s
step 16800, loss 3.73, lr 0.000553, consume 71.23s
step 16900, loss 3.72, lr 0.000553, consume 71.24s
step 17000, loss 3.72, lr 0.000552, consume 71.24s
step 17100, loss 3.71, lr 0.000552, consume 71.23s
step 17200, loss 3.72, lr 0.000551, consume 71.21s
step 17300, loss 3.72, lr 0.000550, consume 71.21s
step 17400, loss 3.71, lr 0.000550, consume 71.22s
step 17500, loss 3.71, lr 0.000549, consume 71.21s
step 17600, loss 3.72, lr 0.000548, consume 71.20s
processing 13: english_c4/c4-train.00013-of-01024.txt, origin: 355723, samples: 173966, accum_tokens: 2487M, iter_num: 17614
step 17700, loss 3.72, lr 0.000548, consume 91.71s
step 17800, loss 3.71, lr 0.000547, consume 74.09s
step 17900, loss 3.71, lr 0.000547, consume 83.20s
step 18000, loss 3.72, lr 0.000546, consume 71.22s
step 18100, loss 3.70, lr 0.000545, consume 71.23s
step 18200, loss 3.72, lr 0.000545, consume 71.24s
step 18300, loss 3.71, lr 0.000544, consume 71.23s
step 18400, loss 3.71, lr 0.000543, consume 71.24s
step 18500, loss 3.72, lr 0.000543, consume 71.23s
step 18600, loss 3.71, lr 0.000542, consume 71.23s
step 18700, loss 3.70, lr 0.000541, consume 71.24s
step 18800, loss 3.71, lr 0.000541, consume 71.24s
step 18900, loss 3.70, lr 0.000540, consume 71.24s
processing 14: english_c4/c4-train.00014-of-01024.txt, origin: 355708, samples: 174115, accum_tokens: 2665M, iter_num: 18973
step 19000, loss 3.71, lr 0.000539, consume 91.00s
step 19100, loss 3.71, lr 0.000538, consume 73.18s
step 19200, loss 3.71, lr 0.000538, consume 84.88s
step 19300, loss 3.70, lr 0.000537, consume 71.13s
step 19400, loss 3.70, lr 0.000536, consume 71.22s
step 19500, loss 3.71, lr 0.000536, consume 71.24s
step 19600, loss 3.70, lr 0.000535, consume 71.25s
step 19700, loss 3.70, lr 0.000534, consume 71.23s
step 19800, loss 3.70, lr 0.000534, consume 71.23s
step 19900, loss 3.70, lr 0.000533, consume 71.22s
step 20000, loss 3.69, lr 0.000532, consume 71.23s
step 20100, loss 3.71, lr 0.000531, consume 71.23s
step 20200, loss 3.70, lr 0.000531, consume 71.22s
step 20300, loss 3.69, lr 0.000530, consume 71.21s
processing 15: english_c4/c4-train.00015-of-01024.txt, origin: 355698, samples: 173319, accum_tokens: 2842M, iter_num: 20333
step 20400, loss 3.71, lr 0.000529, consume 91.57s
step 20500, loss 3.70, lr 0.000528, consume 72.86s
step 20600, loss 3.70, lr 0.000528, consume 84.56s
step 20700, loss 3.70, lr 0.000527, consume 71.17s
step 20800, loss 3.70, lr 0.000526, consume 71.23s
step 20900, loss 3.70, lr 0.000525, consume 71.23s
step 21000, loss 3.70, lr 0.000525, consume 71.23s
step 21100, loss 3.70, lr 0.000524, consume 71.23s
step 21200, loss 3.69, lr 0.000523, consume 71.21s
step 21300, loss 3.70, lr 0.000522, consume 71.21s
step 21400, loss 3.69, lr 0.000522, consume 71.21s
step 21500, loss 3.69, lr 0.000521, consume 71.21s
step 21600, loss 3.69, lr 0.000520, consume 71.21s
processing 16: english_c4/c4-train.00016-of-01024.txt, origin: 355697, samples: 173354, accum_tokens: 3020M, iter_num: 21687
step 21700, loss 3.70, lr 0.000519, consume 90.78s
step 21800, loss 3.70, lr 0.000519, consume 72.45s
step 21900, loss 3.69, lr 0.000518, consume 85.63s
step 22000, loss 3.69, lr 0.000517, consume 70.97s
step 22100, loss 3.69, lr 0.000516, consume 71.21s
step 22200, loss 3.69, lr 0.000515, consume 71.24s
step 22300, loss 3.69, lr 0.000515, consume 71.23s
step 22400, loss 3.69, lr 0.000514, consume 71.24s
step 22500, loss 3.69, lr 0.000513, consume 71.25s
step 22600, loss 3.68, lr 0.000512, consume 71.23s
step 22700, loss 3.69, lr 0.000511, consume 71.23s
step 22800, loss 3.69, lr 0.000511, consume 71.21s
step 22900, loss 3.68, lr 0.000510, consume 71.23s
step 23000, loss 3.68, lr 0.000509, consume 71.24s
processing 17: english_c4/c4-train.00017-of-01024.txt, origin: 355726, samples: 174259, accum_tokens: 3198M, iter_num: 23042
step 23100, loss 3.68, lr 0.000508, consume 91.10s
step 23200, loss 3.69, lr 0.000507, consume 72.64s
step 23300, loss 3.68, lr 0.000507, consume 84.29s
step 23400, loss 3.69, lr 0.000506, consume 71.12s
step 23500, loss 3.69, lr 0.000505, consume 71.25s
step 23600, loss 3.69, lr 0.000504, consume 71.24s
step 23700, loss 3.68, lr 0.000503, consume 71.23s
step 23800, loss 3.68, lr 0.000502, consume 71.25s
step 23900, loss 3.68, lr 0.000502, consume 71.22s
step 24000, loss 3.69, lr 0.000501, consume 71.23s
step 24100, loss 3.67, lr 0.000500, consume 71.22s
step 24200, loss 3.68, lr 0.000499, consume 71.22s
step 24300, loss 3.68, lr 0.000498, consume 71.23s
step 24400, loss 3.68, lr 0.000497, consume 71.22s
processing 18: english_c4/c4-train.00018-of-01024.txt, origin: 355709, samples: 173222, accum_tokens: 3376M, iter_num: 24403
step 24500, loss 3.69, lr 0.000497, consume 92.35s
step 24600, loss 3.68, lr 0.000496, consume 73.23s
step 24700, loss 3.69, lr 0.000495, consume 83.15s
step 24800, loss 3.68, lr 0.000494, consume 71.11s
step 24900, loss 3.68, lr 0.000493, consume 71.24s
step 25000, loss 3.68, lr 0.000492, consume 71.24s
step 25100, loss 3.67, lr 0.000491, consume 71.24s
step 25200, loss 3.68, lr 0.000490, consume 71.24s
step 25300, loss 3.68, lr 0.000490, consume 71.24s
step 25400, loss 3.68, lr 0.000489, consume 71.22s
step 25500, loss 3.67, lr 0.000488, consume 71.24s
step 25600, loss 3.68, lr 0.000487, consume 71.25s
step 25700, loss 3.67, lr 0.000486, consume 71.23s
processing 19: english_c4/c4-train.00019-of-01024.txt, origin: 355697, samples: 173993, accum_tokens: 3554M, iter_num: 25756
step 25800, loss 3.68, lr 0.000485, consume 91.43s
step 25900, loss 3.68, lr 0.000484, consume 73.26s
step 26000, loss 3.67, lr 0.000483, consume 84.61s
step 26100, loss 3.67, lr 0.000482, consume 71.15s
step 26200, loss 3.67, lr 0.000482, consume 71.23s
step 26300, loss 3.67, lr 0.000481, consume 71.25s
step 26400, loss 3.67, lr 0.000480, consume 71.24s
step 26500, loss 3.67, lr 0.000479, consume 71.23s
step 26600, loss 3.67, lr 0.000478, consume 71.24s
step 26700, loss 3.67, lr 0.000477, consume 71.23s
step 26800, loss 3.67, lr 0.000476, consume 71.24s
step 26900, loss 3.67, lr 0.000475, consume 71.25s
step 27000, loss 3.67, lr 0.000474, consume 71.24s
step 27100, loss 3.67, lr 0.000473, consume 71.25s
processing 20: english_c4/c4-train.00020-of-01024.txt, origin: 355687, samples: 173497, accum_tokens: 3732M, iter_num: 27115
step 27200, loss 3.67, lr 0.000472, consume 92.14s
step 27300, loss 3.67, lr 0.000472, consume 73.45s
step 27400, loss 3.68, lr 0.000471, consume 83.52s
step 27500, loss 3.68, lr 0.000470, consume 71.21s
step 27600, loss 3.67, lr 0.000469, consume 71.25s
step 27700, loss 3.66, lr 0.000468, consume 71.26s
step 27800, loss 3.67, lr 0.000467, consume 71.25s
step 27900, loss 3.67, lr 0.000466, consume 71.24s
step 28000, loss 3.67, lr 0.000465, consume 71.24s
step 28100, loss 3.67, lr 0.000464, consume 71.23s
step 28200, loss 3.66, lr 0.000463, consume 71.23s
step 28300, loss 3.65, lr 0.000462, consume 71.25s
step 28400, loss 3.66, lr 0.000461, consume 71.22s
processing 21: english_c4/c4-train.00021-of-01024.txt, origin: 355709, samples: 173358, accum_tokens: 3909M, iter_num: 28471
step 28500, loss 3.66, lr 0.000460, consume 91.06s
step 28600, loss 3.66, lr 0.000459, consume 73.25s
step 28700, loss 3.66, lr 0.000458, consume 84.99s
step 28800, loss 3.65, lr 0.000457, consume 71.15s
step 28900, loss 3.66, lr 0.000456, consume 71.25s
step 29000, loss 3.66, lr 0.000455, consume 71.26s
step 29100, loss 3.66, lr 0.000455, consume 71.25s
step 29200, loss 3.66, lr 0.000454, consume 71.25s
step 29300, loss 3.66, lr 0.000453, consume 71.24s
step 29400, loss 3.66, lr 0.000452, consume 71.24s
step 29500, loss 3.66, lr 0.000451, consume 71.25s
step 29600, loss 3.66, lr 0.000450, consume 71.22s
step 29700, loss 3.66, lr 0.000449, consume 71.21s
step 29800, loss 3.65, lr 0.000448, consume 71.24s
processing 22: english_c4/c4-train.00022-of-01024.txt, origin: 355742, samples: 173215, accum_tokens: 4086M, iter_num: 29825
step 29900, loss 3.65, lr 0.000447, consume 91.30s
step 30000, loss 3.67, lr 0.000446, consume 73.06s
step 30100, loss 3.66, lr 0.000445, consume 84.52s
step 30200, loss 3.66, lr 0.000444, consume 71.18s
step 30300, loss 3.66, lr 0.000443, consume 71.24s
step 30400, loss 3.66, lr 0.000442, consume 71.22s
step 30500, loss 3.66, lr 0.000441, consume 71.23s
step 30600, loss 3.66, lr 0.000440, consume 71.21s
step 30700, loss 3.66, lr 0.000439, consume 71.22s
step 30800, loss 3.65, lr 0.000438, consume 71.23s
step 30900, loss 3.66, lr 0.000437, consume 71.21s
step 31000, loss 3.66, lr 0.000436, consume 71.23s
step 31100, loss 3.66, lr 0.000435, consume 71.23s
processing 23: english_c4/c4-train.00023-of-01024.txt, origin: 355714, samples: 173979, accum_tokens: 4265M, iter_num: 31178
step 31200, loss 3.66, lr 0.000434, consume 90.99s
step 31300, loss 3.66, lr 0.000433, consume 72.94s
step 31400, loss 3.65, lr 0.000432, consume 84.61s
step 31500, loss 3.65, lr 0.000431, consume 71.11s
step 31600, loss 3.66, lr 0.000430, consume 71.21s
step 31700, loss 3.65, lr 0.000429, consume 71.27s
step 31800, loss 3.65, lr 0.000428, consume 71.25s
step 31900, loss 3.65, lr 0.000427, consume 71.25s
step 32000, loss 3.65, lr 0.000426, consume 71.23s
step 32100, loss 3.65, lr 0.000425, consume 71.23s
step 32200, loss 3.65, lr 0.000424, consume 71.22s
step 32300, loss 3.65, lr 0.000423, consume 71.22s
step 32400, loss 3.65, lr 0.000422, consume 71.22s
step 32500, loss 3.64, lr 0.000421, consume 71.24s
processing 24: english_c4/c4-train.00024-of-01024.txt, origin: 355728, samples: 172879, accum_tokens: 4442M, iter_num: 32537
step 32600, loss 3.65, lr 0.000420, consume 91.89s
step 32700, loss 3.66, lr 0.000419, consume 73.02s
step 32800, loss 3.65, lr 0.000418, consume 84.79s
step 32900, loss 3.65, lr 0.000417, consume 71.17s
step 33000, loss 3.65, lr 0.000416, consume 71.24s
step 33100, loss 3.64, lr 0.000414, consume 71.24s
step 33200, loss 3.65, lr 0.000413, consume 71.23s
step 33300, loss 3.65, lr 0.000412, consume 71.24s
step 33400, loss 3.65, lr 0.000411, consume 71.24s
step 33500, loss 3.65, lr 0.000410, consume 71.22s
step 33600, loss 3.65, lr 0.000409, consume 71.23s
step 33700, loss 3.65, lr 0.000408, consume 71.23s
step 33800, loss 3.65, lr 0.000407, consume 71.25s
processing 25: english_c4/c4-train.00025-of-01024.txt, origin: 355713, samples: 173638, accum_tokens: 4619M, iter_num: 33887
step 33900, loss 3.64, lr 0.000406, consume 90.96s
step 34000, loss 3.65, lr 0.000405, consume 72.76s
step 34100, loss 3.64, lr 0.000404, consume 85.99s
step 34200, loss 3.64, lr 0.000403, consume 70.96s
step 34300, loss 3.64, lr 0.000402, consume 71.23s
step 34400, loss 3.64, lr 0.000401, consume 71.25s
step 34500, loss 3.64, lr 0.000400, consume 71.25s
step 34600, loss 3.64, lr 0.000399, consume 71.23s
step 34700, loss 3.64, lr 0.000398, consume 71.24s
step 34800, loss 3.63, lr 0.000397, consume 71.25s
step 34900, loss 3.63, lr 0.000396, consume 71.23s
step 35000, loss 3.63, lr 0.000395, consume 71.23s
step 35100, loss 3.64, lr 0.000394, consume 71.24s
step 35200, loss 3.63, lr 0.000393, consume 71.22s
processing 26: english_c4/c4-train.00026-of-01024.txt, origin: 355688, samples: 173072, accum_tokens: 4797M, iter_num: 35244
step 35300, loss 3.63, lr 0.000391, consume 90.96s
step 35400, loss 3.64, lr 0.000390, consume 73.52s
step 35500, loss 3.63, lr 0.000389, consume 84.73s
step 35600, loss 3.64, lr 0.000388, consume 71.19s
step 35700, loss 3.63, lr 0.000387, consume 71.26s
step 35800, loss 3.63, lr 0.000386, consume 71.27s
step 35900, loss 3.64, lr 0.000385, consume 71.26s
step 36000, loss 3.64, lr 0.000384, consume 71.27s
step 36100, loss 3.63, lr 0.000383, consume 71.23s
step 36200, loss 3.63, lr 0.000382, consume 71.24s
step 36300, loss 3.62, lr 0.000381, consume 71.24s
step 36400, loss 3.63, lr 0.000380, consume 71.25s
step 36500, loss 3.63, lr 0.000379, consume 71.24s
processing 27: english_c4/c4-train.00027-of-01024.txt, origin: 355713, samples: 174471, accum_tokens: 4975M, iter_num: 36596
step 36600, loss 3.63, lr 0.000378, consume 88.44s
step 36700, loss 3.63, lr 0.000377, consume 75.03s
step 36800, loss 3.63, lr 0.000375, consume 73.65s
step 36900, loss 3.63, lr 0.000374, consume 82.94s
step 37000, loss 3.62, lr 0.000373, consume 71.23s
step 37100, loss 3.63, lr 0.000372, consume 71.26s
step 37200, loss 3.63, lr 0.000371, consume 71.26s
step 37300, loss 3.63, lr 0.000370, consume 71.25s
step 37400, loss 3.63, lr 0.000369, consume 71.26s
step 37500, loss 3.63, lr 0.000368, consume 71.27s
step 37600, loss 3.62, lr 0.000367, consume 71.26s
step 37700, loss 3.62, lr 0.000366, consume 71.25s
step 37800, loss 3.62, lr 0.000365, consume 71.27s
step 37900, loss 3.63, lr 0.000364, consume 71.26s
processing 28: english_c4/c4-train.00028-of-01024.txt, origin: 355701, samples: 173576, accum_tokens: 5153M, iter_num: 37959
step 38000, loss 3.62, lr 0.000363, consume 91.13s
step 38100, loss 3.63, lr 0.000361, consume 73.09s
step 38200, loss 3.63, lr 0.000360, consume 84.82s
step 38300, loss 3.63, lr 0.000359, consume 71.09s
step 38400, loss 3.62, lr 0.000358, consume 71.27s
step 38500, loss 3.63, lr 0.000357, consume 71.28s
step 38600, loss 3.62, lr 0.000356, consume 71.27s
step 38700, loss 3.63, lr 0.000355, consume 71.26s
step 38800, loss 3.63, lr 0.000354, consume 71.26s
step 38900, loss 3.62, lr 0.000353, consume 71.24s
step 39000, loss 3.62, lr 0.000352, consume 71.23s
step 39100, loss 3.62, lr 0.000351, consume 71.22s
step 39200, loss 3.62, lr 0.000350, consume 71.22s
step 39300, loss 3.62, lr 0.000348, consume 71.22s
processing 29: english_c4/c4-train.00029-of-01024.txt, origin: 355707, samples: 173593, accum_tokens: 5331M, iter_num: 39315
step 39400, loss 3.62, lr 0.000347, consume 91.60s
step 39500, loss 3.62, lr 0.000346, consume 73.11s
step 39600, loss 3.62, lr 0.000345, consume 84.52s
step 39700, loss 3.61, lr 0.000344, consume 71.17s
step 39800, loss 3.62, lr 0.000343, consume 71.24s
step 39900, loss 3.61, lr 0.000342, consume 71.25s
step 40000, loss 3.61, lr 0.000341, consume 71.27s
step 40100, loss 3.62, lr 0.000340, consume 71.23s
step 40200, loss 3.62, lr 0.000339, consume 71.24s
step 40300, loss 3.62, lr 0.000338, consume 71.23s
step 40400, loss 3.61, lr 0.000337, consume 71.24s
step 40500, loss 3.61, lr 0.000335, consume 71.23s
step 40600, loss 3.62, lr 0.000334, consume 71.22s
processing 30: english_c4/c4-train.00030-of-01024.txt, origin: 355751, samples: 173202, accum_tokens: 5508M, iter_num: 40671
step 40700, loss 3.61, lr 0.000333, consume 91.10s
step 40800, loss 3.62, lr 0.000332, consume 73.07s
step 40900, loss 3.62, lr 0.000331, consume 84.83s
step 41000, loss 3.62, lr 0.000330, consume 71.45s
step 41100, loss 3.62, lr 0.000329, consume 71.11s
step 41200, loss 3.61, lr 0.000328, consume 71.05s
step 41300, loss 3.61, lr 0.000327, consume 71.03s
step 41400, loss 3.60, lr 0.000326, consume 71.02s
step 41500, loss 3.60, lr 0.000325, consume 71.00s
step 41600, loss 3.61, lr 0.000323, consume 71.02s
step 41700, loss 3.61, lr 0.000322, consume 71.01s
step 41800, loss 3.61, lr 0.000321, consume 71.02s
step 41900, loss 3.62, lr 0.000320, consume 71.02s
step 42000, loss 3.61, lr 0.000319, consume 71.00s
processing 31: english_c4/c4-train.00031-of-01024.txt, origin: 355742, samples: 173547, accum_tokens: 5686M, iter_num: 42024
step 42100, loss 3.62, lr 0.000318, consume 91.35s
step 42200, loss 3.61, lr 0.000317, consume 72.94s
step 42300, loss 3.62, lr 0.000316, consume 84.25s
step 42400, loss 3.60, lr 0.000315, consume 70.92s
step 42500, loss 3.61, lr 0.000314, consume 71.02s
step 42600, loss 3.61, lr 0.000313, consume 71.02s
step 42700, loss 3.61, lr 0.000312, consume 71.04s
step 42800, loss 3.60, lr 0.000310, consume 70.99s
step 42900, loss 3.60, lr 0.000309, consume 71.01s
step 43000, loss 3.62, lr 0.000308, consume 71.01s
step 43100, loss 3.61, lr 0.000307, consume 71.02s
step 43200, loss 3.60, lr 0.000306, consume 71.02s
step 43300, loss 3.61, lr 0.000305, consume 71.01s
processing 32: english_c4/c4-train.00032-of-01024.txt, origin: 355738, samples: 174928, accum_tokens: 5865M, iter_num: 43380
step 43400, loss 3.64, lr 0.000304, consume 37.25s
step 43500, loss 3.60, lr 0.000303, consume 72.99s
step 43600, loss 3.60, lr 0.000302, consume 91.83s
step 43700, loss 3.61, lr 0.000301, consume 70.98s
step 43800, loss 3.60, lr 0.000300, consume 71.10s
step 43900, loss 3.60, lr 0.000299, consume 71.15s
step 44000, loss 3.59, lr 0.000297, consume 71.11s
step 44100, loss 3.59, lr 0.000296, consume 71.11s
step 44200, loss 3.60, lr 0.000295, consume 71.12s
step 44300, loss 3.60, lr 0.000294, consume 71.11s
step 44400, loss 3.59, lr 0.000293, consume 71.11s
step 44500, loss 3.60, lr 0.000292, consume 71.11s
step 44600, loss 3.59, lr 0.000291, consume 71.09s
step 44700, loss 3.59, lr 0.000290, consume 71.08s
processing 33: english_c4/c4-train.00033-of-01024.txt, origin: 355671, samples: 174586, accum_tokens: 6044M, iter_num: 44746
step 44800, loss 3.59, lr 0.000289, consume 89.08s
step 44900, loss 3.60, lr 0.000288, consume 73.41s
step 45000, loss 3.59, lr 0.000287, consume 90.71s
step 45100, loss 3.59, lr 0.000286, consume 71.05s
step 45200, loss 3.59, lr 0.000285, consume 71.13s
step 45300, loss 3.59, lr 0.000283, consume 71.12s
step 45400, loss 3.59, lr 0.000282, consume 71.12s
step 45500, loss 3.60, lr 0.000281, consume 71.12s
step 45600, loss 3.59, lr 0.000280, consume 71.11s
step 45700, loss 3.59, lr 0.000279, consume 71.11s
step 45800, loss 3.59, lr 0.000278, consume 71.06s
step 45900, loss 3.59, lr 0.000277, consume 71.04s
step 46000, loss 3.59, lr 0.000276, consume 71.06s
step 46100, loss 3.59, lr 0.000275, consume 71.06s
processing 34: english_c4/c4-train.00034-of-01024.txt, origin: 355742, samples: 173885, accum_tokens: 6222M, iter_num: 46110
step 46200, loss 3.59, lr 0.000274, consume 89.70s
step 46300, loss 3.60, lr 0.000273, consume 73.56s
step 46400, loss 3.59, lr 0.000272, consume 91.19s
step 46500, loss 3.59, lr 0.000271, consume 71.15s
step 46600, loss 3.59, lr 0.000270, consume 71.18s
step 46700, loss 3.58, lr 0.000269, consume 71.17s
step 46800, loss 3.58, lr 0.000268, consume 71.19s
step 46900, loss 3.59, lr 0.000266, consume 71.16s
step 47000, loss 3.59, lr 0.000265, consume 71.13s
step 47100, loss 3.58, lr 0.000264, consume 71.15s
step 47200, loss 3.59, lr 0.000263, consume 71.14s
step 47300, loss 3.58, lr 0.000262, consume 71.14s
step 47400, loss 3.58, lr 0.000261, consume 71.14s
processing 35: english_c4/c4-train.00035-of-01024.txt, origin: 355715, samples: 173695, accum_tokens: 6400M, iter_num: 47468
step 47500, loss 3.58, lr 0.000260, consume 88.58s
step 47600, loss 3.59, lr 0.000259, consume 72.50s
step 47700, loss 3.59, lr 0.000258, consume 91.70s
step 47800, loss 3.59, lr 0.000257, consume 71.04s
step 47900, loss 3.59, lr 0.000256, consume 71.15s
step 48000, loss 3.58, lr 0.000255, consume 71.19s
step 48100, loss 3.59, lr 0.000254, consume 71.17s
step 48200, loss 3.59, lr 0.000253, consume 71.19s
step 48300, loss 3.58, lr 0.000252, consume 71.14s
step 48400, loss 3.58, lr 0.000251, consume 71.17s
step 48500, loss 3.58, lr 0.000250, consume 71.19s
step 48600, loss 3.58, lr 0.000249, consume 71.17s
step 48700, loss 3.58, lr 0.000248, consume 71.17s
step 48800, loss 3.57, lr 0.000247, consume 71.19s
processing 36: english_c4/c4-train.00036-of-01024.txt, origin: 355725, samples: 173921, accum_tokens: 6578M, iter_num: 48825
step 48900, loss 3.58, lr 0.000246, consume 89.38s
step 49000, loss 3.57, lr 0.000245, consume 73.36s
step 49100, loss 3.58, lr 0.000243, consume 90.47s
step 49200, loss 3.58, lr 0.000242, consume 71.06s
step 49300, loss 3.57, lr 0.000241, consume 71.18s
step 49400, loss 3.57, lr 0.000240, consume 71.22s
step 49500, loss 3.58, lr 0.000239, consume 71.16s
step 49600, loss 3.57, lr 0.000238, consume 71.19s
step 49700, loss 3.57, lr 0.000237, consume 71.22s
step 49800, loss 3.58, lr 0.000236, consume 71.22s
step 49900, loss 3.58, lr 0.000235, consume 71.18s
step 50000, loss 3.57, lr 0.000234, consume 71.20s
step 50100, loss 3.57, lr 0.000233, consume 71.21s
processing 37: english_c4/c4-train.00037-of-01024.txt, origin: 355760, samples: 174372, accum_tokens: 6756M, iter_num: 50184
step 50200, loss 3.61, lr 0.000232, consume 35.73s
step 50300, loss 3.58, lr 0.000231, consume 74.53s
step 50400, loss 3.58, lr 0.000230, consume 93.91s
step 50500, loss 3.57, lr 0.000229, consume 72.60s
step 50600, loss 3.58, lr 0.000228, consume 72.73s
step 50700, loss 3.58, lr 0.000227, consume 72.74s
step 50800, loss 3.58, lr 0.000226, consume 72.74s
step 50900, loss 3.58, lr 0.000225, consume 72.74s
step 51000, loss 3.57, lr 0.000224, consume 72.75s
step 51100, loss 3.57, lr 0.000223, consume 72.74s
step 51200, loss 3.57, lr 0.000222, consume 72.73s
step 51300, loss 3.58, lr 0.000221, consume 72.71s
step 51400, loss 3.57, lr 0.000220, consume 72.90s
step 51500, loss 3.57, lr 0.000219, consume 73.33s
processing 38: english_c4/c4-train.00038-of-01024.txt, origin: 355686, samples: 173519, accum_tokens: 6934M, iter_num: 51546
step 51600, loss 3.57, lr 0.000218, consume 91.12s
step 51700, loss 3.56, lr 0.000217, consume 75.39s
step 51800, loss 3.57, lr 0.000216, consume 92.54s
step 51900, loss 3.56, lr 0.000215, consume 72.95s
step 52000, loss 3.57, lr 0.000214, consume 72.98s
step 52100, loss 3.57, lr 0.000213, consume 72.99s
step 52200, loss 3.56, lr 0.000212, consume 72.99s
step 52300, loss 3.57, lr 0.000211, consume 72.98s
step 52400, loss 3.56, lr 0.000210, consume 72.97s
step 52500, loss 3.56, lr 0.000209, consume 72.97s
step 52600, loss 3.57, lr 0.000208, consume 72.97s
step 52700, loss 3.56, lr 0.000207, consume 72.98s
step 52800, loss 3.56, lr 0.000206, consume 72.97s
step 52900, loss 3.57, lr 0.000205, consume 72.97s
processing 39: english_c4/c4-train.00039-of-01024.txt, origin: 355723, samples: 174477, accum_tokens: 7113M, iter_num: 52901
step 53000, loss 3.57, lr 0.000205, consume 91.63s
step 53100, loss 3.57, lr 0.000204, consume 75.32s
step 53200, loss 3.57, lr 0.000203, consume 92.89s
step 53300, loss 3.57, lr 0.000202, consume 73.07s
step 53400, loss 3.57, lr 0.000201, consume 73.06s
step 53500, loss 3.57, lr 0.000200, consume 73.05s
step 53600, loss 3.56, lr 0.000199, consume 73.05s
step 53700, loss 3.57, lr 0.000198, consume 73.06s
step 53800, loss 3.56, lr 0.000197, consume 73.05s
step 53900, loss 3.57, lr 0.000196, consume 73.04s
step 54000, loss 3.57, lr 0.000195, consume 73.05s
step 54100, loss 3.56, lr 0.000194, consume 73.06s
step 54200, loss 3.57, lr 0.000193, consume 73.05s
processing 40: english_c4/c4-train.00040-of-01024.txt, origin: 355743, samples: 174552, accum_tokens: 7291M, iter_num: 54264
step 54300, loss 3.57, lr 0.000192, consume 91.41s
step 54400, loss 3.57, lr 0.000191, consume 74.77s
step 54500, loss 3.56, lr 0.000190, consume 93.89s
step 54600, loss 3.56, lr 0.000189, consume 73.00s
step 54700, loss 3.57, lr 0.000188, consume 73.09s
step 54800, loss 3.56, lr 0.000188, consume 73.10s
step 54900, loss 3.56, lr 0.000187, consume 73.08s
step 55000, loss 3.56, lr 0.000186, consume 73.14s
step 55100, loss 3.56, lr 0.000185, consume 73.15s
step 55200, loss 3.55, lr 0.000184, consume 72.83s
step 55300, loss 3.55, lr 0.000183, consume 72.83s
step 55400, loss 3.56, lr 0.000182, consume 72.83s
step 55500, loss 3.56, lr 0.000181, consume 72.83s
step 55600, loss 3.55, lr 0.000180, consume 72.83s
processing 41: english_c4/c4-train.00041-of-01024.txt, origin: 355732, samples: 174188, accum_tokens: 7470M, iter_num: 55628
step 55700, loss 3.56, lr 0.000179, consume 91.55s
step 55800, loss 3.56, lr 0.000178, consume 74.90s
step 55900, loss 3.56, lr 0.000178, consume 91.46s
step 56000, loss 3.56, lr 0.000177, consume 72.84s
step 56100, loss 3.57, lr 0.000176, consume 72.87s
step 56200, loss 3.55, lr 0.000175, consume 72.87s
step 56300, loss 3.56, lr 0.000174, consume 72.88s
step 56400, loss 3.56, lr 0.000173, consume 72.85s
step 56500, loss 3.56, lr 0.000172, consume 72.85s
step 56600, loss 3.56, lr 0.000171, consume 72.85s
step 56700, loss 3.56, lr 0.000170, consume 72.86s
step 56800, loss 3.55, lr 0.000170, consume 72.85s
step 56900, loss 3.55, lr 0.000169, consume 72.83s
processing 42: english_c4/c4-train.00042-of-01024.txt, origin: 355693, samples: 173274, accum_tokens: 7647M, iter_num: 56989
step 57000, loss 3.55, lr 0.000168, consume 90.62s
step 57100, loss 3.56, lr 0.000167, consume 74.68s
step 57200, loss 3.55, lr 0.000166, consume 93.32s
step 57300, loss 3.56, lr 0.000165, consume 72.73s
step 57400, loss 3.56, lr 0.000164, consume 72.89s
step 57500, loss 3.55, lr 0.000163, consume 72.90s
step 57600, loss 3.56, lr 0.000163, consume 72.90s
step 57700, loss 3.56, lr 0.000162, consume 72.90s
step 57800, loss 3.55, lr 0.000161, consume 72.90s
step 57900, loss 3.55, lr 0.000160, consume 72.89s
step 58000, loss 3.55, lr 0.000159, consume 72.89s
step 58100, loss 3.55, lr 0.000158, consume 72.89s
step 58200, loss 3.55, lr 0.000158, consume 72.89s
step 58300, loss 3.56, lr 0.000157, consume 72.89s
processing 43: english_c4/c4-train.00043-of-01024.txt, origin: 355728, samples: 172990, accum_tokens: 7824M, iter_num: 58342
step 58400, loss 3.55, lr 0.000156, consume 90.58s
step 58500, loss 3.56, lr 0.000155, consume 75.45s
step 58600, loss 3.55, lr 0.000154, consume 92.21s
step 58700, loss 3.55, lr 0.000153, consume 72.86s
step 58800, loss 3.55, lr 0.000153, consume 72.90s
step 58900, loss 3.55, lr 0.000152, consume 72.92s
step 59000, loss 3.55, lr 0.000151, consume 72.90s
step 59100, loss 3.55, lr 0.000150, consume 72.89s
step 59200, loss 3.54, lr 0.000149, consume 72.91s
step 59300, loss 3.55, lr 0.000149, consume 72.90s
step 59400, loss 3.55, lr 0.000148, consume 72.91s
step 59500, loss 3.54, lr 0.000147, consume 72.88s
step 59600, loss 3.54, lr 0.000146, consume 72.89s
processing 44: english_c4/c4-train.00044-of-01024.txt, origin: 355718, samples: 173869, accum_tokens: 8002M, iter_num: 59693
step 59700, loss 3.54, lr 0.000145, consume 87.94s
step 59800, loss 3.55, lr 0.000145, consume 77.06s
step 59900, loss 3.55, lr 0.000144, consume 93.09s
step 60000, loss 3.55, lr 0.000143, consume 72.74s
step 60100, loss 3.54, lr 0.000142, consume 72.89s
step 60200, loss 3.55, lr 0.000141, consume 72.91s
step 60300, loss 3.54, lr 0.000141, consume 72.92s
step 60400, loss 3.54, lr 0.000140, consume 72.93s
step 60500, loss 3.54, lr 0.000139, consume 72.90s
step 60600, loss 3.54, lr 0.000138, consume 72.90s
step 60700, loss 3.55, lr 0.000138, consume 72.90s
step 60800, loss 3.54, lr 0.000137, consume 72.89s
step 60900, loss 3.54, lr 0.000136, consume 72.90s
step 61000, loss 3.54, lr 0.000135, consume 72.89s
processing 45: english_c4/c4-train.00045-of-01024.txt, origin: 355708, samples: 174224, accum_tokens: 8181M, iter_num: 61052
step 61100, loss 3.54, lr 0.000135, consume 90.95s
step 61200, loss 3.54, lr 0.000134, consume 74.46s
step 61300, loss 3.54, lr 0.000133, consume 93.57s
step 61400, loss 3.55, lr 0.000132, consume 72.87s
step 61500, loss 3.55, lr 0.000132, consume 72.93s
step 61600, loss 3.54, lr 0.000131, consume 72.93s
step 61700, loss 3.53, lr 0.000130, consume 72.92s
step 61800, loss 3.54, lr 0.000129, consume 72.92s
step 61900, loss 3.54, lr 0.000129, consume 72.93s
step 62000, loss 3.54, lr 0.000128, consume 72.92s
step 62100, loss 3.54, lr 0.000127, consume 72.92s
step 62200, loss 3.54, lr 0.000126, consume 72.92s
step 62300, loss 3.54, lr 0.000126, consume 72.93s
step 62400, loss 3.54, lr 0.000125, consume 72.91s
processing 46: english_c4/c4-train.00046-of-01024.txt, origin: 355711, samples: 173811, accum_tokens: 8359M, iter_num: 62413
step 62500, loss 3.53, lr 0.000124, consume 91.76s
step 62600, loss 3.54, lr 0.000124, consume 75.19s
step 62700, loss 3.54, lr 0.000123, consume 92.11s
step 62800, loss 3.54, lr 0.000122, consume 72.89s
step 62900, loss 3.53, lr 0.000122, consume 72.93s
step 63000, loss 3.54, lr 0.000121, consume 72.92s
step 63100, loss 3.53, lr 0.000120, consume 72.93s
step 63200, loss 3.54, lr 0.000119, consume 72.92s
step 63300, loss 3.54, lr 0.000119, consume 72.93s
step 63400, loss 3.53, lr 0.000118, consume 72.93s
step 63500, loss 3.54, lr 0.000117, consume 72.94s
step 63600, loss 3.53, lr 0.000117, consume 73.85s
step 63700, loss 3.53, lr 0.000116, consume 72.93s
processing 47: english_c4/c4-train.00047-of-01024.txt, origin: 355731, samples: 173284, accum_tokens: 8536M, iter_num: 63770
step 63800, loss 3.53, lr 0.000115, consume 90.69s
step 63900, loss 3.53, lr 0.000115, consume 74.37s
step 64000, loss 3.53, lr 0.000114, consume 92.35s
step 64100, loss 3.54, lr 0.000114, consume 72.80s
step 64200, loss 3.54, lr 0.000113, consume 72.95s
step 64300, loss 3.54, lr 0.000112, consume 72.95s
step 64400, loss 3.53, lr 0.000112, consume 72.95s
step 64500, loss 3.53, lr 0.000111, consume 72.95s
step 64600, loss 3.53, lr 0.000110, consume 72.96s
step 64700, loss 3.53, lr 0.000110, consume 72.94s
step 64800, loss 3.53, lr 0.000109, consume 72.92s
step 64900, loss 3.53, lr 0.000108, consume 72.94s
step 65000, loss 3.52, lr 0.000108, consume 72.92s
step 65100, loss 3.53, lr 0.000107, consume 72.94s
processing 48: english_c4/c4-train.00048-of-01024.txt, origin: 355721, samples: 173031, accum_tokens: 8713M, iter_num: 65124
step 65200, loss 3.53, lr 0.000107, consume 91.73s
step 65300, loss 3.53, lr 0.000106, consume 74.96s
step 65400, loss 3.53, lr 0.000105, consume 92.01s
step 65500, loss 3.54, lr 0.000105, consume 72.89s
step 65600, loss 3.53, lr 0.000104, consume 72.94s
step 65700, loss 3.53, lr 0.000104, consume 72.96s
step 65800, loss 3.52, lr 0.000103, consume 72.95s
step 65900, loss 3.53, lr 0.000102, consume 72.95s
step 66000, loss 3.53, lr 0.000102, consume 72.96s
step 66100, loss 3.53, lr 0.000101, consume 72.94s
step 66200, loss 3.53, lr 0.000101, consume 72.92s
step 66300, loss 3.53, lr 0.000100, consume 72.94s
step 66400, loss 3.53, lr 0.000100, consume 72.93s
processing 49: english_c4/c4-train.00049-of-01024.txt, origin: 355716, samples: 174175, accum_tokens: 8892M, iter_num: 66476
step 66500, loss 3.53, lr 0.000099, consume 90.80s
step 66600, loss 3.53, lr 0.000098, consume 74.63s
step 66700, loss 3.52, lr 0.000098, consume 93.00s
step 66800, loss 3.52, lr 0.000097, consume 72.79s
step 66900, loss 3.52, lr 0.000097, consume 72.94s
step 67000, loss 3.53, lr 0.000096, consume 72.95s
step 67100, loss 3.53, lr 0.000096, consume 72.94s
step 67200, loss 3.52, lr 0.000095, consume 72.95s
step 67300, loss 3.52, lr 0.000095, consume 72.95s
step 67400, loss 3.52, lr 0.000094, consume 72.94s
step 67500, loss 3.52, lr 0.000094, consume 72.94s
step 67600, loss 3.52, lr 0.000093, consume 72.94s
step 67700, loss 3.52, lr 0.000092, consume 72.94s
step 67800, loss 3.52, lr 0.000092, consume 72.94s
processing 50: english_c4/c4-train.00050-of-01024.txt, origin: 355718, samples: 173257, accum_tokens: 9069M, iter_num: 67836
step 67900, loss 3.53, lr 0.000091, consume 90.87s
step 68000, loss 3.52, lr 0.000091, consume 74.90s
step 68100, loss 3.53, lr 0.000090, consume 92.01s
step 68200, loss 3.52, lr 0.000090, consume 72.91s
step 68300, loss 3.53, lr 0.000089, consume 72.96s
step 68400, loss 3.52, lr 0.000089, consume 72.97s
step 68500, loss 3.52, lr 0.000088, consume 72.96s
step 68600, loss 3.52, lr 0.000088, consume 72.97s
step 68700, loss 3.53, lr 0.000087, consume 72.96s
step 68800, loss 3.53, lr 0.000087, consume 72.96s
step 68900, loss 3.53, lr 0.000087, consume 72.96s
step 69000, loss 3.52, lr 0.000086, consume 72.97s
step 69100, loss 3.52, lr 0.000086, consume 72.95s
processing 51: english_c4/c4-train.00051-of-01024.txt, origin: 355672, samples: 173927, accum_tokens: 9247M, iter_num: 69190
step 69200, loss 3.52, lr 0.000085, consume 91.41s
step 69300, loss 3.52, lr 0.000085, consume 73.97s
step 69400, loss 3.52, lr 0.000084, consume 94.96s
step 69500, loss 3.52, lr 0.000084, consume 72.70s
step 69600, loss 3.52, lr 0.000083, consume 72.95s
step 69700, loss 3.52, lr 0.000083, consume 72.98s
step 69800, loss 3.51, lr 0.000082, consume 72.98s
step 69900, loss 3.51, lr 0.000082, consume 72.98s
step 70000, loss 3.52, lr 0.000082, consume 72.97s
step 70100, loss 3.52, lr 0.000081, consume 72.97s
step 70200, loss 3.51, lr 0.000081, consume 72.97s
step 70300, loss 3.51, lr 0.000080, consume 72.95s
step 70400, loss 3.52, lr 0.000080, consume 72.94s
step 70500, loss 3.51, lr 0.000080, consume 72.95s
processing 52: english_c4/c4-train.00052-of-01024.txt, origin: 355741, samples: 174993, accum_tokens: 9427M, iter_num: 70549
step 70600, loss 3.52, lr 0.000079, consume 90.78s
step 70700, loss 3.52, lr 0.000079, consume 74.55s
step 70800, loss 3.51, lr 0.000078, consume 94.04s
step 70900, loss 3.52, lr 0.000078, consume 72.82s
step 71000, loss 3.52, lr 0.000078, consume 72.96s
step 71100, loss 3.52, lr 0.000077, consume 72.95s
step 71200, loss 3.51, lr 0.000077, consume 72.96s
step 71300, loss 3.51, lr 0.000076, consume 72.97s
step 71400, loss 3.52, lr 0.000076, consume 72.95s
step 71500, loss 3.52, lr 0.000076, consume 72.98s
step 71600, loss 3.52, lr 0.000075, consume 72.96s
step 71700, loss 3.51, lr 0.000075, consume 72.96s
step 71800, loss 3.52, lr 0.000075, consume 72.94s
step 71900, loss 3.51, lr 0.000074, consume 72.94s
processing 53: english_c4/c4-train.00053-of-01024.txt, origin: 355705, samples: 175004, accum_tokens: 9606M, iter_num: 71916
step 72000, loss 3.51, lr 0.000074, consume 92.07s
step 72100, loss 3.52, lr 0.000074, consume 75.17s
step 72200, loss 3.51, lr 0.000073, consume 92.80s
step 72300, loss 3.51, lr 0.000073, consume 72.89s
step 72400, loss 3.51, lr 0.000073, consume 72.96s
step 72500, loss 3.51, lr 0.000072, consume 72.96s
step 72600, loss 3.51, lr 0.000072, consume 72.95s
step 72700, loss 3.51, lr 0.000072, consume 72.94s
step 72800, loss 3.51, lr 0.000071, consume 72.94s
step 72900, loss 3.51, lr 0.000071, consume 72.96s
step 73000, loss 3.51, lr 0.000071, consume 72.96s
step 73100, loss 3.51, lr 0.000070, consume 72.94s
step 73200, loss 3.52, lr 0.000070, consume 72.93s
processing 54: english_c4/c4-train.00054-of-01024.txt, origin: 355738, samples: 174860, accum_tokens: 9785M, iter_num: 73283
step 73300, loss 3.51, lr 0.000070, consume 91.10s
step 73400, loss 3.52, lr 0.000069, consume 74.04s
step 73500, loss 3.52, lr 0.000069, consume 95.06s
step 73600, loss 3.51, lr 0.000069, consume 72.87s
step 73700, loss 3.51, lr 0.000069, consume 72.94s
step 73800, loss 3.51, lr 0.000068, consume 72.94s
step 73900, loss 3.51, lr 0.000068, consume 72.95s
step 74000, loss 3.52, lr 0.000068, consume 72.96s
step 74100, loss 3.51, lr 0.000068, consume 72.96s
step 74200, loss 3.51, lr 0.000067, consume 72.94s
step 74300, loss 3.51, lr 0.000067, consume 73.04s
step 74400, loss 3.51, lr 0.000067, consume 72.98s
step 74500, loss 3.51, lr 0.000067, consume 72.93s
step 74600, loss 3.51, lr 0.000066, consume 72.94s
processing 55: english_c4/c4-train.00055-of-01024.txt, origin: 355762, samples: 173702, accum_tokens: 9963M, iter_num: 74649
step 74700, loss 3.51, lr 0.000066, consume 90.74s
step 74800, loss 3.51, lr 0.000066, consume 75.18s
step 74900, loss 3.51, lr 0.000066, consume 91.82s
step 75000, loss 3.51, lr 0.000065, consume 72.88s
step 75100, loss 3.51, lr 0.000065, consume 72.95s
step 75200, loss 3.51, lr 0.000065, consume 72.94s
step 75300, loss 3.51, lr 0.000065, consume 72.95s
step 75400, loss 3.51, lr 0.000065, consume 72.93s
step 75500, loss 3.51, lr 0.000064, consume 72.95s
step 75600, loss 3.52, lr 0.000064, consume 72.95s
step 75700, loss 3.50, lr 0.000064, consume 72.92s
step 75800, loss 3.51, lr 0.000064, consume 72.93s
step 75900, loss 3.51, lr 0.000064, consume 72.94s
step 76000, loss 3.51, lr 0.000063, consume 72.94s
processing 56: english_c4/c4-train.00056-of-01024.txt, origin: 355728, samples: 174276, accum_tokens: 10141M, iter_num: 76006
step 76100, loss 3.51, lr 0.000063, consume 92.04s
step 76200, loss 3.51, lr 0.000063, consume 75.33s
step 76300, loss 3.51, lr 0.000063, consume 92.44s
step 76400, loss 3.51, lr 0.000063, consume 72.92s
step 76500, loss 3.50, lr 0.000063, consume 72.96s
step 76600, loss 3.51, lr 0.000063, consume 72.96s
step 76700, loss 3.50, lr 0.000062, consume 72.96s
step 76800, loss 3.50, lr 0.000062, consume 72.97s
step 76900, loss 3.50, lr 0.000062, consume 72.95s
step 77000, loss 3.50, lr 0.000062, consume 72.97s
step 77100, loss 3.51, lr 0.000062, consume 72.97s
step 77200, loss 3.51, lr 0.000062, consume 72.97s
step 77300, loss 3.50, lr 0.000062, consume 72.96s
processing 57: english_c4/c4-train.00057-of-01024.txt, origin: 355709, samples: 174420, accum_tokens: 10320M, iter_num: 77367
step 77400, loss 3.51, lr 0.000061, consume 91.32s
step 77500, loss 3.50, lr 0.000061, consume 74.71s
step 77600, loss 3.51, lr 0.000061, consume 93.52s
step 77700, loss 3.51, lr 0.000061, consume 72.89s
step 77800, loss 3.52, lr 0.000061, consume 72.97s
step 77900, loss 3.51, lr 0.000061, consume 72.98s
step 78000, loss 3.50, lr 0.000061, consume 72.98s
step 78100, loss 3.51, lr 0.000061, consume 72.98s
step 78200, loss 3.50, lr 0.000061, consume 72.98s
step 78300, loss 3.50, lr 0.000061, consume 72.96s
step 78400, loss 3.50, lr 0.000061, consume 72.97s
step 78500, loss 3.51, lr 0.000060, consume 72.96s
step 78600, loss 3.50, lr 0.000060, consume 72.95s
step 78700, loss 3.51, lr 0.000060, consume 72.96s
processing 58: english_c4/c4-train.00058-of-01024.txt, origin: 355737, samples: 173510, accum_tokens: 10497M, iter_num: 78730
step 78800, loss 3.51, lr 0.000060, consume 91.00s
step 78900, loss 3.51, lr 0.000060, consume 74.68s
step 79000, loss 3.51, lr 0.000060, consume 93.35s
step 79100, loss 3.51, lr 0.000060, consume 72.91s
step 79200, loss 3.51, lr 0.000060, consume 72.97s
step 79300, loss 3.51, lr 0.000060, consume 73.00s
step 79400, loss 3.51, lr 0.000060, consume 72.98s
step 79500, loss 3.51, lr 0.000060, consume 72.98s
step 79600, loss 3.50, lr 0.000060, consume 72.98s
step 79700, loss 3.51, lr 0.000060, consume 72.97s
step 79800, loss 3.51, lr 0.000060, consume 72.96s
step 79900, loss 3.51, lr 0.000060, consume 72.97s
step 80000, loss 3.51, lr 0.000060, consume 72.97s
